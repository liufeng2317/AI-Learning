{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《An Image is Worth 16 x 16 Words: transformers for image recognition at scale》\n",
    "\n",
    "### (1)网络结构设计和实现 Vision Transformer\n",
    "![](Md_img/2023-06-20-10-51-19.png)\n",
    "\n",
    "标准的Transformer是对一维序列的 token embedding，所以需要转换。\n",
    "\n",
    "**图片转换为patch**\n",
    "\n",
    "为了能够处理二维数据，将一张 $x \\in R^{H \\times W \\times C}$ 图片变为一系列 二维 patch $x_p  \\in R^{N \\times (P^2.C)}$。其中 $(H,W)$是原始图片的分辨率，$C$是原始图片的通道。 $(P,P)$ 是每一个patch的分辨率， $N = HW/P^2 = H/P * W/P$ 是patch的数量。 \n",
    "\n",
    "**线性映射为D维隐变量**\n",
    "\n",
    "由于transformer使用D维大小的常隐变量响铃，可以通过一个线性映射得到从 patch到patch embedding的转变\n",
    "\n",
    "$$z_0 = [x_{class};x_p^1E;x_p^2E; ... ;x_p^NE;] + E_{pos}$$\n",
    "\n",
    "**Class token**\n",
    "\n",
    "注意，这里我们将分类的标签作为一个可以学习的token放在了 序列embedding的头部，我们将使用这个参数作为分类标志。\n",
    "\n",
    "**位置编码**\n",
    "\n",
    "位置编码是一个1D的位置编码，本文没有发现2D的位置编码可以明显提高效果\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2023-06-22 10:57:27\n",
      "Namespace(batch_size=128, data_path='./data', dset='mnist', embed_dim=96, epochs=200, forward_mul=2, img_size=28, load_model=False, log_step=50, lr=0.0005, model_path='./model/mnist', n_attention_heads=4, n_channels=1, n_classes=10, n_layers=6, num_workers=4, patch_size=4)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Transformer')\n",
    "parser.add_argument('--epochs', type=int, default=200)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--n_classes', type=int, default=10)\n",
    "parser.add_argument('--num_workers', type=int, default=4)\n",
    "parser.add_argument('--lr', type=float, default=5e-4)\n",
    "parser.add_argument('--log_step', type=int, default=50)\n",
    "\n",
    "parser.add_argument('--dset', type=str, default='mnist', help=['mnist', 'fmnist'])\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"Img size\")\n",
    "parser.add_argument(\"--patch_size\", type=int, default=4, help=\"Patch Size\")\n",
    "parser.add_argument(\"--n_channels\", type=int, default=1, help=\"Number of channels\")\n",
    "parser.add_argument('--data_path', type=str, default='./data')\n",
    "parser.add_argument('--model_path', type=str, default='./model')\n",
    "\n",
    "parser.add_argument(\"--embed_dim\", type=int, default=96, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--n_attention_heads\", type=int, default=4, help=\"number of heads to be used\")\n",
    "\n",
    "parser.add_argument(\"--forward_mul\", type=int, default=2, help=\"forward multiplier\")\n",
    "parser.add_argument(\"--n_layers\", type=int, default=6, help=\"number of encoder layers\")\n",
    "parser.add_argument(\"--load_model\", type=bool, default=False, help=\"Load saved model\")\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Started at \" + str(start_time.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.model_path = os.path.join(args.model_path, args.dset)\n",
    "print(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# B -> Batch size\n",
    "# C -> Number of Input channels\n",
    "\n",
    "# IH -> Image Height\n",
    "# IW -> Image Width\n",
    "# P -> Patch size\n",
    "\n",
    "# E -> Embedding Dimension\n",
    "# S -> （the number of patchs）Sequence Length = IH/P * IW/P\n",
    "\n",
    "# Q -> Query Sequence Length \n",
    "# K -> Key Sequence length\n",
    "# V -> Value Sequence length(same as Key length)\n",
    "\n",
    "# H -> Number of head\n",
    "# HE -> Head Embedding Dimension = E/H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedLayer(nn.Module):\n",
    "    \"\"\"\n",
    "        embedding for images\n",
    "        (1) image -> patch\n",
    "        (2) patch -> flatten patch embeddings\n",
    "        (3) adding classification tokens (parameters for learn)\n",
    "        (4) adding pos_embedding\n",
    "    \"\"\"\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.conv1 = nn.Conv2d(args.n_channels,\n",
    "                            args.embed_dim,\n",
    "                            kernel_size=args.patch_size,\n",
    "                            stride=args.patch_size) # pixcel embedding\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1,1,args.embed_dim),requires_grad=True) # cls token\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1,(args.img_size//args.patch_size)**2+1,args.embed_dim),requires_grad=True) # position embedding\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # B C IH IW -> B E IH/P IW/P (embedding the patches)\n",
    "        x = x.reshape([x.shape[0],self.args.embed_dim,-1]) # B E IH/P IW/P -> B E S(Flattening the patches)\n",
    "        x = x.transpose(1,2) # B E S -> B S E\n",
    "        x = torch.cat((torch.repeat_interleave(self.cls_token,x.shape[0],0),x),dim=1) # Adding classification token at the start of every sequence\n",
    "        x = x + self.pos_embedding # adding positional embedding\n",
    "        return x "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些基本的计算公式：\n",
    "多头注意力机制中的每一个注意力机制的输入分为三个输入 $Q,K,V$，是上一层输出结果的线性变换结果的三种不同形式。\n",
    "\n",
    "$$Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}}) V$$\n",
    "\n",
    "多头注意力：\n",
    "\n",
    "$$MultiHead(Q,K,V) = Concat(head_1,head_2,...,head_h)W^O$$\n",
    "\n",
    "其中 $head_i = Attention(QW_i^Q,KW_i^K,VW_i^V)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "        Multi-head Attention calculation the same as transformer for sequence data\n",
    "    \"\"\"\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        # the number of attention heads\n",
    "        self.n_attention_heads = args.n_attention_heads\n",
    "        # the dimension of the embedding\n",
    "        self.embed_dim = args.embed_dim\n",
    "        # the embedding dimension of each head \n",
    "        self.head_embed_dim = self.embed_dim // self.n_attention_heads\n",
    "        \n",
    "        self.queries = nn.Linear(self.embed_dim,self.head_embed_dim*self.n_attention_heads,bias=True)\n",
    "        self.keys = nn.Linear(self.embed_dim,self.head_embed_dim*self.n_attention_heads,bias=True)\n",
    "        self.values = nn.Linear(self.embed_dim,self.head_embed_dim*self.n_attention_heads,bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            Input: Batch, patch number , Embedding\n",
    "            Output: Batch, query length, number of head\n",
    "        \"\"\"\n",
    "        m,s,e = x.shape # Batch, patch number , Embedding\n",
    "        # query\n",
    "        xq = self.queries(x).reshape(m,s,self.n_attention_heads,self.head_embed_dim) # B,Q,E -> B,Q,H,HE\n",
    "        xq = xq.transpose(1,2) # B,Q,H,HE -> B,H,Q,HE\n",
    "        # key\n",
    "        xk = self.keys(x).reshape(m,s,self.n_attention_heads,self.head_embed_dim) # B,K,E -> B,K,H,HE\n",
    "        xk = xk.transpose(1,2) # B,K,H,HE -> B,H,K,HE\n",
    "        # value\n",
    "        xv = self.values(x).reshape(m,s,self.n_attention_heads,self.head_embed_dim) # B,V,E -> B,V,H,HE\n",
    "        xv = xv.transpose(1,2) # B,V,H,HE -> B,H,V,HE\n",
    "        \n",
    "        xq = xq.reshape([-1,s,self.head_embed_dim]) # B,H,Q,HE -> (BH),Q,HE\n",
    "        xk = xk.reshape([-1,s,self.head_embed_dim]) # B,H,K,HE -> (BH),K,HE\n",
    "        xv = xv.reshape([-1,s,self.head_embed_dim]) # B,H,V,HE -> (BH),V,HE\n",
    "        \n",
    "        # calculate the attention(没有看到除以根号K？)\n",
    "        xk = xk.transpose(1,2) # (BH),K,HE -> (BH),HE,K\n",
    "        x_attention = xq.bmm(xk) # (BH),Q,HE * (BH),HE,K -> (BH),Q,K\n",
    "        x_attention = torch.softmax(x_attention,dim = -1)\n",
    "        x = x_attention.bmm(xv) # (BH),Q,K * (BH),V,HE -> (BH),Q,HE\n",
    "        \n",
    "        x = x.reshape([-1,self.n_attention_heads,s,self.head_embed_dim]) # (BH),Q,HE -> B,H,Q,HE\n",
    "        x = x.transpose(1,2) # B,H,Q,HE -> B,Q,H,HE\n",
    "        x = x.reshape(m,s,e) # B,Q,H,HE -> B,Q,E\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder说明：\n",
    "$$LayerNorm(X + MultiHeadAttention(X))$$\n",
    "$$LayerNorm(X+FeedForward(X))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Transformer Encoder\"\"\"\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(args)\n",
    "        self.fc1 = nn.Linear(args.embed_dim,args.embed_dim * args.forward_mul)\n",
    "        self.activation = nn.GELU()\n",
    "        self.fc2 = nn.Linear(args.embed_dim*args.forward_mul,args.embed_dim)\n",
    "        self.norm1 = nn.LayerNorm(args.embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(args.embed_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # Multihead Attention\n",
    "        x = x + self.attention(self.norm1(x)) # skip connection\n",
    "        # Feed Forward model\n",
    "        x = x + self.fc2(self.activation(self.fc1(self.norm2(x)))) # skip connection\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(args.embed_dim,args.embed_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(args.embed_dim,args.n_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x[:,0,:] # get CLS token\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.embedding = EmbedLayer(args)\n",
    "        self.encoder = nn.Sequential(*[Encoder(args) for _ in range(args.n_layers)],nn.LayerNorm(args.embed_dim))\n",
    "        self.norm = nn.LayerNorm(args.embed_dim) # final normalization layer after the last block\n",
    "        self.classifier = Classifier(args)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import os \n",
    "\n",
    "def get_loader(args):\n",
    "    if args.dset == 'mnist':\n",
    "        tr_transform = transforms.Compose([transforms.RandomCrop(args.img_size,padding=2),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5],[0.5])\n",
    "                                            ])\n",
    "        train = datasets.MNIST(os.path.join(args.data_path,args.dset),train=True,download=True,transform=tr_transform)\n",
    "\n",
    "        te_transform = transforms.Compose([transforms.Resize([args.img_size,args.img_size]),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5],[0.5])])\n",
    "        test = datasets.MNIST(os.path.join(args.data_path,args.dset),train=False,download=True,transform=te_transform)\n",
    "    elif args.dset=='fmnist':\n",
    "        tr_transform = transforms.Compose([transforms.RandomCrop(args.img_size,padding=2),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5],[0.5])\n",
    "                                            ])\n",
    "        train = datasets.MNIST(os.path.join(args.data_path,args.dset),train=True,download=True,transform=tr_transform)\n",
    "\n",
    "        te_transform = transforms.Compose([transforms.Resize(args.img_size,args.img_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5],[0.5])])\n",
    "        test = datasets.MNIST(os.path.join(args.data_path,args.dest),train=False,download=True,transform=te_transform)\n",
    "    else:\n",
    "        print(\"Unknown datasets\")\n",
    "        exit(0)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = train,\n",
    "        batch_size = args.batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = args.num_workers,\n",
    "        drop_last = True\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset = test,\n",
    "        batch_size = args.batch_size*2,\n",
    "        shuffle = False,\n",
    "        num_workers = args.num_workers,\n",
    "        drop_last = False\n",
    "    )\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求解器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch import optim \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    def __init__(self,args):\n",
    "        self.args = args \n",
    "        self.train_loader,self.test_loader = get_loader(args)\n",
    "        \n",
    "        self.model = VisionTransformer(args).cuda()\n",
    "        \n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        print(\"----------------------Network----------------------------\")\n",
    "        print(self.model)\n",
    "        \n",
    "        if args.load_model:\n",
    "            print(\"using pretrained model\")\n",
    "            self.model.load_state_dict(torch.load(os.path.join(self.args.model_path,'Transformer.pt')))\n",
    "    \n",
    "    def test_dataset(self,db='test'):\n",
    "        self.model.eval()\n",
    "        \n",
    "        actual = []\n",
    "        pred = []\n",
    "        \n",
    "        if db.lower == 'train':\n",
    "            loader = self.train_loader\n",
    "        else:\n",
    "            loader = self.test_loader\n",
    "        \n",
    "        for (imgs,labels) in loader:\n",
    "            imgs = imgs.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                class_out = self.model(imgs)\n",
    "            \n",
    "            _,predicted = torch.max(class_out.data,1)\n",
    "            \n",
    "            actual += labels.tolist()\n",
    "            pred += predicted.tolist()\n",
    "        \n",
    "        acc = accuracy_score(y_true=actual,y_pred=pred)*100\n",
    "        cm = confusion_matrix(y_true=actual,y_pred=pred,labels=range(self.args.n_classes))\n",
    "        return acc,cm\n",
    "    \n",
    "    def test(self):\n",
    "        train_acc, cm = self.test_dataset('train')\n",
    "        print(\"Tr Acc: %.2f\" % train_acc)\n",
    "        print(cm)\n",
    "\n",
    "        test_acc, cm = self.test_dataset('test')\n",
    "        print(\"Te Acc: %.2f\" % test_acc)\n",
    "        print(cm)\n",
    "\n",
    "        return train_acc, test_acc\n",
    "    \n",
    "    def train(self):\n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        \n",
    "        optimizer = optim.AdamW(self.model.parameters(),self.args.lr,weight_decay=1e-3)\n",
    "        cos_decay = optim.lr_scheduler.CosineAnnealingLR(optimizer,self.args.epochs,verbose=True)\n",
    "        \n",
    "        for epoch in range(self.args.epochs):\n",
    "            self.model.train()\n",
    "            for i, (imgs, labels) in enumerate(self.train_loader):\n",
    "                imgs, labels = imgs.cuda(), labels.cuda()\n",
    "                logits = self.model(imgs)\n",
    "                clf_loss = self.ce(logits, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                clf_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if i % 50 == 0 or i == (iter_per_epoch - 1):\n",
    "                    print('Ep: %d/%d, it: %d/%d, err: %.4f' % (epoch + 1, self.args.epochs, i + 1, iter_per_epoch, clf_loss))\n",
    "            test_acc, cm = self.test_dataset('test')\n",
    "            print(\"Test acc: %0.2f\" % test_acc)\n",
    "            print(cm, \"\\n\")\n",
    "\n",
    "            cos_decay.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import datetime\n",
    "# import os \n",
    "\n",
    "# def main(args):\n",
    "#     os.makedirs(args.model_path,exist_ok=True)\n",
    "#     solver = Solver(args)\n",
    "#     solver.train()\n",
    "#     solver.test()\n",
    "\n",
    "# def print_args(args):\n",
    "#     for k in dict(sorted(vars(args).items())).items():\n",
    "#         print(k)\n",
    "#     print()\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Transformer')\n",
    "#     parser.add_argument('--epochs', type=int, default=200)\n",
    "#     parser.add_argument('--batch_size', type=int, default=128)\n",
    "#     parser.add_argument('--n_classes', type=int, default=10)\n",
    "#     parser.add_argument('--num_workers', type=int, default=4)\n",
    "#     parser.add_argument('--lr', type=float, default=5e-4)\n",
    "#     parser.add_argument('--log_step', type=int, default=50)\n",
    "\n",
    "#     parser.add_argument('--dset', type=str, default='mnist', help=['mnist', 'fmnist'])\n",
    "#     parser.add_argument(\"--img_size\", type=int, default=28, help=\"Img size\")\n",
    "#     parser.add_argument(\"--patch_size\", type=int, default=4, help=\"Patch Size\")\n",
    "#     parser.add_argument(\"--n_channels\", type=int, default=1, help=\"Number of channels\")\n",
    "#     parser.add_argument('--data_path', type=str, default='/media/liufeng/a0b205ec-bfb3-473f-a6f0-0680c5da64ba/project/MachineLearning_DeepLearning/data')\n",
    "#     parser.add_argument('--model_path', type=str, default='./model')\n",
    "\n",
    "#     parser.add_argument(\"--embed_dim\", type=int, default=96, help=\"dimensionality of the latent space\")\n",
    "#     parser.add_argument(\"--n_attention_heads\", type=int, default=4, help=\"number of heads to be used\")\n",
    "    \n",
    "#     parser.add_argument(\"--forward_mul\", type=int, default=2, help=\"forward multiplier\")\n",
    "#     parser.add_argument(\"--n_layers\", type=int, default=6, help=\"number of encoder layers\")\n",
    "#     parser.add_argument(\"--load_model\", type=bool, default=False, help=\"Load saved model\")\n",
    "\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     print(\"Started at \" + str(start_time.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "#     args = parser.parse_args(args=[])\n",
    "#     args.model_path = os.path.join(args.model_path, args.dset)\n",
    "#     print(args)\n",
    "    \n",
    "#     main(args)\n",
    "\n",
    "#     end_time = datetime.datetime.now()\n",
    "#     duration = end_time - start_time\n",
    "#     print(\"Ended at \" + str(end_time.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "#     print(\"Duration: \" + str(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2023-06-20 11:46:49\n",
      "Namespace(batch_size=128, data_path='/media/liufeng/a0b205ec-bfb3-473f-a6f0-0680c5da64ba/project/MachineLearning_DeepLearning/data', dset='mnist', embed_dim=96, epochs=200, forward_mul=2, img_size=28, load_model=False, log_step=50, lr=0.0005, model_path='./model/mnist', n_attention_heads=4, n_channels=1, n_classes=10, n_layers=6, num_workers=4, patch_size=4)\n",
      "----------------------Network----------------------------\n",
      "VisionTransformer(\n",
      "  (embedding): EmbedLayer(\n",
      "    (conv1): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (4): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Encoder(\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (keys): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (values): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (6): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  (classifier): Classifier(\n",
      "    (fc1): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (activation): Tanh()\n",
      "    (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Ep: 1/200, it: 1/468, err: 2.3103\n",
      "Ep: 1/200, it: 51/468, err: 1.6234\n",
      "Ep: 1/200, it: 101/468, err: 1.2953\n",
      "Ep: 1/200, it: 151/468, err: 1.1803\n",
      "Ep: 1/200, it: 201/468, err: 1.0323\n",
      "Ep: 1/200, it: 251/468, err: 0.9498\n",
      "Ep: 1/200, it: 301/468, err: 0.9230\n",
      "Ep: 1/200, it: 351/468, err: 0.8388\n",
      "Ep: 1/200, it: 401/468, err: 0.6678\n",
      "Ep: 1/200, it: 451/468, err: 0.6117\n",
      "Ep: 1/200, it: 468/468, err: 0.4301\n",
      "Test acc: 84.96\n",
      "[[ 914    1    4    0    3    5    8    1   36    8]\n",
      " [   1 1122    3    1    0    0    0    7    1    0]\n",
      " [  22    6  718   86    4   11    7   29  129   20]\n",
      " [   0    1    7  912    1   16    0   15   44   14]\n",
      " [   3   11    0    0  855    0    6    7    6   94]\n",
      " [   6   12    8  216    4  516    3    7   98   22]\n",
      " [  57   11    4    2   16    6  780    0   79    3]\n",
      " [   2   43   12   14    6    1    0  914    4   32]\n",
      " [  16    0    6   13    2    1    5    3  892   36]\n",
      " [   6    7    0    7   30    5    3   26   52  873]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9997e-04.\n",
      "Ep: 2/200, it: 1/468, err: 0.5687\n",
      "Ep: 2/200, it: 51/468, err: 0.3880\n",
      "Ep: 2/200, it: 101/468, err: 0.4390\n",
      "Ep: 2/200, it: 151/468, err: 0.3369\n",
      "Ep: 2/200, it: 201/468, err: 0.2943\n",
      "Ep: 2/200, it: 251/468, err: 0.3662\n",
      "Ep: 2/200, it: 301/468, err: 0.3263\n",
      "Ep: 2/200, it: 351/468, err: 0.2659\n",
      "Ep: 2/200, it: 401/468, err: 0.2681\n",
      "Ep: 2/200, it: 451/468, err: 0.2966\n",
      "Ep: 2/200, it: 468/468, err: 0.3586\n",
      "Test acc: 92.69\n",
      "[[ 968    0    2    0    0    0    7    1    1    1]\n",
      " [   2 1119    2    3    2    0    4    3    0    0]\n",
      " [  54    2  921   21    5    2    7    2   15    3]\n",
      " [   2    0    7  942    0   40    0    3   13    3]\n",
      " [   2    3    0    0  943    0   11    0    1   22]\n",
      " [   4    3    0   11    1  854   13    1    3    2]\n",
      " [  27    3    0    0    4    4  919    0    1    0]\n",
      " [   5   27   31   21    6    3    0  922    0   13]\n",
      " [  61    3    7   13    8   15   58    0  793   16]\n",
      " [  26    4    1    6   45    9    1   15   14  888]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9988e-04.\n",
      "Ep: 3/200, it: 1/468, err: 0.4053\n",
      "Ep: 3/200, it: 51/468, err: 0.2619\n",
      "Ep: 3/200, it: 101/468, err: 0.2999\n",
      "Ep: 3/200, it: 151/468, err: 0.3174\n",
      "Ep: 3/200, it: 201/468, err: 0.3419\n",
      "Ep: 3/200, it: 251/468, err: 0.2908\n",
      "Ep: 3/200, it: 301/468, err: 0.2254\n",
      "Ep: 3/200, it: 351/468, err: 0.2207\n",
      "Ep: 3/200, it: 401/468, err: 0.2344\n",
      "Ep: 3/200, it: 451/468, err: 0.2134\n",
      "Ep: 3/200, it: 468/468, err: 0.1788\n",
      "Test acc: 95.13\n",
      "[[ 942    0   18    1    0    3    2    0   11    3]\n",
      " [   0 1115    1    5    2    0    2   10    0    0]\n",
      " [   3    1  989   17    1    0    2    8    9    2]\n",
      " [   0    0    3  990    0    5    0    5    6    1]\n",
      " [   2    3    0    0  929    0    5    1    4   38]\n",
      " [   1    2    1   41    0  826    0    1   17    3]\n",
      " [  21    7   14    0    8   15  878    0   14    1]\n",
      " [   1    2    9   13    0    1    0  991    0   11]\n",
      " [   5    0    9   15    1    6    4    6  916   12]\n",
      " [   6    1    1   11   12    9    0   16   16  937]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9972e-04.\n",
      "Ep: 4/200, it: 1/468, err: 0.1563\n",
      "Ep: 4/200, it: 51/468, err: 0.2238\n",
      "Ep: 4/200, it: 101/468, err: 0.2401\n",
      "Ep: 4/200, it: 151/468, err: 0.1728\n",
      "Ep: 4/200, it: 201/468, err: 0.1674\n",
      "Ep: 4/200, it: 251/468, err: 0.2567\n",
      "Ep: 4/200, it: 301/468, err: 0.1790\n",
      "Ep: 4/200, it: 351/468, err: 0.1742\n",
      "Ep: 4/200, it: 401/468, err: 0.0940\n",
      "Ep: 4/200, it: 451/468, err: 0.1130\n",
      "Ep: 4/200, it: 468/468, err: 0.1419\n",
      "Test acc: 94.78\n",
      "[[ 970    0    6    0    0    0    2    1    0    1]\n",
      " [   0 1114    8    1    2    0    5    0    5    0]\n",
      " [   6    0 1016    0    0    0    2    1    6    1]\n",
      " [   2    0   69  887    0   16    0    8   24    4]\n",
      " [   2    1    1    0  921    0   10    2    8   37]\n",
      " [  16    3    6   18    0  783   20    2   36    8]\n",
      " [  10    1    0    0    2    0  938    0    6    1]\n",
      " [   5   10   21    3    5    2    0  969    2   11]\n",
      " [  12    0   16    0    0    0    9    2  931    4]\n",
      " [   8    1    0    0   11    1    1    2   36  949]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9951e-04.\n",
      "Ep: 5/200, it: 1/468, err: 0.2208\n",
      "Ep: 5/200, it: 51/468, err: 0.3036\n",
      "Ep: 5/200, it: 101/468, err: 0.1407\n",
      "Ep: 5/200, it: 151/468, err: 0.0887\n",
      "Ep: 5/200, it: 201/468, err: 0.1959\n",
      "Ep: 5/200, it: 251/468, err: 0.1834\n",
      "Ep: 5/200, it: 301/468, err: 0.0277\n",
      "Ep: 5/200, it: 351/468, err: 0.2070\n",
      "Ep: 5/200, it: 401/468, err: 0.1999\n",
      "Ep: 5/200, it: 451/468, err: 0.2329\n",
      "Ep: 5/200, it: 468/468, err: 0.1144\n",
      "Test acc: 97.19\n",
      "[[ 963    0    8    0    2    0    3    1    2    1]\n",
      " [   0 1121    3    2    2    0    1    5    0    1]\n",
      " [   1    1 1015    1    2    0    0   10    2    0]\n",
      " [   0    0    5  991    0   10    0    2    1    1]\n",
      " [   1    2    0    0  953    0    1    0    1   24]\n",
      " [   2    0    2   14    0  866    3    1    2    2]\n",
      " [   5    4    6    0    1    7  934    0    0    1]\n",
      " [   1    2    5    5    1    0    0  998    0   16]\n",
      " [   6    0   16   19    3    4    8    2  900   16]\n",
      " [   5    1    0    1    9    4    0    6    5  978]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9923e-04.\n",
      "Ep: 6/200, it: 1/468, err: 0.0501\n",
      "Ep: 6/200, it: 51/468, err: 0.1481\n",
      "Ep: 6/200, it: 101/468, err: 0.1107\n",
      "Ep: 6/200, it: 151/468, err: 0.0895\n",
      "Ep: 6/200, it: 201/468, err: 0.1039\n",
      "Ep: 6/200, it: 251/468, err: 0.2571\n",
      "Ep: 6/200, it: 301/468, err: 0.1591\n",
      "Ep: 6/200, it: 351/468, err: 0.0998\n",
      "Ep: 6/200, it: 401/468, err: 0.0479\n",
      "Ep: 6/200, it: 451/468, err: 0.0746\n",
      "Ep: 6/200, it: 468/468, err: 0.1287\n",
      "Test acc: 97.02\n",
      "[[ 955    0    9    0    1    0    7    1    6    1]\n",
      " [   0 1110    7    1    2    0    2    9    3    1]\n",
      " [   0    0 1021    1    1    0    1    5    3    0]\n",
      " [   0    0   10  992    0    6    0    0    1    1]\n",
      " [   1    0    0    0  945    0    3    0    1   32]\n",
      " [   1    1    1   31    0  843    2    1    8    4]\n",
      " [   0    3    4    0    2    4  938    0    6    1]\n",
      " [   0    0   18    4    4    0    0  990    1   11]\n",
      " [   5    0   23    3    5    2    6    4  919    7]\n",
      " [   0    0    0    0    9    2    0    2    7  989]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9889e-04.\n",
      "Ep: 7/200, it: 1/468, err: 0.0823\n",
      "Ep: 7/200, it: 51/468, err: 0.1177\n",
      "Ep: 7/200, it: 101/468, err: 0.2091\n",
      "Ep: 7/200, it: 151/468, err: 0.2076\n",
      "Ep: 7/200, it: 201/468, err: 0.1077\n",
      "Ep: 7/200, it: 251/468, err: 0.0916\n",
      "Ep: 7/200, it: 301/468, err: 0.0854\n",
      "Ep: 7/200, it: 351/468, err: 0.1618\n",
      "Ep: 7/200, it: 401/468, err: 0.1896\n",
      "Ep: 7/200, it: 451/468, err: 0.1837\n",
      "Ep: 7/200, it: 468/468, err: 0.0980\n",
      "Test acc: 97.08\n",
      "[[ 971    0    3    0    1    0    2    1    1    1]\n",
      " [   0 1118    1    0    0    0   10    5    1    0]\n",
      " [   4    1  993    3    4    1    2   18    4    2]\n",
      " [   0    0    7  966    0   12    0   16    4    5]\n",
      " [   0    1    0    0  940    0    6    1    3   31]\n",
      " [   4    1    2    6    0  866    5    3    4    1]\n",
      " [  17    1    0    0    2    3  934    0    0    1]\n",
      " [   0    3    0    1    0    0    0 1018    0    6]\n",
      " [  12    0    6    3    0    6   16    2  925    4]\n",
      " [   1    5    0    0    7    3    0    3   13  977]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9849e-04.\n",
      "Ep: 8/200, it: 1/468, err: 0.1535\n",
      "Ep: 8/200, it: 51/468, err: 0.0855\n",
      "Ep: 8/200, it: 101/468, err: 0.1164\n",
      "Ep: 8/200, it: 151/468, err: 0.1694\n",
      "Ep: 8/200, it: 201/468, err: 0.0916\n",
      "Ep: 8/200, it: 251/468, err: 0.0569\n",
      "Ep: 8/200, it: 301/468, err: 0.0904\n",
      "Ep: 8/200, it: 351/468, err: 0.1471\n",
      "Ep: 8/200, it: 401/468, err: 0.0690\n",
      "Ep: 8/200, it: 451/468, err: 0.0974\n",
      "Ep: 8/200, it: 468/468, err: 0.1178\n",
      "Test acc: 97.39\n",
      "[[ 974    0    2    0    0    0    3    1    0    0]\n",
      " [   0 1122    2    0    1    1    1    6    2    0]\n",
      " [   4    0 1017    1    1    0    1    4    3    1]\n",
      " [   0    1    5  987    0    7    0    1    4    5]\n",
      " [   0    2    0    0  961    0    6    0    2   11]\n",
      " [   3    2    3   12    1  849    4    2   12    4]\n",
      " [   7    5    2    1    3    3  929    0    7    1]\n",
      " [   1    1   11    5   10    0    0  987    1   12]\n",
      " [   4    0   15    2    0    4    0    2  944    3]\n",
      " [   4    0    0    0   21    2    2    3    8  969]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9803e-04.\n",
      "Ep: 9/200, it: 1/468, err: 0.0524\n",
      "Ep: 9/200, it: 51/468, err: 0.0697\n",
      "Ep: 9/200, it: 101/468, err: 0.0732\n",
      "Ep: 9/200, it: 151/468, err: 0.1507\n",
      "Ep: 9/200, it: 201/468, err: 0.1243\n",
      "Ep: 9/200, it: 251/468, err: 0.0818\n",
      "Ep: 9/200, it: 301/468, err: 0.0751\n",
      "Ep: 9/200, it: 351/468, err: 0.0782\n",
      "Ep: 9/200, it: 401/468, err: 0.1614\n",
      "Ep: 9/200, it: 451/468, err: 0.0797\n",
      "Ep: 9/200, it: 468/468, err: 0.1110\n",
      "Test acc: 97.35\n",
      "[[ 957    0    4    0    0    2    9    1    7    0]\n",
      " [   0 1088    2    1    5    1    6   17    5   10]\n",
      " [   0    0  988   15    1    1    1   13   13    0]\n",
      " [   0    0    0  996    0    7    0    3    3    1]\n",
      " [   0    0    2    0  947    0    2    5    4   22]\n",
      " [   1    0    1   10    0  874    1    2    1    2]\n",
      " [   4    2    2    1    2    5  937    0    4    1]\n",
      " [   0    0    0    5    1    0    0 1008    2   12]\n",
      " [   1    0    1    2    0    3    1    2  961    3]\n",
      " [   1    0    0    3    6    1    0    5   14  979]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9751e-04.\n",
      "Ep: 10/200, it: 1/468, err: 0.0980\n",
      "Ep: 10/200, it: 51/468, err: 0.1622\n",
      "Ep: 10/200, it: 101/468, err: 0.1540\n",
      "Ep: 10/200, it: 151/468, err: 0.0848\n",
      "Ep: 10/200, it: 201/468, err: 0.0650\n",
      "Ep: 10/200, it: 251/468, err: 0.1474\n",
      "Ep: 10/200, it: 301/468, err: 0.0796\n",
      "Ep: 10/200, it: 351/468, err: 0.0985\n",
      "Ep: 10/200, it: 401/468, err: 0.0904\n",
      "Ep: 10/200, it: 451/468, err: 0.0330\n",
      "Ep: 10/200, it: 468/468, err: 0.0603\n",
      "Test acc: 98.00\n",
      "[[ 975    0    3    0    0    0    1    1    0    0]\n",
      " [   0 1127    3    0    1    0    0    3    1    0]\n",
      " [   0    0 1025    2    0    0    1    4    0    0]\n",
      " [   0    0    8  985    0    2    0    7    7    1]\n",
      " [   0    3    0    0  950    0    5   11    0   13]\n",
      " [   1    1    1   10    0  867    2    3    6    1]\n",
      " [   2    5    3    0    0    3  944    0    1    0]\n",
      " [   0    1   15    0    1    1    0 1007    1    2]\n",
      " [   4    0   10    0    0    1    3    1  953    2]\n",
      " [   1    0    0    1    9    4    0   11   16  967]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9692e-04.\n",
      "Ep: 11/200, it: 1/468, err: 0.0763\n",
      "Ep: 11/200, it: 51/468, err: 0.0673\n",
      "Ep: 11/200, it: 101/468, err: 0.0623\n",
      "Ep: 11/200, it: 151/468, err: 0.1330\n",
      "Ep: 11/200, it: 201/468, err: 0.0950\n",
      "Ep: 11/200, it: 251/468, err: 0.0667\n",
      "Ep: 11/200, it: 301/468, err: 0.0611\n",
      "Ep: 11/200, it: 351/468, err: 0.0642\n",
      "Ep: 11/200, it: 401/468, err: 0.0733\n",
      "Ep: 11/200, it: 451/468, err: 0.0420\n",
      "Ep: 11/200, it: 468/468, err: 0.0462\n",
      "Test acc: 97.94\n",
      "[[ 977    0    0    0    0    0    0    1    0    2]\n",
      " [   0 1133    1    0    0    0    0    1    0    0]\n",
      " [   4    3 1000    8    3    1    1   10    1    1]\n",
      " [   0    1    1 1001    0    4    0    1    0    2]\n",
      " [   0    1    0    0  963    0    0    1    0   17]\n",
      " [   2    2    0   11    0  870    2    1    1    3]\n",
      " [   8    6    0    0    5    2  936    0    0    1]\n",
      " [   0    2    1    3    2    0    0 1019    0    1]\n",
      " [  13    5    3    8    0    5    6    2  904   28]\n",
      " [   1    2    0    3    6    0    0    5    1  991]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9628e-04.\n",
      "Ep: 12/200, it: 1/468, err: 0.0639\n",
      "Ep: 12/200, it: 51/468, err: 0.1566\n",
      "Ep: 12/200, it: 101/468, err: 0.2044\n",
      "Ep: 12/200, it: 151/468, err: 0.1098\n",
      "Ep: 12/200, it: 201/468, err: 0.1910\n",
      "Ep: 12/200, it: 251/468, err: 0.0571\n",
      "Ep: 12/200, it: 301/468, err: 0.1234\n",
      "Ep: 12/200, it: 351/468, err: 0.0700\n",
      "Ep: 12/200, it: 401/468, err: 0.0443\n",
      "Ep: 12/200, it: 451/468, err: 0.1070\n",
      "Ep: 12/200, it: 468/468, err: 0.1582\n",
      "Test acc: 97.93\n",
      "[[ 965    0    1    0    1    0    5    1    3    4]\n",
      " [   0 1120    1    1    1    2    1    8    1    0]\n",
      " [   0    0 1002    5    1    0    3   17    3    1]\n",
      " [   0    0    1  989    0   13    0    5    2    0]\n",
      " [   0    1    0    0  970    0    5    1    1    4]\n",
      " [   1    0    0    1    0  882    2    2    4    0]\n",
      " [   2    4    0    0    2    3  943    0    3    1]\n",
      " [   0    0    1    1    3    1    0 1019    1    2]\n",
      " [   1    0    3    8    1    4    4    5  948    0]\n",
      " [   0    1    0    2   36    3    0    5    7  955]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9557e-04.\n",
      "Ep: 13/200, it: 1/468, err: 0.0584\n",
      "Ep: 13/200, it: 51/468, err: 0.0879\n",
      "Ep: 13/200, it: 101/468, err: 0.1287\n",
      "Ep: 13/200, it: 151/468, err: 0.2127\n",
      "Ep: 13/200, it: 201/468, err: 0.0447\n",
      "Ep: 13/200, it: 251/468, err: 0.1274\n",
      "Ep: 13/200, it: 301/468, err: 0.0741\n",
      "Ep: 13/200, it: 351/468, err: 0.0495\n",
      "Ep: 13/200, it: 401/468, err: 0.0735\n",
      "Ep: 13/200, it: 451/468, err: 0.0241\n",
      "Ep: 13/200, it: 468/468, err: 0.1306\n",
      "Test acc: 98.44\n",
      "[[ 976    0    1    0    0    0    1    1    1    0]\n",
      " [   0 1125    2    1    0    0    3    3    1    0]\n",
      " [   0    0 1025    2    0    0    0    4    1    0]\n",
      " [   0    0    1 1002    0    2    0    4    1    0]\n",
      " [   1    0    0    0  958    0    5    3    1   14]\n",
      " [   2    0    2    9    0  872    2    3    0    2]\n",
      " [   3    3    0    0    4    7  940    0    1    0]\n",
      " [   0    0    6    2    0    0    0 1020    0    0]\n",
      " [   4    1    3    3    1    3    2    0  954    3]\n",
      " [   0    1    1    4   10    4    0   11    6  972]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9481e-04.\n",
      "Ep: 14/200, it: 1/468, err: 0.0265\n",
      "Ep: 14/200, it: 51/468, err: 0.1070\n",
      "Ep: 14/200, it: 101/468, err: 0.1150\n",
      "Ep: 14/200, it: 151/468, err: 0.0601\n",
      "Ep: 14/200, it: 201/468, err: 0.0909\n",
      "Ep: 14/200, it: 251/468, err: 0.0729\n",
      "Ep: 14/200, it: 301/468, err: 0.0703\n",
      "Ep: 14/200, it: 351/468, err: 0.0639\n",
      "Ep: 14/200, it: 401/468, err: 0.0341\n",
      "Ep: 14/200, it: 451/468, err: 0.0884\n",
      "Ep: 14/200, it: 468/468, err: 0.0450\n",
      "Test acc: 98.30\n",
      "[[ 974    0    0    1    0    1    2    1    1    0]\n",
      " [   0 1115    1    1    0    0    3    4   10    1]\n",
      " [   0    0 1023    2    0    0    0    4    3    0]\n",
      " [   0    1    0 1002    0    6    0    0    0    1]\n",
      " [   0    0    0    0  949    0    2    1    6   24]\n",
      " [   2    0    0    5    0  875    2    2    2    4]\n",
      " [   4    2    0    0    2    4  945    0    1    0]\n",
      " [   0    3    5    6    0    1    0  996    2   15]\n",
      " [   1    0    1    7    0    3    1    0  960    1]\n",
      " [   0    0    0    1    4    4    0    2    7  991]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9398e-04.\n",
      "Ep: 15/200, it: 1/468, err: 0.0437\n",
      "Ep: 15/200, it: 51/468, err: 0.0237\n",
      "Ep: 15/200, it: 101/468, err: 0.0909\n",
      "Ep: 15/200, it: 151/468, err: 0.0714\n",
      "Ep: 15/200, it: 201/468, err: 0.0326\n",
      "Ep: 15/200, it: 251/468, err: 0.0499\n",
      "Ep: 15/200, it: 301/468, err: 0.0440\n",
      "Ep: 15/200, it: 351/468, err: 0.0215\n",
      "Ep: 15/200, it: 401/468, err: 0.0279\n",
      "Ep: 15/200, it: 451/468, err: 0.1052\n",
      "Ep: 15/200, it: 468/468, err: 0.0210\n",
      "Test acc: 98.40\n",
      "[[ 976    0    2    0    0    0    1    1    0    0]\n",
      " [   1 1127    1    1    0    0    2    3    0    0]\n",
      " [   0    0 1026    0    1    0    0    4    1    0]\n",
      " [   0    1    3  999    0    0    0    3    3    1]\n",
      " [   0    1    0    0  960    0    3    1    2   15]\n",
      " [   2    1    0   19    0  851    2    4   11    2]\n",
      " [   6    5    0    0    4    0  943    0    0    0]\n",
      " [   0    3    3    1    2    0    0 1017    0    2]\n",
      " [   3    0    4    3    0    0    3    3  957    1]\n",
      " [   0    2    0    1   10    4    0    2    6  984]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9309e-04.\n",
      "Ep: 16/200, it: 1/468, err: 0.0724\n",
      "Ep: 16/200, it: 51/468, err: 0.0196\n",
      "Ep: 16/200, it: 101/468, err: 0.0577\n",
      "Ep: 16/200, it: 151/468, err: 0.0439\n",
      "Ep: 16/200, it: 201/468, err: 0.0073\n",
      "Ep: 16/200, it: 251/468, err: 0.1097\n",
      "Ep: 16/200, it: 301/468, err: 0.0535\n",
      "Ep: 16/200, it: 351/468, err: 0.0423\n",
      "Ep: 16/200, it: 401/468, err: 0.0685\n",
      "Ep: 16/200, it: 451/468, err: 0.1547\n",
      "Ep: 16/200, it: 468/468, err: 0.0710\n",
      "Test acc: 98.36\n",
      "[[ 973    0    0    1    0    0    3    1    1    1]\n",
      " [   0 1125    0    2    1    0    5    1    1    0]\n",
      " [   0    0 1017    5    1    0    0    4    5    0]\n",
      " [   0    0    0 1007    0    2    0    1    0    0]\n",
      " [   0    1    0    0  962    0    6    1    0   12]\n",
      " [   4    0    0    6    1  878    1    2    0    0]\n",
      " [   1    0    0    0    0    8  949    0    0    0]\n",
      " [   0    3   13    2    1    0    0 1007    2    0]\n",
      " [   1    0    2    4    0    4    5    0  955    3]\n",
      " [   0    2    0    3   14    4    0   11   12  963]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9215e-04.\n",
      "Ep: 17/200, it: 1/468, err: 0.0847\n",
      "Ep: 17/200, it: 51/468, err: 0.0383\n",
      "Ep: 17/200, it: 101/468, err: 0.0121\n",
      "Ep: 17/200, it: 151/468, err: 0.1338\n",
      "Ep: 17/200, it: 201/468, err: 0.1022\n",
      "Ep: 17/200, it: 251/468, err: 0.0460\n",
      "Ep: 17/200, it: 301/468, err: 0.0404\n",
      "Ep: 17/200, it: 351/468, err: 0.0438\n",
      "Ep: 17/200, it: 401/468, err: 0.0579\n",
      "Ep: 17/200, it: 451/468, err: 0.0950\n",
      "Ep: 17/200, it: 468/468, err: 0.0646\n",
      "Test acc: 98.60\n",
      "[[ 967    0    5    0    0    0    2    1    5    0]\n",
      " [   0 1121    1    1    1    0    3    3    5    0]\n",
      " [   1    1 1025    1    0    0    0    4    0    0]\n",
      " [   0    0    2 1004    0    3    0    0    1    0]\n",
      " [   0    0    3    0  966    0    1    1    1   10]\n",
      " [   1    0    1    9    0  876    1    1    1    2]\n",
      " [   1    5    1    0    4    3  942    0    2    0]\n",
      " [   0    2   10    2    0    0    0 1005    1    8]\n",
      " [   0    0    2    1    0    1    2    0  966    2]\n",
      " [   0    0    1    2   11    3    0    2    2  988]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9114e-04.\n",
      "Ep: 18/200, it: 1/468, err: 0.0669\n",
      "Ep: 18/200, it: 51/468, err: 0.0980\n",
      "Ep: 18/200, it: 101/468, err: 0.0373\n",
      "Ep: 18/200, it: 151/468, err: 0.1122\n",
      "Ep: 18/200, it: 201/468, err: 0.1112\n",
      "Ep: 18/200, it: 251/468, err: 0.0145\n",
      "Ep: 18/200, it: 301/468, err: 0.0428\n",
      "Ep: 18/200, it: 351/468, err: 0.0769\n",
      "Ep: 18/200, it: 401/468, err: 0.0131\n",
      "Ep: 18/200, it: 451/468, err: 0.0630\n",
      "Ep: 18/200, it: 468/468, err: 0.1261\n",
      "Test acc: 98.44\n",
      "[[ 969    0    2    1    1    1    3    1    2    0]\n",
      " [   0 1127    2    0    1    0    5    0    0    0]\n",
      " [   0    2 1020    2    1    0    0    4    3    0]\n",
      " [   0    1    1  996    0    8    0    1    3    0]\n",
      " [   0    0    0    0  975    0    6    1    0    0]\n",
      " [   2    0    0    1    0  886    2    1    0    0]\n",
      " [   2    2    0    0    0    5  948    0    1    0]\n",
      " [   0    3    3    1    3    1    0 1017    0    0]\n",
      " [   0    0    2    5    1    4    3    0  958    1]\n",
      " [   0    1    0    1   41    4    0   12    2  948]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9007e-04.\n",
      "Ep: 19/200, it: 1/468, err: 0.1236\n",
      "Ep: 19/200, it: 51/468, err: 0.0629\n",
      "Ep: 19/200, it: 101/468, err: 0.0289\n",
      "Ep: 19/200, it: 151/468, err: 0.0992\n",
      "Ep: 19/200, it: 201/468, err: 0.0101\n",
      "Ep: 19/200, it: 251/468, err: 0.1038\n",
      "Ep: 19/200, it: 301/468, err: 0.0657\n",
      "Ep: 19/200, it: 351/468, err: 0.0667\n",
      "Ep: 19/200, it: 401/468, err: 0.0823\n",
      "Ep: 19/200, it: 451/468, err: 0.1278\n",
      "Ep: 19/200, it: 468/468, err: 0.0413\n",
      "Test acc: 98.66\n",
      "[[ 973    0    4    0    0    0    1    1    1    0]\n",
      " [   0 1125    3    0    1    0    2    3    1    0]\n",
      " [   0    0 1028    0    1    0    0    1    2    0]\n",
      " [   0    1    8  991    0    7    0    0    3    0]\n",
      " [   0    0    1    0  974    0    3    0    1    3]\n",
      " [   2    0    1    9    0  878    1    1    0    0]\n",
      " [   3    1    0    0    4    2  947    0    1    0]\n",
      " [   0    3   11    3    0    0    0 1009    0    2]\n",
      " [   0    0    4    2    0    1    0    1  965    1]\n",
      " [   0    1    3    6    9    7    0    3    4  976]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8895e-04.\n",
      "Ep: 20/200, it: 1/468, err: 0.0604\n",
      "Ep: 20/200, it: 51/468, err: 0.0188\n",
      "Ep: 20/200, it: 101/468, err: 0.0465\n",
      "Ep: 20/200, it: 151/468, err: 0.0067\n",
      "Ep: 20/200, it: 201/468, err: 0.0581\n",
      "Ep: 20/200, it: 251/468, err: 0.0428\n",
      "Ep: 20/200, it: 301/468, err: 0.0225\n",
      "Ep: 20/200, it: 351/468, err: 0.0976\n",
      "Ep: 20/200, it: 401/468, err: 0.1040\n",
      "Ep: 20/200, it: 451/468, err: 0.0698\n",
      "Ep: 20/200, it: 468/468, err: 0.0755\n",
      "Test acc: 98.35\n",
      "[[ 975    0    2    0    0    0    1    2    0    0]\n",
      " [   1 1124    1    1    0    0    1    6    1    0]\n",
      " [   1    1 1016    9    0    0    1    1    3    0]\n",
      " [   0    0    0 1007    0    1    0    1    1    0]\n",
      " [   0    0    1    0  954    0    3    1    3   20]\n",
      " [   4    0    0   22    0  858    1    2    2    3]\n",
      " [   2    0    2    1    2    2  943    0    6    0]\n",
      " [   0    1    3    8    1    0    0 1015    0    0]\n",
      " [   1    0    2   10    0    1    1    1  956    2]\n",
      " [   0    0    1    5    3    2    0    6    5  987]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8776e-04.\n",
      "Ep: 21/200, it: 1/468, err: 0.0401\n",
      "Ep: 21/200, it: 51/468, err: 0.0094\n",
      "Ep: 21/200, it: 101/468, err: 0.0282\n",
      "Ep: 21/200, it: 151/468, err: 0.0246\n",
      "Ep: 21/200, it: 201/468, err: 0.0276\n",
      "Ep: 21/200, it: 251/468, err: 0.0523\n",
      "Ep: 21/200, it: 301/468, err: 0.0610\n",
      "Ep: 21/200, it: 351/468, err: 0.0757\n",
      "Ep: 21/200, it: 401/468, err: 0.0421\n",
      "Ep: 21/200, it: 451/468, err: 0.0280\n",
      "Ep: 21/200, it: 468/468, err: 0.0170\n",
      "Test acc: 98.75\n",
      "[[ 966    0    0    0    0    0    7    1    6    0]\n",
      " [   0 1123    1    0    0    1    3    5    1    1]\n",
      " [   2    3 1010    3    1    1    0    9    3    0]\n",
      " [   0    0    0 1001    0    5    0    0    2    2]\n",
      " [   0    1    0    0  965    0    7    0    1    8]\n",
      " [   1    0    0    3    0  878    8    1    1    0]\n",
      " [   2    1    0    0    0    2  952    0    1    0]\n",
      " [   0    1    3    4    1    0    0 1017    0    2]\n",
      " [   0    0    1    0    0    1    0    2  968    2]\n",
      " [   0    0    0    2    6    4    0    2    0  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8652e-04.\n",
      "Ep: 22/200, it: 1/468, err: 0.0184\n",
      "Ep: 22/200, it: 51/468, err: 0.0231\n",
      "Ep: 22/200, it: 101/468, err: 0.0312\n",
      "Ep: 22/200, it: 151/468, err: 0.0151\n",
      "Ep: 22/200, it: 201/468, err: 0.0740\n",
      "Ep: 22/200, it: 251/468, err: 0.0179\n",
      "Ep: 22/200, it: 301/468, err: 0.0277\n",
      "Ep: 22/200, it: 351/468, err: 0.0803\n",
      "Ep: 22/200, it: 401/468, err: 0.0081\n",
      "Ep: 22/200, it: 451/468, err: 0.0934\n",
      "Ep: 22/200, it: 468/468, err: 0.0339\n",
      "Test acc: 98.64\n",
      "[[ 972    0    0    1    0    5    1    1    0    0]\n",
      " [   0 1129    1    1    0    0    0    3    0    1]\n",
      " [   1    0 1022    3    1    0    1    3    1    0]\n",
      " [   0    0    1 1002    0    6    0    0    1    0]\n",
      " [   1    0    0    0  967    0    3    2    1    8]\n",
      " [   0    0    0    2    0  887    1    2    0    0]\n",
      " [   4    4    0    0    1    4  944    0    1    0]\n",
      " [   1    2   15    2    0    0    0 1005    0    3]\n",
      " [   1    0    3    5    0    6    4    2  951    2]\n",
      " [   0    2    1    2    8    8    0    1    2  985]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8522e-04.\n",
      "Ep: 23/200, it: 1/468, err: 0.0441\n",
      "Ep: 23/200, it: 51/468, err: 0.0399\n",
      "Ep: 23/200, it: 101/468, err: 0.0470\n",
      "Ep: 23/200, it: 151/468, err: 0.0370\n",
      "Ep: 23/200, it: 201/468, err: 0.0451\n",
      "Ep: 23/200, it: 251/468, err: 0.0102\n",
      "Ep: 23/200, it: 301/468, err: 0.0074\n",
      "Ep: 23/200, it: 351/468, err: 0.0365\n",
      "Ep: 23/200, it: 401/468, err: 0.0252\n",
      "Ep: 23/200, it: 451/468, err: 0.0479\n",
      "Ep: 23/200, it: 468/468, err: 0.0486\n",
      "Test acc: 98.74\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1121    1    2    4    0    2    4    1    0]\n",
      " [   5    0 1019    3    0    0    0    0    5    0]\n",
      " [   0    1    0 1007    0    2    0    0    0    0]\n",
      " [   0    0    0    0  972    0    5    1    0    4]\n",
      " [   3    0    0    6    0  880    0    3    0    0]\n",
      " [   3    2    0    0    1    6  943    0    3    0]\n",
      " [   0    5    9    1    0    0    0 1013    0    0]\n",
      " [   3    0    2    5    0    4    1    1  957    1]\n",
      " [   0    0    1    6    9    4    0    3    1  985]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8386e-04.\n",
      "Ep: 24/200, it: 1/468, err: 0.0335\n",
      "Ep: 24/200, it: 51/468, err: 0.0441\n",
      "Ep: 24/200, it: 101/468, err: 0.0309\n",
      "Ep: 24/200, it: 151/468, err: 0.0430\n",
      "Ep: 24/200, it: 201/468, err: 0.0153\n",
      "Ep: 24/200, it: 251/468, err: 0.0551\n",
      "Ep: 24/200, it: 301/468, err: 0.0446\n",
      "Ep: 24/200, it: 351/468, err: 0.0394\n",
      "Ep: 24/200, it: 401/468, err: 0.0672\n",
      "Ep: 24/200, it: 451/468, err: 0.0227\n",
      "Ep: 24/200, it: 468/468, err: 0.1220\n",
      "Test acc: 98.54\n",
      "[[ 968    0    4    0    0    0    4    3    1    0]\n",
      " [   0 1130    1    1    0    0    1    2    0    0]\n",
      " [   0    0 1025    0    0    0    0    4    3    0]\n",
      " [   0    1    3  995    0    2    0    3    6    0]\n",
      " [   0    1    0    0  968    0    3    4    1    5]\n",
      " [   2    0    0    4    0  882    1    3    0    0]\n",
      " [   2    4    2    0    2    5  941    0    2    0]\n",
      " [   0    2    5    3    0    0    0 1018    0    0]\n",
      " [   0    0    4    3    0    5    1    2  955    4]\n",
      " [   0    4    0    2   11    6    0   10    4  972]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8244e-04.\n",
      "Ep: 25/200, it: 1/468, err: 0.0512\n",
      "Ep: 25/200, it: 51/468, err: 0.0424\n",
      "Ep: 25/200, it: 101/468, err: 0.0341\n",
      "Ep: 25/200, it: 151/468, err: 0.0656\n",
      "Ep: 25/200, it: 201/468, err: 0.0418\n",
      "Ep: 25/200, it: 251/468, err: 0.0795\n",
      "Ep: 25/200, it: 301/468, err: 0.0221\n",
      "Ep: 25/200, it: 351/468, err: 0.0651\n",
      "Ep: 25/200, it: 401/468, err: 0.0333\n",
      "Ep: 25/200, it: 451/468, err: 0.0180\n",
      "Ep: 25/200, it: 468/468, err: 0.0627\n",
      "Test acc: 98.61\n",
      "[[ 976    0    0    0    0    0    2    2    0    0]\n",
      " [   0 1131    1    1    0    0    0    2    0    0]\n",
      " [   4    0 1007    0    0    0    0   16    5    0]\n",
      " [   0    1    2  996    0    3    0    2    5    1]\n",
      " [   1    0    0    0  968    0    5    2    0    6]\n",
      " [   2    0    0    7    0  874    2    2    1    4]\n",
      " [   7    6    2    0    0    1  941    0    1    0]\n",
      " [   0    7    1    2    1    0    0 1014    0    3]\n",
      " [   8    0    2    0    0    1    1    1  956    5]\n",
      " [   1    0    0    1    5    0    0    3    1  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8097e-04.\n",
      "Ep: 26/200, it: 1/468, err: 0.0453\n",
      "Ep: 26/200, it: 51/468, err: 0.0271\n",
      "Ep: 26/200, it: 101/468, err: 0.0293\n",
      "Ep: 26/200, it: 151/468, err: 0.0569\n",
      "Ep: 26/200, it: 201/468, err: 0.0489\n",
      "Ep: 26/200, it: 251/468, err: 0.0329\n",
      "Ep: 26/200, it: 301/468, err: 0.0813\n",
      "Ep: 26/200, it: 351/468, err: 0.0632\n",
      "Ep: 26/200, it: 401/468, err: 0.0493\n",
      "Ep: 26/200, it: 451/468, err: 0.0234\n",
      "Ep: 26/200, it: 468/468, err: 0.0048\n",
      "Test acc: 98.73\n",
      "[[ 976    0    0    0    1    0    2    1    0    0]\n",
      " [   0 1130    1    1    0    0    3    0    0    0]\n",
      " [   1    0 1027    1    1    0    0    2    0    0]\n",
      " [   0    1    0 1005    0    3    0    0    1    0]\n",
      " [   0    0    0    0  972    0    4    0    0    6]\n",
      " [   5    0    0    5    0  875    3    3    0    1]\n",
      " [   2    1    0    0    1    2  951    0    1    0]\n",
      " [   0    6    7    1    1    0    0 1012    0    1]\n",
      " [   5    0    5    3    0    3    6    3  946    3]\n",
      " [   1    3    2    1   12    4    0    4    3  979]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7944e-04.\n",
      "Ep: 27/200, it: 1/468, err: 0.0314\n",
      "Ep: 27/200, it: 51/468, err: 0.0201\n",
      "Ep: 27/200, it: 101/468, err: 0.0870\n",
      "Ep: 27/200, it: 151/468, err: 0.0898\n",
      "Ep: 27/200, it: 201/468, err: 0.0195\n",
      "Ep: 27/200, it: 251/468, err: 0.0188\n",
      "Ep: 27/200, it: 301/468, err: 0.0578\n",
      "Ep: 27/200, it: 351/468, err: 0.0135\n",
      "Ep: 27/200, it: 401/468, err: 0.0575\n",
      "Ep: 27/200, it: 451/468, err: 0.1632\n",
      "Ep: 27/200, it: 468/468, err: 0.0558\n",
      "Test acc: 98.92\n",
      "[[ 976    0    2    0    0    1    0    1    0    0]\n",
      " [   0 1130    1    0    0    0    2    2    0    0]\n",
      " [   0    0 1024    1    1    0    0    5    1    0]\n",
      " [   1    2    3  999    0    1    0    0    4    0]\n",
      " [   0    0    0    0  973    0    1    0    2    6]\n",
      " [   2    0    2    4    1  881    0    0    0    2]\n",
      " [   5    3    1    0    6    5  935    0    3    0]\n",
      " [   0    4    5    1    0    1    0 1016    0    1]\n",
      " [   1    0    1    1    0    1    2    1  965    2]\n",
      " [   3    0    2    0    6    1    0    1    3  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7785e-04.\n",
      "Ep: 28/200, it: 1/468, err: 0.0086\n",
      "Ep: 28/200, it: 51/468, err: 0.0238\n",
      "Ep: 28/200, it: 101/468, err: 0.0118\n",
      "Ep: 28/200, it: 151/468, err: 0.0195\n",
      "Ep: 28/200, it: 201/468, err: 0.0840\n",
      "Ep: 28/200, it: 251/468, err: 0.0868\n",
      "Ep: 28/200, it: 301/468, err: 0.0062\n",
      "Ep: 28/200, it: 351/468, err: 0.0064\n",
      "Ep: 28/200, it: 401/468, err: 0.0153\n",
      "Ep: 28/200, it: 451/468, err: 0.0057\n",
      "Ep: 28/200, it: 468/468, err: 0.0578\n",
      "Test acc: 98.75\n",
      "[[ 968    0    2    0    1    4    2    1    2    0]\n",
      " [   0 1128    0    2    0    0    2    2    0    1]\n",
      " [   1    1 1020    1    1    0    0    5    3    0]\n",
      " [   0    1    1 1000    0    8    0    0    0    0]\n",
      " [   0    0    1    0  976    0    2    1    0    2]\n",
      " [   0    0    0    1    0  891    0    0    0    0]\n",
      " [   3    4    0    0    0   12  936    0    3    0]\n",
      " [   0    3    1    3    1    0    0 1018    1    1]\n",
      " [   0    1    1    2    0    3    0    0  965    2]\n",
      " [   0    1    1    1   15   12    0    2    4  973]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7621e-04.\n",
      "Ep: 29/200, it: 1/468, err: 0.0136\n",
      "Ep: 29/200, it: 51/468, err: 0.0579\n",
      "Ep: 29/200, it: 101/468, err: 0.0681\n",
      "Ep: 29/200, it: 151/468, err: 0.0336\n",
      "Ep: 29/200, it: 201/468, err: 0.0331\n",
      "Ep: 29/200, it: 251/468, err: 0.0300\n",
      "Ep: 29/200, it: 301/468, err: 0.0472\n",
      "Ep: 29/200, it: 351/468, err: 0.0104\n",
      "Ep: 29/200, it: 401/468, err: 0.0826\n",
      "Ep: 29/200, it: 451/468, err: 0.0419\n",
      "Ep: 29/200, it: 468/468, err: 0.0414\n",
      "Test acc: 98.92\n",
      "[[ 975    0    2    0    0    0    2    1    0    0]\n",
      " [   0 1129    2    0    0    0    2    2    0    0]\n",
      " [   0    0 1031    0    0    0    0    1    0    0]\n",
      " [   0    1    0 1003    0    3    0    0    2    1]\n",
      " [   0    0    0    0  966    0    4    3    1    8]\n",
      " [   2    1    1    4    0  877    1    2    1    3]\n",
      " [   3    6    0    0    0    4  942    0    3    0]\n",
      " [   0    5    8    1    0    0    0 1014    0    0]\n",
      " [   1    0    7    1    0    0    0    3  961    1]\n",
      " [   0    1    2    0    5    2    0    5    0  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7451e-04.\n",
      "Ep: 30/200, it: 1/468, err: 0.0317\n",
      "Ep: 30/200, it: 51/468, err: 0.0432\n",
      "Ep: 30/200, it: 101/468, err: 0.0444\n",
      "Ep: 30/200, it: 151/468, err: 0.0224\n",
      "Ep: 30/200, it: 201/468, err: 0.0115\n",
      "Ep: 30/200, it: 251/468, err: 0.0244\n",
      "Ep: 30/200, it: 301/468, err: 0.0181\n",
      "Ep: 30/200, it: 351/468, err: 0.0120\n",
      "Ep: 30/200, it: 401/468, err: 0.0399\n",
      "Ep: 30/200, it: 451/468, err: 0.0232\n",
      "Ep: 30/200, it: 468/468, err: 0.0380\n",
      "Test acc: 99.00\n",
      "[[ 976    0    2    0    0    0    0    2    0    0]\n",
      " [   0 1133    2    0    0    0    0    0    0    0]\n",
      " [   0    2 1027    0    0    0    0    3    0    0]\n",
      " [   0    0    2 1001    0    5    0    0    2    0]\n",
      " [   0    0    0    0  977    0    1    0    1    3]\n",
      " [   1    0    1    2    0  885    1    1    0    1]\n",
      " [   3    2    2    0    3    2  945    0    1    0]\n",
      " [   0   10    3    0    2    0    0 1011    1    1]\n",
      " [   0    0    5    2    0    1    2    0  963    1]\n",
      " [   0    5    1    1    9    3    0    2    6  982]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7275e-04.\n",
      "Ep: 31/200, it: 1/468, err: 0.0467\n",
      "Ep: 31/200, it: 51/468, err: 0.0190\n",
      "Ep: 31/200, it: 101/468, err: 0.0376\n",
      "Ep: 31/200, it: 151/468, err: 0.0100\n",
      "Ep: 31/200, it: 201/468, err: 0.0842\n",
      "Ep: 31/200, it: 251/468, err: 0.0131\n",
      "Ep: 31/200, it: 301/468, err: 0.0459\n",
      "Ep: 31/200, it: 351/468, err: 0.0218\n",
      "Ep: 31/200, it: 401/468, err: 0.0475\n",
      "Ep: 31/200, it: 451/468, err: 0.0658\n",
      "Ep: 31/200, it: 468/468, err: 0.0076\n",
      "Test acc: 98.99\n",
      "[[ 973    0    1    0    0    0    3    2    1    0]\n",
      " [   0 1128    1    0    0    0    5    1    0    0]\n",
      " [   1    1 1027    0    0    0    0    3    0    0]\n",
      " [   0    1    2 1005    0    1    0    0    1    0]\n",
      " [   0    0    0    0  967    0    5    3    1    6]\n",
      " [   1    0    0    5    0  884    1    1    0    0]\n",
      " [   2    0    0    0    0    2  953    0    1    0]\n",
      " [   0    3    3    1    3    0    0 1018    0    0]\n",
      " [   0    0    4    3    0    1    4    0  961    1]\n",
      " [   0    3    2    3    7    4    0    3    4  983]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7094e-04.\n",
      "Ep: 32/200, it: 1/468, err: 0.0527\n",
      "Ep: 32/200, it: 51/468, err: 0.0649\n",
      "Ep: 32/200, it: 101/468, err: 0.0258\n",
      "Ep: 32/200, it: 151/468, err: 0.0137\n",
      "Ep: 32/200, it: 201/468, err: 0.0068\n",
      "Ep: 32/200, it: 251/468, err: 0.0192\n",
      "Ep: 32/200, it: 301/468, err: 0.0151\n",
      "Ep: 32/200, it: 351/468, err: 0.0102\n",
      "Ep: 32/200, it: 401/468, err: 0.0044\n",
      "Ep: 32/200, it: 451/468, err: 0.0853\n",
      "Ep: 32/200, it: 468/468, err: 0.0104\n",
      "Test acc: 98.83\n",
      "[[ 978    0    0    0    0    0    0    2    0    0]\n",
      " [   0 1129    1    0    0    0    2    3    0    0]\n",
      " [   2    0 1023    1    0    0    0    5    1    0]\n",
      " [   0    0    0 1008    0    0    0    1    1    0]\n",
      " [   2    1    0    0  964    0    3    1    0   11]\n",
      " [   1    0    1   21    0  867    1    1    0    0]\n",
      " [   7    4    1    0    0    2  942    0    2    0]\n",
      " [   0    1    2    3    3    0    0 1016    0    3]\n",
      " [   1    0    3    6    0    1    1    1  958    3]\n",
      " [   0    0    0    3    5    1    0    2    0  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6908e-04.\n",
      "Ep: 33/200, it: 1/468, err: 0.0293\n",
      "Ep: 33/200, it: 51/468, err: 0.0192\n",
      "Ep: 33/200, it: 101/468, err: 0.0053\n",
      "Ep: 33/200, it: 151/468, err: 0.0029\n",
      "Ep: 33/200, it: 201/468, err: 0.0650\n",
      "Ep: 33/200, it: 251/468, err: 0.0336\n",
      "Ep: 33/200, it: 301/468, err: 0.0057\n",
      "Ep: 33/200, it: 351/468, err: 0.0235\n",
      "Ep: 33/200, it: 401/468, err: 0.0330\n",
      "Ep: 33/200, it: 451/468, err: 0.0187\n",
      "Ep: 33/200, it: 468/468, err: 0.0481\n",
      "Test acc: 98.70\n",
      "[[ 975    0    1    0    0    0    1    1    2    0]\n",
      " [   0 1122    3    0    0    1    3    5    1    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    2 1000    0    6    0    0    2    0]\n",
      " [   0    0    1    0  953    0    5    2    7   14]\n",
      " [   2    0    1    3    0  876    3    1    5    1]\n",
      " [   4    1    1    0    0    2  948    0    2    0]\n",
      " [   1    1   10    1    2    0    0 1011    1    1]\n",
      " [   0    0    2    3    0    1    0    0  968    0]\n",
      " [   0    0    0    2    2    4    0    1   11  989]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6716e-04.\n",
      "Ep: 34/200, it: 1/468, err: 0.0405\n",
      "Ep: 34/200, it: 51/468, err: 0.0224\n",
      "Ep: 34/200, it: 101/468, err: 0.0329\n",
      "Ep: 34/200, it: 151/468, err: 0.0383\n",
      "Ep: 34/200, it: 201/468, err: 0.0498\n",
      "Ep: 34/200, it: 251/468, err: 0.0449\n",
      "Ep: 34/200, it: 301/468, err: 0.0474\n",
      "Ep: 34/200, it: 351/468, err: 0.0058\n",
      "Ep: 34/200, it: 401/468, err: 0.0405\n",
      "Ep: 34/200, it: 451/468, err: 0.0208\n",
      "Ep: 34/200, it: 468/468, err: 0.0563\n",
      "Test acc: 98.80\n",
      "[[ 976    0    1    0    0    0    1    2    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   1    1 1023    0    0    0    0    2    5    0]\n",
      " [   0    0    1 1000    0    2    0    3    4    0]\n",
      " [   0    4    0    0  971    0    4    0    0    3]\n",
      " [   1    0    0   10    0  879    1    1    0    0]\n",
      " [   2    5    1    0    2    7  935    0    6    0]\n",
      " [   0    9    4    1    0    0    0 1010    0    4]\n",
      " [   0    0    2    1    0    1    0    1  968    1]\n",
      " [   0    1    1    3   10    5    0    5    1  983]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6519e-04.\n",
      "Ep: 35/200, it: 1/468, err: 0.0361\n",
      "Ep: 35/200, it: 51/468, err: 0.0088\n",
      "Ep: 35/200, it: 101/468, err: 0.0463\n",
      "Ep: 35/200, it: 151/468, err: 0.0776\n",
      "Ep: 35/200, it: 201/468, err: 0.0469\n",
      "Ep: 35/200, it: 251/468, err: 0.0170\n",
      "Ep: 35/200, it: 301/468, err: 0.0169\n",
      "Ep: 35/200, it: 351/468, err: 0.0112\n",
      "Ep: 35/200, it: 401/468, err: 0.0279\n",
      "Ep: 35/200, it: 451/468, err: 0.0112\n",
      "Ep: 35/200, it: 468/468, err: 0.0208\n",
      "Test acc: 99.02\n",
      "[[ 976    0    0    0    0    0    3    1    0    0]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   1    0 1023    1    1    0    0    4    2    0]\n",
      " [   0    1    1  995    0    7    0    3    2    1]\n",
      " [   0    0    0    0  976    0    1    0    0    5]\n",
      " [   2    0    0    0    0  883    1    4    1    1]\n",
      " [   1    3    1    0    0    1  951    0    1    0]\n",
      " [   0    3    4    0    2    0    0 1017    0    2]\n",
      " [   1    0    1    3    0    2    2    5  958    2]\n",
      " [   1    1    0    0    9    2    0    4    1  991]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6316e-04.\n",
      "Ep: 36/200, it: 1/468, err: 0.0286\n",
      "Ep: 36/200, it: 51/468, err: 0.0086\n",
      "Ep: 36/200, it: 101/468, err: 0.0140\n",
      "Ep: 36/200, it: 151/468, err: 0.0326\n",
      "Ep: 36/200, it: 201/468, err: 0.0248\n",
      "Ep: 36/200, it: 251/468, err: 0.0433\n",
      "Ep: 36/200, it: 301/468, err: 0.0224\n",
      "Ep: 36/200, it: 351/468, err: 0.0230\n",
      "Ep: 36/200, it: 401/468, err: 0.0452\n",
      "Ep: 36/200, it: 451/468, err: 0.0201\n",
      "Ep: 36/200, it: 468/468, err: 0.0733\n",
      "Test acc: 98.91\n",
      "[[ 973    0    1    0    0    0    5    1    0    0]\n",
      " [   0 1132    0    0    0    0    2    0    1    0]\n",
      " [   0    1 1025    1    1    0    0    3    1    0]\n",
      " [   0    0    1 1001    0    4    0    0    4    0]\n",
      " [   0    0    0    0  964    0    7    2    1    8]\n",
      " [   1    0    0    1    0  888    1    1    0    0]\n",
      " [   1    1    0    0    0    2  953    0    1    0]\n",
      " [   0    5    5    3    0    0    0 1011    3    1]\n",
      " [   0    0    1    2    0    1    0    1  968    1]\n",
      " [   0    1    1    5    5    2    0    0   19  976]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6108e-04.\n",
      "Ep: 37/200, it: 1/468, err: 0.0374\n",
      "Ep: 37/200, it: 51/468, err: 0.0054\n",
      "Ep: 37/200, it: 101/468, err: 0.0143\n",
      "Ep: 37/200, it: 151/468, err: 0.0129\n",
      "Ep: 37/200, it: 201/468, err: 0.0382\n",
      "Ep: 37/200, it: 251/468, err: 0.0206\n",
      "Ep: 37/200, it: 301/468, err: 0.0285\n",
      "Ep: 37/200, it: 351/468, err: 0.0020\n",
      "Ep: 37/200, it: 401/468, err: 0.0480\n",
      "Ep: 37/200, it: 451/468, err: 0.0187\n",
      "Ep: 37/200, it: 468/468, err: 0.0380\n",
      "Test acc: 98.89\n",
      "[[ 971    0    5    0    1    0    2    1    0    0]\n",
      " [   0 1129    2    0    0    0    3    1    0    0]\n",
      " [   0    0 1026    0    2    0    0    4    0    0]\n",
      " [   0    1    1 1000    0    5    0    1    1    1]\n",
      " [   0    1    0    0  969    0    2    1    0    9]\n",
      " [   4    0    0    5    0  879    1    3    0    0]\n",
      " [   1    0    0    0    1    0  955    0    1    0]\n",
      " [   0    1    4    2    1    0    0 1020    0    0]\n",
      " [   4    0    4    3    0    2    2    0  958    1]\n",
      " [   0    0    1    4   12    2    0    7    1  982]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5895e-04.\n",
      "Ep: 38/200, it: 1/468, err: 0.0094\n",
      "Ep: 38/200, it: 51/468, err: 0.0023\n",
      "Ep: 38/200, it: 101/468, err: 0.0407\n",
      "Ep: 38/200, it: 151/468, err: 0.1142\n",
      "Ep: 38/200, it: 201/468, err: 0.0296\n",
      "Ep: 38/200, it: 251/468, err: 0.0425\n",
      "Ep: 38/200, it: 301/468, err: 0.0309\n",
      "Ep: 38/200, it: 351/468, err: 0.0291\n",
      "Ep: 38/200, it: 401/468, err: 0.0581\n",
      "Ep: 38/200, it: 451/468, err: 0.0064\n",
      "Ep: 38/200, it: 468/468, err: 0.0184\n",
      "Test acc: 98.91\n",
      "[[ 973    0    2    0    0    0    3    1    1    0]\n",
      " [   0 1121    6    1    0    0    3    3    1    0]\n",
      " [   0    0 1027    2    1    0    0    1    1    0]\n",
      " [   0    0    0 1003    0    5    0    0    2    0]\n",
      " [   0    0    0    0  967    0    2    0    1   12]\n",
      " [   2    0    0    3    0  881    3    2    0    1]\n",
      " [   3    0    3    0    0    0  951    0    1    0]\n",
      " [   0    0    5    3    2    0    0 1015    1    2]\n",
      " [   1    0    3    3    0    3    0    1  961    2]\n",
      " [   0    0    0    2    6    2    0    1    6  992]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5677e-04.\n",
      "Ep: 39/200, it: 1/468, err: 0.0069\n",
      "Ep: 39/200, it: 51/468, err: 0.0347\n",
      "Ep: 39/200, it: 101/468, err: 0.0097\n",
      "Ep: 39/200, it: 151/468, err: 0.0101\n",
      "Ep: 39/200, it: 201/468, err: 0.0067\n",
      "Ep: 39/200, it: 251/468, err: 0.0403\n",
      "Ep: 39/200, it: 301/468, err: 0.0248\n",
      "Ep: 39/200, it: 351/468, err: 0.0162\n",
      "Ep: 39/200, it: 401/468, err: 0.0086\n",
      "Ep: 39/200, it: 451/468, err: 0.0350\n",
      "Ep: 39/200, it: 468/468, err: 0.0278\n",
      "Test acc: 98.86\n",
      "[[ 971    0    2    0    1    0    4    1    1    0]\n",
      " [   0 1127    0    1    0    2    2    3    0    0]\n",
      " [   0    0 1026    0    2    0    0    4    0    0]\n",
      " [   0    1    1  996    0    8    0    1    3    0]\n",
      " [   0    0    0    0  964    0    2    0    2   14]\n",
      " [   4    0    0    0    0  885    1    2    0    0]\n",
      " [   1    1    0    0    1    0  953    0    2    0]\n",
      " [   0    4    1    2    2    0    0 1013    0    6]\n",
      " [   0    0    4    1    0    4    0    2  960    3]\n",
      " [   0    0    1    0    7    4    0    1    5  991]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5454e-04.\n",
      "Ep: 40/200, it: 1/468, err: 0.0046\n",
      "Ep: 40/200, it: 51/468, err: 0.0232\n",
      "Ep: 40/200, it: 101/468, err: 0.0050\n",
      "Ep: 40/200, it: 151/468, err: 0.0347\n",
      "Ep: 40/200, it: 201/468, err: 0.0625\n",
      "Ep: 40/200, it: 251/468, err: 0.0135\n",
      "Ep: 40/200, it: 301/468, err: 0.0313\n",
      "Ep: 40/200, it: 351/468, err: 0.0261\n",
      "Ep: 40/200, it: 401/468, err: 0.0120\n",
      "Ep: 40/200, it: 451/468, err: 0.0982\n",
      "Ep: 40/200, it: 468/468, err: 0.0083\n",
      "Test acc: 98.99\n",
      "[[ 975    0    2    0    0    0    1    1    1    0]\n",
      " [   0 1127    0    2    1    1    0    3    1    0]\n",
      " [   0    0 1025    0    1    0    0    5    1    0]\n",
      " [   0    0    1 1003    0    3    0    1    2    0]\n",
      " [   0    0    0    0  971    0    3    0    0    8]\n",
      " [   1    0    0    2    0  888    1    0    0    0]\n",
      " [   3    5    3    0    1    5  940    0    1    0]\n",
      " [   1    3    5    2    2    0    0 1011    0    4]\n",
      " [   0    0    3    2    0    1    0    1  965    2]\n",
      " [   0    0    1    0    6    6    0    1    1  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5225e-04.\n",
      "Ep: 41/200, it: 1/468, err: 0.0372\n",
      "Ep: 41/200, it: 51/468, err: 0.0266\n",
      "Ep: 41/200, it: 101/468, err: 0.0281\n",
      "Ep: 41/200, it: 151/468, err: 0.0365\n",
      "Ep: 41/200, it: 201/468, err: 0.0258\n",
      "Ep: 41/200, it: 251/468, err: 0.0222\n",
      "Ep: 41/200, it: 301/468, err: 0.0548\n",
      "Ep: 41/200, it: 351/468, err: 0.0414\n",
      "Ep: 41/200, it: 401/468, err: 0.0182\n",
      "Ep: 41/200, it: 451/468, err: 0.0094\n",
      "Ep: 41/200, it: 468/468, err: 0.0164\n",
      "Test acc: 99.06\n",
      "[[ 972    0    1    0    0    0    2    1    4    0]\n",
      " [   0 1132    0    1    1    1    0    0    0    0]\n",
      " [   1    1 1023    0    1    0    0    3    3    0]\n",
      " [   0    0    0 1001    0    2    0    0    7    0]\n",
      " [   0    0    0    0  967    0    5    2    0    8]\n",
      " [   2    0    0    3    0  884    1    1    1    0]\n",
      " [   1    1    0    0    0    2  953    0    1    0]\n",
      " [   0    4    2    1    1    0    0 1014    0    6]\n",
      " [   0    0    1    0    0    1    0    1  967    4]\n",
      " [   0    0    1    1    5    4    0    4    1  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4992e-04.\n",
      "Ep: 42/200, it: 1/468, err: 0.0453\n",
      "Ep: 42/200, it: 51/468, err: 0.0097\n",
      "Ep: 42/200, it: 101/468, err: 0.0050\n",
      "Ep: 42/200, it: 151/468, err: 0.0334\n",
      "Ep: 42/200, it: 201/468, err: 0.0053\n",
      "Ep: 42/200, it: 251/468, err: 0.0048\n",
      "Ep: 42/200, it: 301/468, err: 0.0626\n",
      "Ep: 42/200, it: 351/468, err: 0.0547\n",
      "Ep: 42/200, it: 401/468, err: 0.0421\n",
      "Ep: 42/200, it: 451/468, err: 0.0327\n",
      "Ep: 42/200, it: 468/468, err: 0.0024\n",
      "Test acc: 98.80\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1119    3    0    2    0    6    4    1    0]\n",
      " [   2    0 1022    1    2    0    0    3    2    0]\n",
      " [   0    1    2  996    0    6    0    2    3    0]\n",
      " [   0    0    0    0  976    0    3    1    0    2]\n",
      " [   2    0    0    2    0  881    6    0    1    0]\n",
      " [   3    1    0    0    0    1  953    0    0    0]\n",
      " [   1    2    4    2    2    1    0 1016    0    0]\n",
      " [   3    0    1    2    0    2    4    0  960    2]\n",
      " [   1    3    0    1   13    5    0    4    1  981]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4754e-04.\n",
      "Ep: 43/200, it: 1/468, err: 0.0903\n",
      "Ep: 43/200, it: 51/468, err: 0.0216\n",
      "Ep: 43/200, it: 101/468, err: 0.0538\n",
      "Ep: 43/200, it: 151/468, err: 0.0062\n",
      "Ep: 43/200, it: 201/468, err: 0.0051\n",
      "Ep: 43/200, it: 251/468, err: 0.0386\n",
      "Ep: 43/200, it: 301/468, err: 0.0210\n",
      "Ep: 43/200, it: 351/468, err: 0.0181\n",
      "Ep: 43/200, it: 401/468, err: 0.0109\n",
      "Ep: 43/200, it: 451/468, err: 0.0080\n",
      "Ep: 43/200, it: 468/468, err: 0.0280\n",
      "Test acc: 99.06\n",
      "[[ 972    0    6    0    0    0    1    1    0    0]\n",
      " [   0 1132    1    0    0    0    2    0    0    0]\n",
      " [   0    1 1028    0    1    0    0    1    1    0]\n",
      " [   0    1    2 1003    0    2    0    0    2    0]\n",
      " [   0    0    0    0  973    0    2    2    0    5]\n",
      " [   1    0    0    3    0  886    2    0    0    0]\n",
      " [   1    0    1    0    1    3  952    0    0    0]\n",
      " [   0    7    5    0    1    1    0 1005    1    8]\n",
      " [   3    0    8    1    0    1    1    0  959    1]\n",
      " [   0    0    3    0    3    4    0    1    2  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4511e-04.\n",
      "Ep: 44/200, it: 1/468, err: 0.0145\n",
      "Ep: 44/200, it: 51/468, err: 0.0346\n",
      "Ep: 44/200, it: 101/468, err: 0.0327\n",
      "Ep: 44/200, it: 151/468, err: 0.0050\n",
      "Ep: 44/200, it: 201/468, err: 0.0204\n",
      "Ep: 44/200, it: 251/468, err: 0.0098\n",
      "Ep: 44/200, it: 301/468, err: 0.0335\n",
      "Ep: 44/200, it: 351/468, err: 0.0314\n",
      "Ep: 44/200, it: 401/468, err: 0.0309\n",
      "Ep: 44/200, it: 451/468, err: 0.0072\n",
      "Ep: 44/200, it: 468/468, err: 0.0224\n",
      "Test acc: 99.10\n",
      "[[ 973    0    2    0    0    1    3    1    0    0]\n",
      " [   0 1130    1    0    0    1    1    2    0    0]\n",
      " [   0    2 1027    0    0    0    0    2    1    0]\n",
      " [   0    1    0 1003    0    4    0    1    1    0]\n",
      " [   0    0    0    0  970    0    4    1    1    6]\n",
      " [   1    0    0    3    0  886    1    1    0    0]\n",
      " [   2    2    0    0    0    2  950    0    2    0]\n",
      " [   0    2    4    1    1    1    0 1017    0    2]\n",
      " [   3    0    3    2    0    1    1    1  962    1]\n",
      " [   0    0    1    1    6    3    0    1    5  992]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4263e-04.\n",
      "Ep: 45/200, it: 1/468, err: 0.0123\n",
      "Ep: 45/200, it: 51/468, err: 0.0042\n",
      "Ep: 45/200, it: 101/468, err: 0.0063\n",
      "Ep: 45/200, it: 151/468, err: 0.0047\n",
      "Ep: 45/200, it: 201/468, err: 0.0064\n",
      "Ep: 45/200, it: 251/468, err: 0.0088\n",
      "Ep: 45/200, it: 301/468, err: 0.0105\n",
      "Ep: 45/200, it: 351/468, err: 0.0383\n",
      "Ep: 45/200, it: 401/468, err: 0.0209\n",
      "Ep: 45/200, it: 451/468, err: 0.0325\n",
      "Ep: 45/200, it: 468/468, err: 0.0258\n",
      "Test acc: 98.96\n",
      "[[ 971    0    1    0    0    2    4    1    1    0]\n",
      " [   0 1130    1    1    0    0    1    2    0    0]\n",
      " [   0    0 1014    1    1    0    0   12    4    0]\n",
      " [   0    0    0 1005    0    3    0    0    2    0]\n",
      " [   0    0    1    0  975    0    1    1    0    4]\n",
      " [   1    0    0    1    0  889    1    0    0    0]\n",
      " [   1    3    0    0    1    2  951    0    0    0]\n",
      " [   0    4    1    1    1    1    0 1018    1    1]\n",
      " [   1    1    2    3    0    2    2    0  962    1]\n",
      " [   0    2    0    1   13    8    0    0    4  981]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4010e-04.\n",
      "Ep: 46/200, it: 1/468, err: 0.0408\n",
      "Ep: 46/200, it: 51/468, err: 0.0098\n",
      "Ep: 46/200, it: 101/468, err: 0.0221\n",
      "Ep: 46/200, it: 151/468, err: 0.0101\n",
      "Ep: 46/200, it: 201/468, err: 0.0140\n",
      "Ep: 46/200, it: 251/468, err: 0.0184\n",
      "Ep: 46/200, it: 301/468, err: 0.0226\n",
      "Ep: 46/200, it: 351/468, err: 0.0138\n",
      "Ep: 46/200, it: 401/468, err: 0.0235\n",
      "Ep: 46/200, it: 451/468, err: 0.0061\n",
      "Ep: 46/200, it: 468/468, err: 0.0037\n",
      "Test acc: 99.01\n",
      "[[ 976    0    1    0    0    0    1    2    0    0]\n",
      " [   0 1128    1    0    0    0    2    2    2    0]\n",
      " [   0    0 1028    1    0    0    0    1    1    1]\n",
      " [   0    1    0 1003    0    2    0    0    1    3]\n",
      " [   0    0    0    0  970    0    3    1    0    8]\n",
      " [   1    0    0    5    0  881    1    2    0    2]\n",
      " [   5    1    0    1    0    3  947    0    1    0]\n",
      " [   0    3   10    3    1    0    0 1008    0    3]\n",
      " [   0    0    1    5    0    2    1    1  961    3]\n",
      " [   0    0    0    0    5    2    0    0    3  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3753e-04.\n",
      "Ep: 47/200, it: 1/468, err: 0.0169\n",
      "Ep: 47/200, it: 51/468, err: 0.0204\n",
      "Ep: 47/200, it: 101/468, err: 0.0143\n",
      "Ep: 47/200, it: 151/468, err: 0.0028\n",
      "Ep: 47/200, it: 201/468, err: 0.0688\n",
      "Ep: 47/200, it: 251/468, err: 0.0136\n",
      "Ep: 47/200, it: 301/468, err: 0.0180\n",
      "Ep: 47/200, it: 351/468, err: 0.0374\n",
      "Ep: 47/200, it: 401/468, err: 0.0317\n",
      "Ep: 47/200, it: 451/468, err: 0.0214\n",
      "Ep: 47/200, it: 468/468, err: 0.0264\n",
      "Test acc: 98.94\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   1 1127    1    1    0    0    3    2    0    0]\n",
      " [   0    0 1022    0    0    0    0    6    4    0]\n",
      " [   0    1    0 1002    0    3    0    0    4    0]\n",
      " [   0    0    0    0  971    0    3    0    1    7]\n",
      " [   1    0    0    3    0  877    3    2    4    2]\n",
      " [   6    1    1    0    0    2  941    0    7    0]\n",
      " [   0    7    2    1    1    0    0 1016    0    1]\n",
      " [   0    0    2    0    0    0    0    0  971    1]\n",
      " [   0    0    0    0    5    2    0    1   11  990]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3491e-04.\n",
      "Ep: 48/200, it: 1/468, err: 0.0054\n",
      "Ep: 48/200, it: 51/468, err: 0.0161\n",
      "Ep: 48/200, it: 101/468, err: 0.0846\n",
      "Ep: 48/200, it: 151/468, err: 0.0017\n",
      "Ep: 48/200, it: 201/468, err: 0.0015\n",
      "Ep: 48/200, it: 251/468, err: 0.0249\n",
      "Ep: 48/200, it: 301/468, err: 0.0029\n",
      "Ep: 48/200, it: 351/468, err: 0.0852\n",
      "Ep: 48/200, it: 401/468, err: 0.0021\n",
      "Ep: 48/200, it: 451/468, err: 0.0064\n",
      "Ep: 48/200, it: 468/468, err: 0.0222\n",
      "Test acc: 99.12\n",
      "[[ 973    0    1    0    0    0    4    2    0    0]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   1    2 1024    0    1    0    0    3    1    0]\n",
      " [   0    0    0 1004    0    2    0    0    4    0]\n",
      " [   0    0    0    0  971    0    3    2    0    6]\n",
      " [   0    0    0    7    0  881    1    1    1    1]\n",
      " [   2    2    0    0    0    2  950    0    2    0]\n",
      " [   0    3    6    2    0    0    0 1016    0    1]\n",
      " [   0    0    2    2    0    0    0    0  969    1]\n",
      " [   0    0    0    5    5    2    0    1    2  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3224e-04.\n",
      "Ep: 49/200, it: 1/468, err: 0.0037\n",
      "Ep: 49/200, it: 51/468, err: 0.0040\n",
      "Ep: 49/200, it: 101/468, err: 0.0370\n",
      "Ep: 49/200, it: 151/468, err: 0.0055\n",
      "Ep: 49/200, it: 201/468, err: 0.0088\n",
      "Ep: 49/200, it: 251/468, err: 0.0055\n",
      "Ep: 49/200, it: 301/468, err: 0.0660\n",
      "Ep: 49/200, it: 351/468, err: 0.0376\n",
      "Ep: 49/200, it: 401/468, err: 0.0483\n",
      "Ep: 49/200, it: 451/468, err: 0.0135\n",
      "Ep: 49/200, it: 468/468, err: 0.0140\n",
      "Test acc: 98.89\n",
      "[[ 974    0    1    0    1    0    2    1    1    0]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   0    1 1029    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1002    0    5    0    1    2    0]\n",
      " [   0    0    0    0  970    0    5    0    0    7]\n",
      " [   0    0    0    4    0  886    2    0    0    0]\n",
      " [   1    4    0    0    1    2  948    0    2    0]\n",
      " [   0    5    9    0    2    0    0 1011    1    0]\n",
      " [   0    1    3    2    0    1    1    1  963    2]\n",
      " [   0    1    0    1   15    9    0    4    4  975]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2953e-04.\n",
      "Ep: 50/200, it: 1/468, err: 0.0183\n",
      "Ep: 50/200, it: 51/468, err: 0.0919\n",
      "Ep: 50/200, it: 101/468, err: 0.0506\n",
      "Ep: 50/200, it: 151/468, err: 0.0054\n",
      "Ep: 50/200, it: 201/468, err: 0.0043\n",
      "Ep: 50/200, it: 251/468, err: 0.0044\n",
      "Ep: 50/200, it: 301/468, err: 0.0360\n",
      "Ep: 50/200, it: 351/468, err: 0.0186\n",
      "Ep: 50/200, it: 401/468, err: 0.0141\n",
      "Ep: 50/200, it: 451/468, err: 0.0224\n",
      "Ep: 50/200, it: 468/468, err: 0.0287\n",
      "Test acc: 98.92\n",
      "[[ 974    0    2    0    0    0    0    1    3    0]\n",
      " [   1 1126    1    1    1    0    2    3    0    0]\n",
      " [   0    1 1024    0    0    0    0    4    3    0]\n",
      " [   0    1    2 1002    0    1    0    1    3    0]\n",
      " [   0    0    1    0  970    0    5    1    1    4]\n",
      " [   1    0    0    3    0  885    1    1    1    0]\n",
      " [   1    3    0    0    0    1  953    0    0    0]\n",
      " [   0    4    4    0    1    1    0 1017    1    0]\n",
      " [   0    0    2    2    0    1    0    0  968    1]\n",
      " [   0    0    0    5    5    2    0    2   22  973]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2678e-04.\n",
      "Ep: 51/200, it: 1/468, err: 0.0484\n",
      "Ep: 51/200, it: 51/468, err: 0.0079\n",
      "Ep: 51/200, it: 101/468, err: 0.0329\n",
      "Ep: 51/200, it: 151/468, err: 0.0411\n",
      "Ep: 51/200, it: 201/468, err: 0.0026\n",
      "Ep: 51/200, it: 251/468, err: 0.0090\n",
      "Ep: 51/200, it: 301/468, err: 0.0064\n",
      "Ep: 51/200, it: 351/468, err: 0.0493\n",
      "Ep: 51/200, it: 401/468, err: 0.0037\n",
      "Ep: 51/200, it: 451/468, err: 0.0371\n",
      "Ep: 51/200, it: 468/468, err: 0.0185\n",
      "Test acc: 98.91\n",
      "[[ 972    0    1    0    2    0    2    2    1    0]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   0    0 1019    1    2    1    0    7    2    0]\n",
      " [   0    0    1 1005    0    3    0    0    1    0]\n",
      " [   0    0    0    0  972    0    4    1    1    4]\n",
      " [   2    0    0    3    0  882    3    1    0    1]\n",
      " [   2    4    0    0    2    1  945    0    4    0]\n",
      " [   0    2    1    3    2    1    0 1019    0    0]\n",
      " [   1    0    3    5    0    2    0    1  961    1]\n",
      " [   0    0    0    3    8    4    0    4    5  985]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2398e-04.\n",
      "Ep: 52/200, it: 1/468, err: 0.0100\n",
      "Ep: 52/200, it: 51/468, err: 0.0347\n",
      "Ep: 52/200, it: 101/468, err: 0.0120\n",
      "Ep: 52/200, it: 151/468, err: 0.0400\n",
      "Ep: 52/200, it: 201/468, err: 0.0240\n",
      "Ep: 52/200, it: 251/468, err: 0.0567\n",
      "Ep: 52/200, it: 301/468, err: 0.0064\n",
      "Ep: 52/200, it: 351/468, err: 0.0122\n",
      "Ep: 52/200, it: 401/468, err: 0.0469\n",
      "Ep: 52/200, it: 451/468, err: 0.0233\n",
      "Ep: 52/200, it: 468/468, err: 0.0018\n",
      "Test acc: 99.03\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1124    2    1    0    0    3    5    0    0]\n",
      " [   0    0 1019    4    2    0    1    5    1    0]\n",
      " [   0    0    0 1007    0    1    0    1    1    0]\n",
      " [   0    0    0    0  969    0    4    0    0    9]\n",
      " [   1    0    1    8    0  877    1    3    0    1]\n",
      " [   2    1    0    0    0    2  952    0    1    0]\n",
      " [   0    0    2    2    0    0    0 1024    0    0]\n",
      " [   1    0    2    2    0    1    1    1  965    1]\n",
      " [   0    0    0    4    8    0    0    5    3  989]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2114e-04.\n",
      "Ep: 53/200, it: 1/468, err: 0.0037\n",
      "Ep: 53/200, it: 51/468, err: 0.0281\n",
      "Ep: 53/200, it: 101/468, err: 0.0186\n",
      "Ep: 53/200, it: 151/468, err: 0.0280\n",
      "Ep: 53/200, it: 201/468, err: 0.0054\n",
      "Ep: 53/200, it: 251/468, err: 0.0072\n",
      "Ep: 53/200, it: 301/468, err: 0.0046\n",
      "Ep: 53/200, it: 351/468, err: 0.0155\n",
      "Ep: 53/200, it: 401/468, err: 0.0017\n",
      "Ep: 53/200, it: 451/468, err: 0.0441\n",
      "Ep: 53/200, it: 468/468, err: 0.0514\n",
      "Test acc: 98.80\n",
      "[[ 975    0    1    0    0    0    2    1    0    1]\n",
      " [   2 1129    0    0    0    0    2    2    0    0]\n",
      " [   0    1 1028    0    2    0    0    1    0    0]\n",
      " [   0    1    2  995    0    9    0    0    3    0]\n",
      " [   0    0    0    0  972    0    4    1    1    4]\n",
      " [   2    1    0    0    0  880    8    0    0    1]\n",
      " [   1    3    0    0    1    1  952    0    0    0]\n",
      " [   0    9    3    0    5    0    0 1007    2    2]\n",
      " [   7    0    5    1    0    1    6    0  952    2]\n",
      " [   1    2    1    0    7    1    1    0    6  990]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1825e-04.\n",
      "Ep: 54/200, it: 1/468, err: 0.0344\n",
      "Ep: 54/200, it: 51/468, err: 0.0112\n",
      "Ep: 54/200, it: 101/468, err: 0.0228\n",
      "Ep: 54/200, it: 151/468, err: 0.0189\n",
      "Ep: 54/200, it: 201/468, err: 0.0057\n",
      "Ep: 54/200, it: 251/468, err: 0.1038\n",
      "Ep: 54/200, it: 301/468, err: 0.0448\n",
      "Ep: 54/200, it: 351/468, err: 0.0466\n",
      "Ep: 54/200, it: 401/468, err: 0.0089\n",
      "Ep: 54/200, it: 451/468, err: 0.0031\n",
      "Ep: 54/200, it: 468/468, err: 0.0053\n",
      "Test acc: 99.32\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1127    1    0    0    0    3    4    0    0]\n",
      " [   0    0 1026    0    1    0    0    5    0    0]\n",
      " [   0    0    2 1004    0    2    0    0    1    1]\n",
      " [   0    0    0    0  976    0    3    0    1    2]\n",
      " [   1    0    0    2    0  886    1    1    0    1]\n",
      " [   1    2    0    0    0    1  953    0    1    0]\n",
      " [   0    2    3    1    2    0    0 1020    0    0]\n",
      " [   0    0    3    2    0    1    0    1  965    2]\n",
      " [   0    1    0    1    6    1    0    0    3  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1533e-04.\n",
      "Ep: 55/200, it: 1/468, err: 0.0065\n",
      "Ep: 55/200, it: 51/468, err: 0.0217\n",
      "Ep: 55/200, it: 101/468, err: 0.0184\n",
      "Ep: 55/200, it: 151/468, err: 0.0191\n",
      "Ep: 55/200, it: 201/468, err: 0.1249\n",
      "Ep: 55/200, it: 251/468, err: 0.0174\n",
      "Ep: 55/200, it: 301/468, err: 0.0235\n",
      "Ep: 55/200, it: 351/468, err: 0.0112\n",
      "Ep: 55/200, it: 401/468, err: 0.0448\n",
      "Ep: 55/200, it: 451/468, err: 0.0176\n",
      "Ep: 55/200, it: 468/468, err: 0.0103\n",
      "Test acc: 99.12\n",
      "[[ 973    0    0    0    0    0    2    2    1    2]\n",
      " [   1 1122    1    0    2    0    6    3    0    0]\n",
      " [   2    1 1021    1    1    0    0    6    0    0]\n",
      " [   0    0    0 1004    0    3    0    2    1    0]\n",
      " [   0    0    0    0  976    0    1    0    0    5]\n",
      " [   1    0    0    1    0  889    1    0    0    0]\n",
      " [   2    1    1    0    1    4  949    0    0    0]\n",
      " [   0    2    2    0    1    0    0 1023    0    0]\n",
      " [   1    0    3    5    0    2    0    0  959    4]\n",
      " [   0    0    0    1    6    3    0    3    0  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1236e-04.\n",
      "Ep: 56/200, it: 1/468, err: 0.0012\n",
      "Ep: 56/200, it: 51/468, err: 0.0038\n",
      "Ep: 56/200, it: 101/468, err: 0.0493\n",
      "Ep: 56/200, it: 151/468, err: 0.0181\n",
      "Ep: 56/200, it: 201/468, err: 0.0378\n",
      "Ep: 56/200, it: 251/468, err: 0.0092\n",
      "Ep: 56/200, it: 301/468, err: 0.0523\n",
      "Ep: 56/200, it: 351/468, err: 0.0356\n",
      "Ep: 56/200, it: 401/468, err: 0.0057\n",
      "Ep: 56/200, it: 451/468, err: 0.0190\n",
      "Ep: 56/200, it: 468/468, err: 0.0492\n",
      "Test acc: 99.15\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1127    2    0    0    0    1    4    0    1]\n",
      " [   0    0 1027    0    1    0    0    2    2    0]\n",
      " [   0    1    0 1007    0    1    0    0    1    0]\n",
      " [   0    0    0    0  967    0    3    3    0    9]\n",
      " [   3    0    0    4    0  884    1    0    0    0]\n",
      " [   2    5    0    0    1    2  944    0    3    1]\n",
      " [   1    0    4    3    0    0    0 1017    0    3]\n",
      " [   1    0    1    5    0    1    0    0  964    2]\n",
      " [   0    0    1    2    4    1    0    0    2  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0936e-04.\n",
      "Ep: 57/200, it: 1/468, err: 0.0023\n",
      "Ep: 57/200, it: 51/468, err: 0.0034\n",
      "Ep: 57/200, it: 101/468, err: 0.0057\n",
      "Ep: 57/200, it: 151/468, err: 0.0035\n",
      "Ep: 57/200, it: 201/468, err: 0.0118\n",
      "Ep: 57/200, it: 251/468, err: 0.0023\n",
      "Ep: 57/200, it: 301/468, err: 0.0331\n",
      "Ep: 57/200, it: 351/468, err: 0.0228\n",
      "Ep: 57/200, it: 401/468, err: 0.0081\n",
      "Ep: 57/200, it: 451/468, err: 0.0143\n",
      "Ep: 57/200, it: 468/468, err: 0.0304\n",
      "Test acc: 99.11\n",
      "[[ 976    0    1    0    0    0    0    3    0    0]\n",
      " [   0 1129    1    0    0    0    2    3    0    0]\n",
      " [   1    0 1028    1    0    0    0    1    1    0]\n",
      " [   0    0    1 1000    0    4    0    1    3    1]\n",
      " [   0    1    0    0  967    0    1    3    0   10]\n",
      " [   2    0    0    2    0  882    1    2    0    3]\n",
      " [   2    3    0    1    4    1  943    0    4    0]\n",
      " [   0    1    2    0    1    0    0 1023    1    0]\n",
      " [   1    0    3    3    0    1    0    1  962    3]\n",
      " [   0    0    0    2    3    0    0    3    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0631e-04.\n",
      "Ep: 58/200, it: 1/468, err: 0.0453\n",
      "Ep: 58/200, it: 51/468, err: 0.0053\n",
      "Ep: 58/200, it: 101/468, err: 0.0039\n",
      "Ep: 58/200, it: 151/468, err: 0.0075\n",
      "Ep: 58/200, it: 201/468, err: 0.0035\n",
      "Ep: 58/200, it: 251/468, err: 0.0176\n",
      "Ep: 58/200, it: 301/468, err: 0.0565\n",
      "Ep: 58/200, it: 351/468, err: 0.1004\n",
      "Ep: 58/200, it: 401/468, err: 0.0266\n",
      "Ep: 58/200, it: 451/468, err: 0.0423\n",
      "Ep: 58/200, it: 468/468, err: 0.0208\n",
      "Test acc: 99.15\n",
      "[[ 976    0    0    0    0    1    1    2    0    0]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   0    0 1027    1    0    0    0    3    0    1]\n",
      " [   0    1    0 1006    0    2    0    0    1    0]\n",
      " [   0    1    0    0  970    0    3    0    0    8]\n",
      " [   1    0    1    3    0  886    0    1    0    0]\n",
      " [   3    6    0    1    2    3  941    0    2    0]\n",
      " [   0    1    2    1    1    0    0 1021    0    2]\n",
      " [   1    0    3    5    0    1    0    0  957    7]\n",
      " [   0    0    0    0    5    2    0    3    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0323e-04.\n",
      "Ep: 59/200, it: 1/468, err: 0.0083\n",
      "Ep: 59/200, it: 51/468, err: 0.0273\n",
      "Ep: 59/200, it: 101/468, err: 0.0263\n",
      "Ep: 59/200, it: 151/468, err: 0.0611\n",
      "Ep: 59/200, it: 201/468, err: 0.0028\n",
      "Ep: 59/200, it: 251/468, err: 0.0182\n",
      "Ep: 59/200, it: 301/468, err: 0.0045\n",
      "Ep: 59/200, it: 351/468, err: 0.0366\n",
      "Ep: 59/200, it: 401/468, err: 0.0097\n",
      "Ep: 59/200, it: 451/468, err: 0.0034\n",
      "Ep: 59/200, it: 468/468, err: 0.0028\n",
      "Test acc: 99.18\n",
      "[[ 976    0    1    0    0    1    0    1    1    0]\n",
      " [   0 1130    1    0    0    0    3    1    0    0]\n",
      " [   0    1 1028    0    0    0    0    1    2    0]\n",
      " [   0    1    0 1002    0    4    0    1    2    0]\n",
      " [   0    0    0    0  973    0    6    0    0    3]\n",
      " [   0    0    1    2    0  887    2    0    0    0]\n",
      " [   2    1    0    0    0    1  952    0    2    0]\n",
      " [   0    4    5    0    1    0    0 1016    1    1]\n",
      " [   0    0    2    4    0    1    1    1  964    1]\n",
      " [   0    1    1    3    4    2    0    1    7  990]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0011e-04.\n",
      "Ep: 60/200, it: 1/468, err: 0.0086\n",
      "Ep: 60/200, it: 51/468, err: 0.0659\n",
      "Ep: 60/200, it: 101/468, err: 0.0303\n",
      "Ep: 60/200, it: 151/468, err: 0.0037\n",
      "Ep: 60/200, it: 201/468, err: 0.0023\n",
      "Ep: 60/200, it: 251/468, err: 0.0336\n",
      "Ep: 60/200, it: 301/468, err: 0.0092\n",
      "Ep: 60/200, it: 351/468, err: 0.0010\n",
      "Ep: 60/200, it: 401/468, err: 0.0303\n",
      "Ep: 60/200, it: 451/468, err: 0.0058\n",
      "Ep: 60/200, it: 468/468, err: 0.0147\n",
      "Test acc: 99.15\n",
      "[[ 977    0    0    0    0    0    1    2    0    0]\n",
      " [   0 1131    0    1    0    0    1    2    0    0]\n",
      " [   0    1 1027    1    0    0    0    1    2    0]\n",
      " [   0    1    0 1005    0    1    0    1    2    0]\n",
      " [   0    0    0    0  977    0    1    2    0    2]\n",
      " [   1    0    0    5    0  884    1    1    0    0]\n",
      " [   1    3    1    0    0    4  947    0    2    0]\n",
      " [   0    2    1    2    0    0    0 1022    0    1]\n",
      " [   0    0    2    3    0    2    1    1  963    2]\n",
      " [   0    0    1    2   10    7    0    5    2  982]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9695e-04.\n",
      "Ep: 61/200, it: 1/468, err: 0.0222\n",
      "Ep: 61/200, it: 51/468, err: 0.0007\n",
      "Ep: 61/200, it: 101/468, err: 0.0083\n",
      "Ep: 61/200, it: 151/468, err: 0.0042\n",
      "Ep: 61/200, it: 201/468, err: 0.0044\n",
      "Ep: 61/200, it: 251/468, err: 0.0171\n",
      "Ep: 61/200, it: 301/468, err: 0.0252\n",
      "Ep: 61/200, it: 351/468, err: 0.0011\n",
      "Ep: 61/200, it: 401/468, err: 0.0114\n",
      "Ep: 61/200, it: 451/468, err: 0.0026\n",
      "Ep: 61/200, it: 468/468, err: 0.0741\n",
      "Test acc: 99.16\n",
      "[[ 976    0    0    0    0    0    1    2    1    0]\n",
      " [   0 1130    2    0    0    0    2    1    0    0]\n",
      " [   0    0 1025    0    0    0    0    4    3    0]\n",
      " [   0    1    0 1000    0    4    0    1    2    2]\n",
      " [   0    0    0    0  961    0    5    1    0   15]\n",
      " [   1    0    0    3    0  885    1    1    0    1]\n",
      " [   1    2    0    0    0    1  952    0    2    0]\n",
      " [   1    3    2    1    0    0    0 1020    0    1]\n",
      " [   0    0    2    2    0    0    0    0  969    1]\n",
      " [   0    1    0    2    4    2    0    0    2  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9375e-04.\n",
      "Ep: 62/200, it: 1/468, err: 0.0030\n",
      "Ep: 62/200, it: 51/468, err: 0.0309\n",
      "Ep: 62/200, it: 101/468, err: 0.0020\n",
      "Ep: 62/200, it: 151/468, err: 0.0095\n",
      "Ep: 62/200, it: 201/468, err: 0.0245\n",
      "Ep: 62/200, it: 251/468, err: 0.0016\n",
      "Ep: 62/200, it: 301/468, err: 0.0601\n",
      "Ep: 62/200, it: 351/468, err: 0.0022\n",
      "Ep: 62/200, it: 401/468, err: 0.0155\n",
      "Ep: 62/200, it: 451/468, err: 0.0047\n",
      "Ep: 62/200, it: 468/468, err: 0.0056\n",
      "Test acc: 99.28\n",
      "[[ 976    0    0    0    0    0    1    2    1    0]\n",
      " [   0 1132    0    0    0    0    0    3    0    0]\n",
      " [   0    0 1022    1    1    0    0    4    4    0]\n",
      " [   0    0    0 1000    0    4    0    1    3    2]\n",
      " [   0    0    0    0  977    0    2    0    0    3]\n",
      " [   0    0    0    4    0  882    2    2    0    2]\n",
      " [   2    2    0    0    0    7  945    0    2    0]\n",
      " [   0    2    1    1    1    0    0 1022    0    1]\n",
      " [   0    0    1    0    0    1    0    0  971    1]\n",
      " [   0    1    0    1    4    0    0    2    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9052e-04.\n",
      "Ep: 63/200, it: 1/468, err: 0.0249\n",
      "Ep: 63/200, it: 51/468, err: 0.0091\n",
      "Ep: 63/200, it: 101/468, err: 0.0067\n",
      "Ep: 63/200, it: 151/468, err: 0.0005\n",
      "Ep: 63/200, it: 201/468, err: 0.0586\n",
      "Ep: 63/200, it: 251/468, err: 0.0275\n",
      "Ep: 63/200, it: 301/468, err: 0.0344\n",
      "Ep: 63/200, it: 351/468, err: 0.0015\n",
      "Ep: 63/200, it: 401/468, err: 0.0140\n",
      "Ep: 63/200, it: 451/468, err: 0.0208\n",
      "Ep: 63/200, it: 468/468, err: 0.0334\n",
      "Test acc: 99.15\n",
      "[[ 975    0    1    0    0    1    0    1    2    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    2 1027    0    1    0    0    2    0    0]\n",
      " [   0    1    0 1004    0    3    0    0    1    1]\n",
      " [   0    0    0    0  977    0    2    0    0    3]\n",
      " [   0    0    0    5    0  886    0    1    0    0]\n",
      " [   1    4    0    1    0    4  947    0    1    0]\n",
      " [   0    3    1    2    2    0    0 1016    0    4]\n",
      " [   0    3    3    4    0    2    1    1  956    4]\n",
      " [   0    0    0    0   12    1    0    2    0  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8726e-04.\n",
      "Ep: 64/200, it: 1/468, err: 0.0619\n",
      "Ep: 64/200, it: 51/468, err: 0.0221\n",
      "Ep: 64/200, it: 101/468, err: 0.0088\n",
      "Ep: 64/200, it: 151/468, err: 0.0113\n",
      "Ep: 64/200, it: 201/468, err: 0.0545\n",
      "Ep: 64/200, it: 251/468, err: 0.0361\n",
      "Ep: 64/200, it: 301/468, err: 0.0135\n",
      "Ep: 64/200, it: 351/468, err: 0.0395\n",
      "Ep: 64/200, it: 401/468, err: 0.0180\n",
      "Ep: 64/200, it: 451/468, err: 0.0035\n",
      "Ep: 64/200, it: 468/468, err: 0.0043\n",
      "Test acc: 99.17\n",
      "[[ 977    0    0    0    0    1    0    1    1    0]\n",
      " [   0 1122    2    3    1    0    3    3    1    0]\n",
      " [   0    0 1029    0    1    0    0    2    0    0]\n",
      " [   0    1    0 1007    0    2    0    0    0    0]\n",
      " [   0    0    0    0  970    0    0    2    0   10]\n",
      " [   0    0    0    4    0  885    1    0    0    2]\n",
      " [   1    1    0    0    1    1  952    0    2    0]\n",
      " [   0    3    4    2    2    0    0 1016    0    1]\n",
      " [   0    0    5    7    0    1    0    1  959    1]\n",
      " [   0    0    0    0    3    1    0    3    2 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8396e-04.\n",
      "Ep: 65/200, it: 1/468, err: 0.0028\n",
      "Ep: 65/200, it: 51/468, err: 0.0624\n",
      "Ep: 65/200, it: 101/468, err: 0.0117\n",
      "Ep: 65/200, it: 151/468, err: 0.0054\n",
      "Ep: 65/200, it: 201/468, err: 0.0109\n",
      "Ep: 65/200, it: 251/468, err: 0.0724\n",
      "Ep: 65/200, it: 301/468, err: 0.0150\n",
      "Ep: 65/200, it: 351/468, err: 0.0030\n",
      "Ep: 65/200, it: 401/468, err: 0.0060\n",
      "Ep: 65/200, it: 451/468, err: 0.0043\n",
      "Ep: 65/200, it: 468/468, err: 0.0098\n",
      "Test acc: 99.06\n",
      "[[ 974    0    3    0    0    0    2    1    0    0]\n",
      " [   0 1127    1    2    1    0    0    4    0    0]\n",
      " [   0    0 1028    1    1    0    0    1    1    0]\n",
      " [   0    0    0 1005    0    3    0    1    1    0]\n",
      " [   0    1    1    0  976    0    2    0    0    2]\n",
      " [   1    0    0    4    0  883    3    1    0    0]\n",
      " [   1    4    2    0    0    1  950    0    0    0]\n",
      " [   0    2    7    1    3    0    0 1015    0    0]\n",
      " [   1    0    3    4    0    0    3    0  962    1]\n",
      " [   0    0    0    0   16    2    0    2    3  986]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8062e-04.\n",
      "Ep: 66/200, it: 1/468, err: 0.0120\n",
      "Ep: 66/200, it: 51/468, err: 0.0075\n",
      "Ep: 66/200, it: 101/468, err: 0.0545\n",
      "Ep: 66/200, it: 151/468, err: 0.0069\n",
      "Ep: 66/200, it: 201/468, err: 0.0018\n",
      "Ep: 66/200, it: 251/468, err: 0.0164\n",
      "Ep: 66/200, it: 301/468, err: 0.0047\n",
      "Ep: 66/200, it: 351/468, err: 0.0130\n",
      "Ep: 66/200, it: 401/468, err: 0.0077\n",
      "Ep: 66/200, it: 451/468, err: 0.0955\n",
      "Ep: 66/200, it: 468/468, err: 0.0093\n",
      "Test acc: 99.17\n",
      "[[ 973    0    1    0    0    1    0    1    4    0]\n",
      " [   0 1123    1    2    1    0    1    6    1    0]\n",
      " [   0    0 1027    1    0    0    0    3    1    0]\n",
      " [   0    0    2 1006    0    1    0    0    1    0]\n",
      " [   0    0    0    0  971    0    3    1    0    7]\n",
      " [   0    0    0    4    0  886    1    1    0    0]\n",
      " [   2    4    0    0    0    4  945    0    3    0]\n",
      " [   0    0    7    3    0    0    0 1018    0    0]\n",
      " [   0    0    2    3    0    0    0    1  967    1]\n",
      " [   0    0    0    1    2    1    0    2    2 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7726e-04.\n",
      "Ep: 67/200, it: 1/468, err: 0.0297\n",
      "Ep: 67/200, it: 51/468, err: 0.0593\n",
      "Ep: 67/200, it: 101/468, err: 0.0860\n",
      "Ep: 67/200, it: 151/468, err: 0.0060\n",
      "Ep: 67/200, it: 201/468, err: 0.0011\n",
      "Ep: 67/200, it: 251/468, err: 0.0144\n",
      "Ep: 67/200, it: 301/468, err: 0.0408\n",
      "Ep: 67/200, it: 351/468, err: 0.0028\n",
      "Ep: 67/200, it: 401/468, err: 0.0048\n",
      "Ep: 67/200, it: 451/468, err: 0.0030\n",
      "Ep: 67/200, it: 468/468, err: 0.0056\n",
      "Test acc: 99.08\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1128    2    1    2    0    0    2    0    0]\n",
      " [   1    0 1028    0    1    0    0    1    1    0]\n",
      " [   0    1    1 1002    0    3    0    0    2    1]\n",
      " [   0    0    1    0  976    0    2    1    0    2]\n",
      " [   1    0    0    2    0  887    2    0    0    0]\n",
      " [   1    3    2    0    0    1  950    0    1    0]\n",
      " [   1    1    2    1    2    0    0 1021    0    0]\n",
      " [   1    0    4    1    0    0    1    1  964    2]\n",
      " [   2    1    0    3   19    4    0    4    1  975]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7386e-04.\n",
      "Ep: 68/200, it: 1/468, err: 0.0331\n",
      "Ep: 68/200, it: 51/468, err: 0.0228\n",
      "Ep: 68/200, it: 101/468, err: 0.0228\n",
      "Ep: 68/200, it: 151/468, err: 0.0110\n",
      "Ep: 68/200, it: 201/468, err: 0.0088\n",
      "Ep: 68/200, it: 251/468, err: 0.0353\n",
      "Ep: 68/200, it: 301/468, err: 0.0563\n",
      "Ep: 68/200, it: 351/468, err: 0.0021\n",
      "Ep: 68/200, it: 401/468, err: 0.0173\n",
      "Ep: 68/200, it: 451/468, err: 0.0243\n",
      "Ep: 68/200, it: 468/468, err: 0.0291\n",
      "Test acc: 99.28\n",
      "[[ 976    0    1    0    0    1    1    1    0    0]\n",
      " [   0 1131    0    0    0    0    3    1    0    0]\n",
      " [   1    0 1021    2    0    0    0    5    3    0]\n",
      " [   0    0    2 1003    0    3    0    1    0    1]\n",
      " [   1    0    0    0  969    0    3    1    0    8]\n",
      " [   0    0    1    4    0  885    1    1    0    0]\n",
      " [   1    0    0    0    0    2  955    0    0    0]\n",
      " [   0    1    1    0    1    0    0 1023    0    2]\n",
      " [   1    0    2    3    0    0    0    1  964    3]\n",
      " [   0    0    0    0    4    3    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7044e-04.\n",
      "Ep: 69/200, it: 1/468, err: 0.0015\n",
      "Ep: 69/200, it: 51/468, err: 0.0064\n",
      "Ep: 69/200, it: 101/468, err: 0.0031\n",
      "Ep: 69/200, it: 151/468, err: 0.0574\n",
      "Ep: 69/200, it: 201/468, err: 0.0282\n",
      "Ep: 69/200, it: 251/468, err: 0.0128\n",
      "Ep: 69/200, it: 301/468, err: 0.0230\n",
      "Ep: 69/200, it: 351/468, err: 0.0686\n",
      "Ep: 69/200, it: 401/468, err: 0.0259\n",
      "Ep: 69/200, it: 451/468, err: 0.0028\n",
      "Ep: 69/200, it: 468/468, err: 0.0624\n",
      "Test acc: 99.26\n",
      "[[ 978    0    0    0    0    1    0    1    0    0]\n",
      " [   0 1127    0    2    1    1    1    3    0    0]\n",
      " [   2    2 1018    2    1    0    0    5    2    0]\n",
      " [   0    0    0 1004    0    3    0    0    3    0]\n",
      " [   0    0    0    0  977    0    1    0    0    4]\n",
      " [   1    0    0    4    0  887    0    0    0    0]\n",
      " [   1    2    0    0    2    5  947    0    1    0]\n",
      " [   0    3    2    1    0    0    0 1021    0    1]\n",
      " [   0    0    2    2    0    1    0    0  967    2]\n",
      " [   0    0    0    0    7    0    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6698e-04.\n",
      "Ep: 70/200, it: 1/468, err: 0.0064\n",
      "Ep: 70/200, it: 51/468, err: 0.0044\n",
      "Ep: 70/200, it: 101/468, err: 0.0007\n",
      "Ep: 70/200, it: 151/468, err: 0.0366\n",
      "Ep: 70/200, it: 201/468, err: 0.0255\n",
      "Ep: 70/200, it: 251/468, err: 0.0295\n",
      "Ep: 70/200, it: 301/468, err: 0.0264\n",
      "Ep: 70/200, it: 351/468, err: 0.0679\n",
      "Ep: 70/200, it: 401/468, err: 0.0044\n",
      "Ep: 70/200, it: 451/468, err: 0.0074\n",
      "Ep: 70/200, it: 468/468, err: 0.0117\n",
      "Test acc: 99.07\n",
      "[[ 976    0    1    0    0    0    0    1    2    0]\n",
      " [   1 1107    2    1    3    2    5    4    9    1]\n",
      " [   0    0 1026    0    1    0    0    2    3    0]\n",
      " [   0    1    3  992    0    7    0    0    6    1]\n",
      " [   0    0    1    0  974    0    2    1    0    4]\n",
      " [   1    0    0    0    0  890    1    0    0    0]\n",
      " [   1    2    1    0    1    2  951    0    0    0]\n",
      " [   0    1    3    1    0    0    0 1023    0    0]\n",
      " [   0    0    4    0    0    0    0    0  969    1]\n",
      " [   0    0    0    0    4    4    0    2    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6350e-04.\n",
      "Ep: 71/200, it: 1/468, err: 0.0078\n",
      "Ep: 71/200, it: 51/468, err: 0.0660\n",
      "Ep: 71/200, it: 101/468, err: 0.0165\n",
      "Ep: 71/200, it: 151/468, err: 0.0105\n",
      "Ep: 71/200, it: 201/468, err: 0.0114\n",
      "Ep: 71/200, it: 251/468, err: 0.0140\n",
      "Ep: 71/200, it: 301/468, err: 0.0249\n",
      "Ep: 71/200, it: 351/468, err: 0.0628\n",
      "Ep: 71/200, it: 401/468, err: 0.0041\n",
      "Ep: 71/200, it: 451/468, err: 0.0132\n",
      "Ep: 71/200, it: 468/468, err: 0.0053\n",
      "Test acc: 99.31\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1133    0    0    0    1    0    1    0    0]\n",
      " [   4    0 1020    0    1    0    0    5    2    0]\n",
      " [   0    0    0 1004    0    3    0    0    2    1]\n",
      " [   0    0    0    0  977    0    3    0    0    2]\n",
      " [   1    0    0    4    0  886    1    0    0    0]\n",
      " [   1    1    2    0    3    2  947    0    2    0]\n",
      " [   0    6    3    1    1    0    0 1017    0    0]\n",
      " [   1    0    1    2    0    1    0    0  968    1]\n",
      " [   0    0    0    0    5    2    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5998e-04.\n",
      "Ep: 72/200, it: 1/468, err: 0.0066\n",
      "Ep: 72/200, it: 51/468, err: 0.0293\n",
      "Ep: 72/200, it: 101/468, err: 0.0058\n",
      "Ep: 72/200, it: 151/468, err: 0.0067\n",
      "Ep: 72/200, it: 201/468, err: 0.0087\n",
      "Ep: 72/200, it: 251/468, err: 0.0170\n",
      "Ep: 72/200, it: 301/468, err: 0.0018\n",
      "Ep: 72/200, it: 351/468, err: 0.0108\n",
      "Ep: 72/200, it: 401/468, err: 0.0036\n",
      "Ep: 72/200, it: 451/468, err: 0.0009\n",
      "Ep: 72/200, it: 468/468, err: 0.0082\n",
      "Test acc: 99.31\n",
      "[[ 978    0    0    0    0    0    0    1    1    0]\n",
      " [   0 1131    1    1    0    1    1    0    0    0]\n",
      " [   0    0 1025    1    2    0    0    3    1    0]\n",
      " [   0    0    1 1001    0    4    0    2    2    0]\n",
      " [   0    1    0    0  972    0    3    0    0    6]\n",
      " [   2    0    0    2    0  884    1    1    1    1]\n",
      " [   1    4    0    0    0    2  950    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    5    1    0    0    0    1  966    1]\n",
      " [   0    0    1    0    4    1    0    2    1 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5644e-04.\n",
      "Ep: 73/200, it: 1/468, err: 0.0179\n",
      "Ep: 73/200, it: 51/468, err: 0.0397\n",
      "Ep: 73/200, it: 101/468, err: 0.0034\n",
      "Ep: 73/200, it: 151/468, err: 0.0586\n",
      "Ep: 73/200, it: 201/468, err: 0.0242\n",
      "Ep: 73/200, it: 251/468, err: 0.0440\n",
      "Ep: 73/200, it: 301/468, err: 0.0186\n",
      "Ep: 73/200, it: 351/468, err: 0.0362\n",
      "Ep: 73/200, it: 401/468, err: 0.0025\n",
      "Ep: 73/200, it: 451/468, err: 0.0157\n",
      "Ep: 73/200, it: 468/468, err: 0.0258\n",
      "Test acc: 99.27\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1131    0    1    0    0    2    1    0    0]\n",
      " [   2    0 1022    0    0    0    0    4    4    0]\n",
      " [   0    0    0 1005    0    2    0    1    2    0]\n",
      " [   0    1    0    0  971    0    3    0    0    7]\n",
      " [   0    0    0    5    0  884    1    1    0    1]\n",
      " [   3    4    0    0    0    1  948    0    2    0]\n",
      " [   0    2    2    0    0    0    0 1023    0    1]\n",
      " [   0    0    0    2    0    0    0    1  968    3]\n",
      " [   3    0    0    0    4    0    0    4    2  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5288e-04.\n",
      "Ep: 74/200, it: 1/468, err: 0.0203\n",
      "Ep: 74/200, it: 51/468, err: 0.0049\n",
      "Ep: 74/200, it: 101/468, err: 0.0021\n",
      "Ep: 74/200, it: 151/468, err: 0.0207\n",
      "Ep: 74/200, it: 201/468, err: 0.0047\n",
      "Ep: 74/200, it: 251/468, err: 0.0016\n",
      "Ep: 74/200, it: 301/468, err: 0.0095\n",
      "Ep: 74/200, it: 351/468, err: 0.0046\n",
      "Ep: 74/200, it: 401/468, err: 0.0197\n",
      "Ep: 74/200, it: 451/468, err: 0.0092\n",
      "Ep: 74/200, it: 468/468, err: 0.0192\n",
      "Test acc: 99.25\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    1    0    1    1    0    0]\n",
      " [   0    1 1025    0    1    0    0    3    2    0]\n",
      " [   0    1    0 1004    0    2    0    0    2    1]\n",
      " [   0    0    0    0  968    0    3    2    0    9]\n",
      " [   1    0    0    2    0  883    2    2    1    1]\n",
      " [   3    3    0    0    0    1  951    0    0    0]\n",
      " [   0    2    3    0    0    0    0 1022    0    1]\n",
      " [   0    0    2    2    0    2    0    1  964    3]\n",
      " [   0    1    0    0    6    2    0    1    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4929e-04.\n",
      "Ep: 75/200, it: 1/468, err: 0.0019\n",
      "Ep: 75/200, it: 51/468, err: 0.0796\n",
      "Ep: 75/200, it: 101/468, err: 0.0073\n",
      "Ep: 75/200, it: 151/468, err: 0.0037\n",
      "Ep: 75/200, it: 201/468, err: 0.0214\n",
      "Ep: 75/200, it: 251/468, err: 0.0110\n",
      "Ep: 75/200, it: 301/468, err: 0.0012\n",
      "Ep: 75/200, it: 351/468, err: 0.0046\n",
      "Ep: 75/200, it: 401/468, err: 0.0527\n",
      "Ep: 75/200, it: 451/468, err: 0.0079\n",
      "Ep: 75/200, it: 468/468, err: 0.0057\n",
      "Test acc: 99.23\n",
      "[[ 977    0    2    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    1    0    0    0    3    0    0]\n",
      " [   0    0 1026    0    1    0    0    3    1    1]\n",
      " [   0    0    2 1005    0    1    0    0    2    0]\n",
      " [   0    0    0    0  972    0    1    0    1    8]\n",
      " [   1    0    0    3    0  886    2    0    0    0]\n",
      " [   1    4    1    0    1    1  948    0    2    0]\n",
      " [   0    1    1    4    0    0    0 1018    0    4]\n",
      " [   0    0    2    4    0    2    0    1  961    4]\n",
      " [   0    0    0    0    3    4    0    3    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4567e-04.\n",
      "Ep: 76/200, it: 1/468, err: 0.0420\n",
      "Ep: 76/200, it: 51/468, err: 0.0212\n",
      "Ep: 76/200, it: 101/468, err: 0.0334\n",
      "Ep: 76/200, it: 151/468, err: 0.0035\n",
      "Ep: 76/200, it: 201/468, err: 0.0147\n",
      "Ep: 76/200, it: 251/468, err: 0.0019\n",
      "Ep: 76/200, it: 301/468, err: 0.0521\n",
      "Ep: 76/200, it: 351/468, err: 0.0041\n",
      "Ep: 76/200, it: 401/468, err: 0.0034\n",
      "Ep: 76/200, it: 451/468, err: 0.0136\n",
      "Ep: 76/200, it: 468/468, err: 0.0658\n",
      "Test acc: 99.17\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1026    0    1    0    0    3    2    0]\n",
      " [   0    1    0 1001    0    5    0    1    2    0]\n",
      " [   0    1    1    0  976    0    2    0    0    2]\n",
      " [   1    0    0    2    0  883    3    2    1    0]\n",
      " [   2    5    0    0    0    1  950    0    0    0]\n",
      " [   0    4    1    0    0    0    0 1023    0    0]\n",
      " [   1    0    6    4    0    1    0    1  958    3]\n",
      " [   0    1    0    3    6    1    0    8    0  990]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4203e-04.\n",
      "Ep: 77/200, it: 1/468, err: 0.0092\n",
      "Ep: 77/200, it: 51/468, err: 0.0598\n",
      "Ep: 77/200, it: 101/468, err: 0.0046\n",
      "Ep: 77/200, it: 151/468, err: 0.0062\n",
      "Ep: 77/200, it: 201/468, err: 0.0068\n",
      "Ep: 77/200, it: 251/468, err: 0.0308\n",
      "Ep: 77/200, it: 301/468, err: 0.0598\n",
      "Ep: 77/200, it: 351/468, err: 0.0023\n",
      "Ep: 77/200, it: 401/468, err: 0.0055\n",
      "Ep: 77/200, it: 451/468, err: 0.0074\n",
      "Ep: 77/200, it: 468/468, err: 0.0164\n",
      "Test acc: 99.08\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   3 1125    1    0    1    0    2    0    2    1]\n",
      " [   2    0 1022    0    1    0    0    5    2    0]\n",
      " [   0    1    0 1001    0    3    0    1    3    1]\n",
      " [   0    0    0    0  978    0    1    0    0    3]\n",
      " [   3    0    0    2    0  883    0    2    0    2]\n",
      " [   4    2    0    0    0    1  948    0    3    0]\n",
      " [   0    8    2    0    3    0    0 1012    0    3]\n",
      " [   2    0    2    1    0    0    0    0  967    2]\n",
      " [   0    0    0    0   11    1    0    3    1  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3837e-04.\n",
      "Ep: 78/200, it: 1/468, err: 0.0028\n",
      "Ep: 78/200, it: 51/468, err: 0.0303\n",
      "Ep: 78/200, it: 101/468, err: 0.0026\n",
      "Ep: 78/200, it: 151/468, err: 0.0068\n",
      "Ep: 78/200, it: 201/468, err: 0.0026\n",
      "Ep: 78/200, it: 251/468, err: 0.0041\n",
      "Ep: 78/200, it: 301/468, err: 0.0204\n",
      "Ep: 78/200, it: 351/468, err: 0.0419\n",
      "Ep: 78/200, it: 401/468, err: 0.0105\n",
      "Ep: 78/200, it: 451/468, err: 0.0072\n",
      "Ep: 78/200, it: 468/468, err: 0.0209\n",
      "Test acc: 99.24\n",
      "[[ 977    0    0    0    0    0    0    1    2    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1023    0    1    0    0    7    1    0]\n",
      " [   0    1    0 1005    0    2    0    0    2    0]\n",
      " [   0    0    0    0  979    0    0    0    0    3]\n",
      " [   0    0    0    3    0  888    0    1    0    0]\n",
      " [   1    4    1    0    0    2  947    0    3    0]\n",
      " [   0    2    3    1    2    0    0 1020    0    0]\n",
      " [   0    0    2    3    0    1    0    1  965    2]\n",
      " [   0    0    0    2   11    5    0    3    2  986]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3468e-04.\n",
      "Ep: 79/200, it: 1/468, err: 0.0159\n",
      "Ep: 79/200, it: 51/468, err: 0.0087\n",
      "Ep: 79/200, it: 101/468, err: 0.0034\n",
      "Ep: 79/200, it: 151/468, err: 0.0052\n",
      "Ep: 79/200, it: 201/468, err: 0.1542\n",
      "Ep: 79/200, it: 251/468, err: 0.0026\n",
      "Ep: 79/200, it: 301/468, err: 0.0636\n",
      "Ep: 79/200, it: 351/468, err: 0.0035\n",
      "Ep: 79/200, it: 401/468, err: 0.0015\n",
      "Ep: 79/200, it: 451/468, err: 0.0296\n",
      "Ep: 79/200, it: 468/468, err: 0.0237\n",
      "Test acc: 99.20\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   1 1129    0    1    0    0    2    1    1    0]\n",
      " [   1    0 1026    0    1    1    0    2    1    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  969    0    5    0    1    7]\n",
      " [   1    0    0    1    0  887    2    1    0    0]\n",
      " [   2    2    0    0    0    1  952    0    1    0]\n",
      " [   0    3    3    2    1    0    0 1018    0    1]\n",
      " [   4    0    3    6    0    1    0    0  959    1]\n",
      " [   2    0    1    1    3    1    0    3    3  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3098e-04.\n",
      "Ep: 80/200, it: 1/468, err: 0.0152\n",
      "Ep: 80/200, it: 51/468, err: 0.0590\n",
      "Ep: 80/200, it: 101/468, err: 0.0316\n",
      "Ep: 80/200, it: 151/468, err: 0.0014\n",
      "Ep: 80/200, it: 201/468, err: 0.0291\n",
      "Ep: 80/200, it: 251/468, err: 0.0247\n",
      "Ep: 80/200, it: 301/468, err: 0.0058\n",
      "Ep: 80/200, it: 351/468, err: 0.0011\n",
      "Ep: 80/200, it: 401/468, err: 0.0067\n",
      "Ep: 80/200, it: 451/468, err: 0.0100\n",
      "Ep: 80/200, it: 468/468, err: 0.0326\n",
      "Test acc: 99.27\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1128    0    2    1    0    1    3    0    0]\n",
      " [   0    0 1029    0    0    0    0    3    0    0]\n",
      " [   0    0    1  994    0    8    0    1    3    3]\n",
      " [   0    0    0    0  976    0    0    0    0    6]\n",
      " [   1    0    0    0    0  890    1    0    0    0]\n",
      " [   1    3    0    0    3    3  946    0    2    0]\n",
      " [   0    2    2    1    1    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    1  966    4]\n",
      " [   0    0    0    1    4    1    0    3    2  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2725e-04.\n",
      "Ep: 81/200, it: 1/468, err: 0.0075\n",
      "Ep: 81/200, it: 51/468, err: 0.0009\n",
      "Ep: 81/200, it: 101/468, err: 0.0205\n",
      "Ep: 81/200, it: 151/468, err: 0.0038\n",
      "Ep: 81/200, it: 201/468, err: 0.0225\n",
      "Ep: 81/200, it: 251/468, err: 0.0015\n",
      "Ep: 81/200, it: 301/468, err: 0.0663\n",
      "Ep: 81/200, it: 351/468, err: 0.0043\n",
      "Ep: 81/200, it: 401/468, err: 0.0597\n",
      "Ep: 81/200, it: 451/468, err: 0.0104\n",
      "Ep: 81/200, it: 468/468, err: 0.0017\n",
      "Test acc: 99.26\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    0    0    0    0    1    2    0]\n",
      " [   0    1    0 1003    0    3    0    0    3    0]\n",
      " [   0    1    0    0  964    0    5    0    1   11]\n",
      " [   0    0    0    2    0  888    1    0    0    1]\n",
      " [   1    4    0    0    1    4  946    0    2    0]\n",
      " [   0    1    2    1    0    0    0 1023    1    0]\n",
      " [   0    0    1    2    0    1    0    1  967    2]\n",
      " [   0    0    0    2    3    3    0    4    1  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2351e-04.\n",
      "Ep: 82/200, it: 1/468, err: 0.0038\n",
      "Ep: 82/200, it: 51/468, err: 0.0027\n",
      "Ep: 82/200, it: 101/468, err: 0.0002\n",
      "Ep: 82/200, it: 151/468, err: 0.0036\n",
      "Ep: 82/200, it: 201/468, err: 0.0095\n",
      "Ep: 82/200, it: 251/468, err: 0.0020\n",
      "Ep: 82/200, it: 301/468, err: 0.0199\n",
      "Ep: 82/200, it: 351/468, err: 0.0086\n",
      "Ep: 82/200, it: 401/468, err: 0.0011\n",
      "Ep: 82/200, it: 451/468, err: 0.0198\n",
      "Ep: 82/200, it: 468/468, err: 0.0141\n",
      "Test acc: 99.23\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1130    0    0    2    0    1    2    0    0]\n",
      " [   0    2 1025    0    1    1    0    3    0    0]\n",
      " [   0    0    0 1003    0    3    0    0    4    0]\n",
      " [   0    0    0    0  978    0    1    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   2    3    1    0    5    2  942    0    3    0]\n",
      " [   0    2    8    2    0    0    0 1016    0    0]\n",
      " [   1    0    1    2    0    1    0    0  967    2]\n",
      " [   1    0    0    1    9    2    0    2    0  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1975e-04.\n",
      "Ep: 83/200, it: 1/468, err: 0.0030\n",
      "Ep: 83/200, it: 51/468, err: 0.0182\n",
      "Ep: 83/200, it: 101/468, err: 0.0214\n",
      "Ep: 83/200, it: 151/468, err: 0.0237\n",
      "Ep: 83/200, it: 201/468, err: 0.0007\n",
      "Ep: 83/200, it: 251/468, err: 0.0288\n",
      "Ep: 83/200, it: 301/468, err: 0.0071\n",
      "Ep: 83/200, it: 351/468, err: 0.0035\n",
      "Ep: 83/200, it: 401/468, err: 0.0135\n",
      "Ep: 83/200, it: 451/468, err: 0.0049\n",
      "Ep: 83/200, it: 468/468, err: 0.0009\n",
      "Test acc: 99.34\n",
      "[[ 975    0    1    0    0    0    3    1    0    0]\n",
      " [   0 1129    2    0    0    0    0    4    0    0]\n",
      " [   0    0 1029    0    0    0    0    2    1    0]\n",
      " [   0    1    0 1003    0    3    0    1    2    0]\n",
      " [   0    0    1    0  977    0    2    0    0    2]\n",
      " [   0    0    0    6    0  885    1    0    0    0]\n",
      " [   2    5    0    0    0    1  948    0    2    0]\n",
      " [   0    2    4    0    1    0    0 1021    0    0]\n",
      " [   0    0    2    2    0    0    0    0  969    1]\n",
      " [   1    1    0    0    7    1    0    1    0  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1597e-04.\n",
      "Ep: 84/200, it: 1/468, err: 0.0018\n",
      "Ep: 84/200, it: 51/468, err: 0.0017\n",
      "Ep: 84/200, it: 101/468, err: 0.0359\n",
      "Ep: 84/200, it: 151/468, err: 0.0206\n",
      "Ep: 84/200, it: 201/468, err: 0.0020\n",
      "Ep: 84/200, it: 251/468, err: 0.0222\n",
      "Ep: 84/200, it: 301/468, err: 0.0942\n",
      "Ep: 84/200, it: 351/468, err: 0.0048\n",
      "Ep: 84/200, it: 401/468, err: 0.0043\n",
      "Ep: 84/200, it: 451/468, err: 0.0268\n",
      "Ep: 84/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.28\n",
      "[[ 975    0    1    0    0    1    1    1    1    0]\n",
      " [   0 1130    0    0    0    0    2    2    1    0]\n",
      " [   0    0 1026    0    0    0    0    3    3    0]\n",
      " [   0    0    0 1004    0    5    0    0    1    0]\n",
      " [   0    0    0    0  974    0    5    0    1    2]\n",
      " [   0    0    0    2    0  889    1    0    0    0]\n",
      " [   2    0    0    0    0    1  954    0    1    0]\n",
      " [   0    4    4    4    1    0    0 1012    1    2]\n",
      " [   0    0    2    1    0    1    0    0  969    1]\n",
      " [   0    0    0    0    8    2    0    1    3  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1217e-04.\n",
      "Ep: 85/200, it: 1/468, err: 0.0029\n",
      "Ep: 85/200, it: 51/468, err: 0.0295\n",
      "Ep: 85/200, it: 101/468, err: 0.0346\n",
      "Ep: 85/200, it: 151/468, err: 0.0861\n",
      "Ep: 85/200, it: 201/468, err: 0.0094\n",
      "Ep: 85/200, it: 251/468, err: 0.0017\n",
      "Ep: 85/200, it: 301/468, err: 0.0254\n",
      "Ep: 85/200, it: 351/468, err: 0.0059\n",
      "Ep: 85/200, it: 401/468, err: 0.0014\n",
      "Ep: 85/200, it: 451/468, err: 0.0082\n",
      "Ep: 85/200, it: 468/468, err: 0.0023\n",
      "Test acc: 99.28\n",
      "[[ 977    0    1    0    0    0    0    2    0    0]\n",
      " [   0 1131    1    0    0    0    1    1    0    1]\n",
      " [   0    0 1027    0    0    0    0    3    2    0]\n",
      " [   0    1    2  999    0    4    0    1    3    0]\n",
      " [   0    0    0    0  974    0    2    0    0    6]\n",
      " [   1    0    1    1    0  888    1    0    0    0]\n",
      " [   4    3    0    0    0    2  946    0    3    0]\n",
      " [   0    2    3    1    0    0    0 1019    0    3]\n",
      " [   0    0    1    2    0    0    0    1  969    1]\n",
      " [   0    0    0    1    2    3    0    0    5  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0836e-04.\n",
      "Ep: 86/200, it: 1/468, err: 0.0227\n",
      "Ep: 86/200, it: 51/468, err: 0.0041\n",
      "Ep: 86/200, it: 101/468, err: 0.0016\n",
      "Ep: 86/200, it: 151/468, err: 0.0015\n",
      "Ep: 86/200, it: 201/468, err: 0.0163\n",
      "Ep: 86/200, it: 251/468, err: 0.0023\n",
      "Ep: 86/200, it: 301/468, err: 0.0017\n",
      "Ep: 86/200, it: 351/468, err: 0.0035\n",
      "Ep: 86/200, it: 401/468, err: 0.0083\n",
      "Ep: 86/200, it: 451/468, err: 0.0142\n",
      "Ep: 86/200, it: 468/468, err: 0.0037\n",
      "Test acc: 99.40\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1129    1    0    1    0    0    4    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1009    0    1    0    0    0    0]\n",
      " [   0    0    0    0  977    0    2    0    0    3]\n",
      " [   0    0    0    7    0  883    1    1    0    0]\n",
      " [   1    3    0    0    0    2  950    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    3    3    0    1    0    1  963    3]\n",
      " [   0    0    0    1    5    0    0    2    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0454e-04.\n",
      "Ep: 87/200, it: 1/468, err: 0.0323\n",
      "Ep: 87/200, it: 51/468, err: 0.0085\n",
      "Ep: 87/200, it: 101/468, err: 0.0011\n",
      "Ep: 87/200, it: 151/468, err: 0.0170\n",
      "Ep: 87/200, it: 201/468, err: 0.0024\n",
      "Ep: 87/200, it: 251/468, err: 0.0005\n",
      "Ep: 87/200, it: 301/468, err: 0.0230\n",
      "Ep: 87/200, it: 351/468, err: 0.0043\n",
      "Ep: 87/200, it: 401/468, err: 0.0644\n",
      "Ep: 87/200, it: 451/468, err: 0.0023\n",
      "Ep: 87/200, it: 468/468, err: 0.0021\n",
      "Test acc: 99.33\n",
      "[[ 978    0    0    0    0    0    0    1    1    0]\n",
      " [   0 1130    0    1    0    0    1    3    0    0]\n",
      " [   0    0 1029    0    0    0    0    3    0    0]\n",
      " [   0    0    0 1008    0    0    0    1    1    0]\n",
      " [   0    1    0    0  974    0    3    1    0    3]\n",
      " [   1    0    0   11    0  876    1    3    0    0]\n",
      " [   2    2    0    0    0    1  952    0    1    0]\n",
      " [   0    1    3    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    4    0    1    0    1  965    2]\n",
      " [   1    0    0    1    3    1    0    6    0  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0070e-04.\n",
      "Ep: 88/200, it: 1/468, err: 0.0080\n",
      "Ep: 88/200, it: 51/468, err: 0.0458\n",
      "Ep: 88/200, it: 101/468, err: 0.0212\n",
      "Ep: 88/200, it: 151/468, err: 0.0069\n",
      "Ep: 88/200, it: 201/468, err: 0.0055\n",
      "Ep: 88/200, it: 251/468, err: 0.0027\n",
      "Ep: 88/200, it: 301/468, err: 0.0041\n",
      "Ep: 88/200, it: 351/468, err: 0.0027\n",
      "Ep: 88/200, it: 401/468, err: 0.0002\n",
      "Ep: 88/200, it: 451/468, err: 0.0236\n",
      "Ep: 88/200, it: 468/468, err: 0.0023\n",
      "Test acc: 99.35\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1128    0    2    0    0    1    4    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1004    0    5    0    0    1    0]\n",
      " [   0    0    0    0  974    0    2    0    0    6]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   3    3    0    0    0    4  947    0    1    0]\n",
      " [   0    0    3    0    1    0    0 1024    0    0]\n",
      " [   0    0    2    3    0    2    0    0  963    4]\n",
      " [   0    0    0    1    7    1    0    1    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9685e-04.\n",
      "Ep: 89/200, it: 1/468, err: 0.0005\n",
      "Ep: 89/200, it: 51/468, err: 0.0010\n",
      "Ep: 89/200, it: 101/468, err: 0.0060\n",
      "Ep: 89/200, it: 151/468, err: 0.0018\n",
      "Ep: 89/200, it: 201/468, err: 0.0171\n",
      "Ep: 89/200, it: 251/468, err: 0.0037\n",
      "Ep: 89/200, it: 301/468, err: 0.0165\n",
      "Ep: 89/200, it: 351/468, err: 0.0032\n",
      "Ep: 89/200, it: 401/468, err: 0.0052\n",
      "Ep: 89/200, it: 451/468, err: 0.0097\n",
      "Ep: 89/200, it: 468/468, err: 0.0195\n",
      "Test acc: 99.47\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    0    0    0    2    2    0    0]\n",
      " [   0    0 1028    0    1    0    0    2    1    0]\n",
      " [   0    1    0 1006    0    2    0    0    1    0]\n",
      " [   0    0    0    0  977    0    2    0    0    3]\n",
      " [   0    0    0    3    0  889    0    0    0    0]\n",
      " [   1    3    0    0    0    1  952    0    1    0]\n",
      " [   0    4    3    0    0    0    0 1021    0    0]\n",
      " [   0    0    4    2    0    0    0    1  966    1]\n",
      " [   0    0    0    4    4    2    0    0    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9298e-04.\n",
      "Ep: 90/200, it: 1/468, err: 0.0719\n",
      "Ep: 90/200, it: 51/468, err: 0.0022\n",
      "Ep: 90/200, it: 101/468, err: 0.0014\n",
      "Ep: 90/200, it: 151/468, err: 0.0217\n",
      "Ep: 90/200, it: 201/468, err: 0.0017\n",
      "Ep: 90/200, it: 251/468, err: 0.0114\n",
      "Ep: 90/200, it: 301/468, err: 0.0023\n",
      "Ep: 90/200, it: 351/468, err: 0.0012\n",
      "Ep: 90/200, it: 401/468, err: 0.0021\n",
      "Ep: 90/200, it: 451/468, err: 0.0093\n",
      "Ep: 90/200, it: 468/468, err: 0.0091\n",
      "Test acc: 99.27\n",
      "[[ 977    0    1    0    0    1    0    1    0    0]\n",
      " [   0 1128    1    1    1    0    2    2    0    0]\n",
      " [   0    1 1029    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1002    0    7    0    0    1    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   0    0    1    4    0  882    3    1    0    1]\n",
      " [   1    1    1    0    0    1  954    0    0    0]\n",
      " [   0    5    4    1    0    0    0 1015    1    2]\n",
      " [   0    0    0    4    0    1    0    0  968    1]\n",
      " [   0    1    0    1    3    1    0    1    3  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8911e-04.\n",
      "Ep: 91/200, it: 1/468, err: 0.0057\n",
      "Ep: 91/200, it: 51/468, err: 0.0076\n",
      "Ep: 91/200, it: 101/468, err: 0.0336\n",
      "Ep: 91/200, it: 151/468, err: 0.0063\n",
      "Ep: 91/200, it: 201/468, err: 0.0111\n",
      "Ep: 91/200, it: 251/468, err: 0.0003\n",
      "Ep: 91/200, it: 301/468, err: 0.0122\n",
      "Ep: 91/200, it: 351/468, err: 0.0085\n",
      "Ep: 91/200, it: 401/468, err: 0.0015\n",
      "Ep: 91/200, it: 451/468, err: 0.0003\n",
      "Ep: 91/200, it: 468/468, err: 0.0122\n",
      "Test acc: 99.25\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1130    0    2    1    0    1    1    0    0]\n",
      " [   0    1 1024    0    1    0    0    3    3    0]\n",
      " [   0    0    0 1002    0    5    0    1    2    0]\n",
      " [   0    0    0    0  977    0    2    0    0    3]\n",
      " [   0    0    0    2    0  889    1    0    0    0]\n",
      " [   2    4    0    0    0    4  947    0    1    0]\n",
      " [   0    5    2    0    1    0    0 1019    0    1]\n",
      " [   1    0    0    2    1    1    0    0  967    2]\n",
      " [   0    0    0    2   11    1    0    2    0  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8523e-04.\n",
      "Ep: 92/200, it: 1/468, err: 0.0016\n",
      "Ep: 92/200, it: 51/468, err: 0.0006\n",
      "Ep: 92/200, it: 101/468, err: 0.0075\n",
      "Ep: 92/200, it: 151/468, err: 0.0005\n",
      "Ep: 92/200, it: 201/468, err: 0.0052\n",
      "Ep: 92/200, it: 251/468, err: 0.0232\n",
      "Ep: 92/200, it: 301/468, err: 0.0012\n",
      "Ep: 92/200, it: 351/468, err: 0.0139\n",
      "Ep: 92/200, it: 401/468, err: 0.0064\n",
      "Ep: 92/200, it: 451/468, err: 0.0080\n",
      "Ep: 92/200, it: 468/468, err: 0.0032\n",
      "Test acc: 99.30\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    1 1028    0    0    0    0    1    2    0]\n",
      " [   0    1    0 1001    0    8    0    0    0    0]\n",
      " [   0    0    0    0  974    0    3    0    0    5]\n",
      " [   1    0    0    1    0  887    1    2    0    0]\n",
      " [   1    2    0    0    1    1  950    0    3    0]\n",
      " [   0    5    3    0    2    0    0 1018    0    0]\n",
      " [   1    0    1    2    1    1    0    1  965    2]\n",
      " [   0    0    1    1   10    1    0    1    0  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8133e-04.\n",
      "Ep: 93/200, it: 1/468, err: 0.0003\n",
      "Ep: 93/200, it: 51/468, err: 0.0006\n",
      "Ep: 93/200, it: 101/468, err: 0.0353\n",
      "Ep: 93/200, it: 151/468, err: 0.0055\n",
      "Ep: 93/200, it: 201/468, err: 0.0073\n",
      "Ep: 93/200, it: 251/468, err: 0.0128\n",
      "Ep: 93/200, it: 301/468, err: 0.0249\n",
      "Ep: 93/200, it: 351/468, err: 0.0142\n",
      "Ep: 93/200, it: 401/468, err: 0.0082\n",
      "Ep: 93/200, it: 451/468, err: 0.0024\n",
      "Ep: 93/200, it: 468/468, err: 0.0074\n",
      "Test acc: 99.35\n",
      "[[ 979    0    1    0    0    0    0    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1026    0    0    0    0    5    1    0]\n",
      " [   0    0    0 1007    0    3    0    0    0    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    2    0  886    1    2    0    0]\n",
      " [   3    3    0    0    2    2  947    0    1    0]\n",
      " [   0    3    1    1    3    0    0 1020    0    0]\n",
      " [   1    0    1    3    0    0    1    0  967    1]\n",
      " [   0    1    0    3    6    1    0    2    0  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7743e-04.\n",
      "Ep: 94/200, it: 1/468, err: 0.0076\n",
      "Ep: 94/200, it: 51/468, err: 0.0664\n",
      "Ep: 94/200, it: 101/468, err: 0.0020\n",
      "Ep: 94/200, it: 151/468, err: 0.0024\n",
      "Ep: 94/200, it: 201/468, err: 0.0057\n",
      "Ep: 94/200, it: 251/468, err: 0.0043\n",
      "Ep: 94/200, it: 301/468, err: 0.0031\n",
      "Ep: 94/200, it: 351/468, err: 0.0026\n",
      "Ep: 94/200, it: 401/468, err: 0.0063\n",
      "Ep: 94/200, it: 451/468, err: 0.0365\n",
      "Ep: 94/200, it: 468/468, err: 0.0146\n",
      "Test acc: 99.37\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    0    0    0    0    2    1    0]\n",
      " [   0    0    0 1005    0    4    0    1    0    0]\n",
      " [   0    0    0    0  966    0    5    3    0    8]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    2    0    0    0    1  952    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1022    0    1]\n",
      " [   0    0    1    3    0    1    0    0  967    2]\n",
      " [   0    0    0    1    3    2    0    2    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7353e-04.\n",
      "Ep: 95/200, it: 1/468, err: 0.0224\n",
      "Ep: 95/200, it: 51/468, err: 0.0026\n",
      "Ep: 95/200, it: 101/468, err: 0.0503\n",
      "Ep: 95/200, it: 151/468, err: 0.0007\n",
      "Ep: 95/200, it: 201/468, err: 0.0055\n",
      "Ep: 95/200, it: 251/468, err: 0.0033\n",
      "Ep: 95/200, it: 301/468, err: 0.0143\n",
      "Ep: 95/200, it: 351/468, err: 0.0015\n",
      "Ep: 95/200, it: 401/468, err: 0.0030\n",
      "Ep: 95/200, it: 451/468, err: 0.0017\n",
      "Ep: 95/200, it: 468/468, err: 0.0280\n",
      "Test acc: 99.33\n",
      "[[ 975    0    0    0    1    0    3    1    0    0]\n",
      " [   0 1132    0    0    2    0    1    0    0    0]\n",
      " [   0    3 1026    0    1    0    0    2    0    0]\n",
      " [   0    0    0 1006    0    1    0    1    2    0]\n",
      " [   0    0    0    0  976    0    4    0    0    2]\n",
      " [   0    0    0    3    0  888    1    0    0    0]\n",
      " [   1    3    0    0    0    2  952    0    0    0]\n",
      " [   0    6    2    0    1    0    0 1018    0    1]\n",
      " [   1    0    2    2    0    1    0    0  967    1]\n",
      " [   0    0    0    0   13    2    0    1    0  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6961e-04.\n",
      "Ep: 96/200, it: 1/468, err: 0.0003\n",
      "Ep: 96/200, it: 51/468, err: 0.0145\n",
      "Ep: 96/200, it: 101/468, err: 0.0014\n",
      "Ep: 96/200, it: 151/468, err: 0.0321\n",
      "Ep: 96/200, it: 201/468, err: 0.0127\n",
      "Ep: 96/200, it: 251/468, err: 0.0206\n",
      "Ep: 96/200, it: 301/468, err: 0.0193\n",
      "Ep: 96/200, it: 351/468, err: 0.0003\n",
      "Ep: 96/200, it: 401/468, err: 0.0004\n",
      "Ep: 96/200, it: 451/468, err: 0.0430\n",
      "Ep: 96/200, it: 468/468, err: 0.0120\n",
      "Test acc: 99.35\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1128    1    0    1    0    1    4    0    0]\n",
      " [   0    0 1029    0    0    0    0    2    1    0]\n",
      " [   0    1    0 1004    0    4    0    0    1    0]\n",
      " [   0    0    0    0  970    0    3    0    0    9]\n",
      " [   2    0    0    2    0  886    1    1    0    0]\n",
      " [   3    0    1    0    1    1  951    0    1    0]\n",
      " [   0    3    2    0    0    0    0 1023    0    0]\n",
      " [   0    0    2    3    0    1    0    1  965    2]\n",
      " [   0    0    0    0    4    2    0    2    1 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6570e-04.\n",
      "Ep: 97/200, it: 1/468, err: 0.0082\n",
      "Ep: 97/200, it: 51/468, err: 0.0070\n",
      "Ep: 97/200, it: 101/468, err: 0.0108\n",
      "Ep: 97/200, it: 151/468, err: 0.0034\n",
      "Ep: 97/200, it: 201/468, err: 0.0012\n",
      "Ep: 97/200, it: 251/468, err: 0.0064\n",
      "Ep: 97/200, it: 301/468, err: 0.0045\n",
      "Ep: 97/200, it: 351/468, err: 0.0308\n",
      "Ep: 97/200, it: 401/468, err: 0.0003\n",
      "Ep: 97/200, it: 451/468, err: 0.0030\n",
      "Ep: 97/200, it: 468/468, err: 0.0041\n",
      "Test acc: 99.31\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1133    0    0    0    0    2    0    0    0]\n",
      " [   1    0 1025    0    0    0    0    4    2    0]\n",
      " [   0    1    0 1005    0    3    0    0    1    0]\n",
      " [   0    0    0    0  970    0    7    0    0    5]\n",
      " [   1    0    0    3    0  886    1    0    0    1]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    4    2    1    0    0    0 1017    0    4]\n",
      " [   1    0    2    2    1    1    0    0  966    1]\n",
      " [   0    0    0    1    3    2    0    0    2 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6178e-04.\n",
      "Ep: 98/200, it: 1/468, err: 0.0053\n",
      "Ep: 98/200, it: 51/468, err: 0.0431\n",
      "Ep: 98/200, it: 101/468, err: 0.0015\n",
      "Ep: 98/200, it: 151/468, err: 0.0002\n",
      "Ep: 98/200, it: 201/468, err: 0.0004\n",
      "Ep: 98/200, it: 251/468, err: 0.0006\n",
      "Ep: 98/200, it: 301/468, err: 0.0489\n",
      "Ep: 98/200, it: 351/468, err: 0.0012\n",
      "Ep: 98/200, it: 401/468, err: 0.0224\n",
      "Ep: 98/200, it: 451/468, err: 0.0046\n",
      "Ep: 98/200, it: 468/468, err: 0.0021\n",
      "Test acc: 99.34\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1028    0    0    0    0    2    2    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    1    0  975    0    3    0    1    2]\n",
      " [   0    0    0    7    0  884    1    0    0    0]\n",
      " [   2    3    0    0    0    1  951    0    1    0]\n",
      " [   0    3    3    3    0    0    0 1018    0    1]\n",
      " [   1    0    1    4    0    1    0    0  965    2]\n",
      " [   0    0    0    0   11    1    0    3    1  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5785e-04.\n",
      "Ep: 99/200, it: 1/468, err: 0.0003\n",
      "Ep: 99/200, it: 51/468, err: 0.0019\n",
      "Ep: 99/200, it: 101/468, err: 0.0020\n",
      "Ep: 99/200, it: 151/468, err: 0.0041\n",
      "Ep: 99/200, it: 201/468, err: 0.0015\n",
      "Ep: 99/200, it: 251/468, err: 0.0005\n",
      "Ep: 99/200, it: 301/468, err: 0.0068\n",
      "Ep: 99/200, it: 351/468, err: 0.0070\n",
      "Ep: 99/200, it: 401/468, err: 0.0169\n",
      "Ep: 99/200, it: 451/468, err: 0.0406\n",
      "Ep: 99/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.34\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1132    0    0    0    1    2    0    0    0]\n",
      " [   0    1 1026    0    0    0    0    2    3    0]\n",
      " [   0    0    0 1007    0    1    0    0    2    0]\n",
      " [   0    0    0    0  970    0    3    0    1    8]\n",
      " [   0    0    0    5    0  885    1    0    0    1]\n",
      " [   1    2    0    0    0    1  953    0    1    0]\n",
      " [   0    3    3    2    0    0    0 1014    0    6]\n",
      " [   0    0    2    4    0    0    0    1  965    2]\n",
      " [   0    0    0    0    2    1    0    0    0 1006]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5393e-04.\n",
      "Ep: 100/200, it: 1/468, err: 0.0037\n",
      "Ep: 100/200, it: 51/468, err: 0.0003\n",
      "Ep: 100/200, it: 101/468, err: 0.0010\n",
      "Ep: 100/200, it: 151/468, err: 0.0271\n",
      "Ep: 100/200, it: 201/468, err: 0.0027\n",
      "Ep: 100/200, it: 251/468, err: 0.0058\n",
      "Ep: 100/200, it: 301/468, err: 0.0172\n",
      "Ep: 100/200, it: 351/468, err: 0.0007\n",
      "Ep: 100/200, it: 401/468, err: 0.0009\n",
      "Ep: 100/200, it: 451/468, err: 0.0033\n",
      "Ep: 100/200, it: 468/468, err: 0.0005\n",
      "Test acc: 99.39\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0    1 1027    0    0    0    0    2    2    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   2    0    0    5    0  884    0    0    0    1]\n",
      " [   1    3    0    0    0    2  950    0    2    0]\n",
      " [   0    5    1    1    1    0    0 1020    0    0]\n",
      " [   1    0    0    5    0    0    0    2  965    1]\n",
      " [   0    0    0    1    7    1    0    0    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n",
      "Ep: 101/200, it: 1/468, err: 0.0009\n",
      "Ep: 101/200, it: 51/468, err: 0.0031\n",
      "Ep: 101/200, it: 101/468, err: 0.0130\n",
      "Ep: 101/200, it: 151/468, err: 0.0004\n",
      "Ep: 101/200, it: 201/468, err: 0.0090\n",
      "Ep: 101/200, it: 251/468, err: 0.0025\n",
      "Ep: 101/200, it: 301/468, err: 0.0029\n",
      "Ep: 101/200, it: 351/468, err: 0.0184\n",
      "Ep: 101/200, it: 401/468, err: 0.0006\n",
      "Ep: 101/200, it: 451/468, err: 0.0066\n",
      "Ep: 101/200, it: 468/468, err: 0.0139\n",
      "Test acc: 99.33\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    2    0    0    1    1    0    0]\n",
      " [   0    0 1030    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  967    0    4    0    0   11]\n",
      " [   1    0    0    2    0  887    1    1    0    0]\n",
      " [   4    4    0    0    0    2  946    0    2    0]\n",
      " [   0    6    2    2    0    0    0 1018    0    0]\n",
      " [   1    0    0    3    0    1    0    1  964    4]\n",
      " [   0    0    0    0    4    1    0    1    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4607e-04.\n",
      "Ep: 102/200, it: 1/468, err: 0.0024\n",
      "Ep: 102/200, it: 51/468, err: 0.0058\n",
      "Ep: 102/200, it: 101/468, err: 0.0237\n",
      "Ep: 102/200, it: 151/468, err: 0.0008\n",
      "Ep: 102/200, it: 201/468, err: 0.0024\n",
      "Ep: 102/200, it: 251/468, err: 0.0098\n",
      "Ep: 102/200, it: 301/468, err: 0.0020\n",
      "Ep: 102/200, it: 351/468, err: 0.0032\n",
      "Ep: 102/200, it: 401/468, err: 0.0016\n",
      "Ep: 102/200, it: 451/468, err: 0.0365\n",
      "Ep: 102/200, it: 468/468, err: 0.0005\n",
      "Test acc: 99.44\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1131    0    1    0    1    0    2    0    0]\n",
      " [   1    0 1028    0    0    0    0    3    0    0]\n",
      " [   0    0    1 1004    0    4    0    0    1    0]\n",
      " [   0    0    0    0  973    0    5    0    0    4]\n",
      " [   2    0    0    2    0  888    0    0    0    0]\n",
      " [   1    3    0    0    0    1  952    0    1    0]\n",
      " [   0    3    1    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    2    0    1    0    2  966    2]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4215e-04.\n",
      "Ep: 103/200, it: 1/468, err: 0.0004\n",
      "Ep: 103/200, it: 51/468, err: 0.0028\n",
      "Ep: 103/200, it: 101/468, err: 0.0011\n",
      "Ep: 103/200, it: 151/468, err: 0.0022\n",
      "Ep: 103/200, it: 201/468, err: 0.0007\n",
      "Ep: 103/200, it: 251/468, err: 0.0027\n",
      "Ep: 103/200, it: 301/468, err: 0.0002\n",
      "Ep: 103/200, it: 351/468, err: 0.0515\n",
      "Ep: 103/200, it: 401/468, err: 0.0585\n",
      "Ep: 103/200, it: 451/468, err: 0.0174\n",
      "Ep: 103/200, it: 468/468, err: 0.0126\n",
      "Test acc: 99.36\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    1    0    0    1    2    0    0]\n",
      " [   0    2 1023    0    0    0    0    3    4    0]\n",
      " [   0    0    0 1005    0    3    0    0    2    0]\n",
      " [   0    0    0    0  974    0    3    0    0    5]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   4    2    0    0    0    2  948    0    2    0]\n",
      " [   0    2    3    2    0    0    0 1019    1    1]\n",
      " [   0    0    0    2    0    1    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    0    5  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3822e-04.\n",
      "Ep: 104/200, it: 1/468, err: 0.0004\n",
      "Ep: 104/200, it: 51/468, err: 0.0002\n",
      "Ep: 104/200, it: 101/468, err: 0.0011\n",
      "Ep: 104/200, it: 151/468, err: 0.0145\n",
      "Ep: 104/200, it: 201/468, err: 0.0048\n",
      "Ep: 104/200, it: 251/468, err: 0.0030\n",
      "Ep: 104/200, it: 301/468, err: 0.0065\n",
      "Ep: 104/200, it: 351/468, err: 0.0004\n",
      "Ep: 104/200, it: 401/468, err: 0.0068\n",
      "Ep: 104/200, it: 451/468, err: 0.0016\n",
      "Ep: 104/200, it: 468/468, err: 0.0038\n",
      "Test acc: 99.33\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   1    1 1026    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1008    0    2    0    0    0    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    6    0  884    1    0    0    0]\n",
      " [   4    4    0    0    0    2  945    0    3    0]\n",
      " [   0    2    2    1    0    0    0 1022    0    1]\n",
      " [   0    0    1    1    0    1    1    1  968    1]\n",
      " [   2    0    0    2    8    1    0    0    2  994]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3430e-04.\n",
      "Ep: 105/200, it: 1/468, err: 0.0072\n",
      "Ep: 105/200, it: 51/468, err: 0.0251\n",
      "Ep: 105/200, it: 101/468, err: 0.0033\n",
      "Ep: 105/200, it: 151/468, err: 0.0018\n",
      "Ep: 105/200, it: 201/468, err: 0.0008\n",
      "Ep: 105/200, it: 251/468, err: 0.0036\n",
      "Ep: 105/200, it: 301/468, err: 0.0151\n",
      "Ep: 105/200, it: 351/468, err: 0.0060\n",
      "Ep: 105/200, it: 401/468, err: 0.0041\n",
      "Ep: 105/200, it: 451/468, err: 0.0100\n",
      "Ep: 105/200, it: 468/468, err: 0.0145\n",
      "Test acc: 99.29\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    2    0    0    0    2    0    0]\n",
      " [   1    1 1024    0    1    0    0    4    1    0]\n",
      " [   0    0    1 1006    0    3    0    0    0    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    4    0  885    1    1    0    0]\n",
      " [   2    6    0    0    2    1  945    0    2    0]\n",
      " [   0    3    0    0    1    0    0 1024    0    0]\n",
      " [   0    0    1    2    0    1    0    2  967    1]\n",
      " [   0    0    0    0   10    1    0    2    0  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3039e-04.\n",
      "Ep: 106/200, it: 1/468, err: 0.0062\n",
      "Ep: 106/200, it: 51/468, err: 0.0001\n",
      "Ep: 106/200, it: 101/468, err: 0.0007\n",
      "Ep: 106/200, it: 151/468, err: 0.0002\n",
      "Ep: 106/200, it: 201/468, err: 0.0095\n",
      "Ep: 106/200, it: 251/468, err: 0.0042\n",
      "Ep: 106/200, it: 301/468, err: 0.0020\n",
      "Ep: 106/200, it: 351/468, err: 0.0037\n",
      "Ep: 106/200, it: 401/468, err: 0.0005\n",
      "Ep: 106/200, it: 451/468, err: 0.0010\n",
      "Ep: 106/200, it: 468/468, err: 0.0053\n",
      "Test acc: 99.37\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1131    0    1    0    0    0    3    0    0]\n",
      " [   0    0 1030    0    0    0    0    2    0    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  978    0    0    0    0    4]\n",
      " [   1    0    1    3    0  884    1    0    0    2]\n",
      " [   1    3    0    0    2    1  950    0    1    0]\n",
      " [   0    2    2    3    1    0    0 1020    0    0]\n",
      " [   1    0    2    1    0    1    0    1  967    1]\n",
      " [   0    0    0    4   10    1    0    0    1  993]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2647e-04.\n",
      "Ep: 107/200, it: 1/468, err: 0.0152\n",
      "Ep: 107/200, it: 51/468, err: 0.0025\n",
      "Ep: 107/200, it: 101/468, err: 0.0101\n",
      "Ep: 107/200, it: 151/468, err: 0.0030\n",
      "Ep: 107/200, it: 201/468, err: 0.0115\n",
      "Ep: 107/200, it: 251/468, err: 0.0273\n",
      "Ep: 107/200, it: 301/468, err: 0.0067\n",
      "Ep: 107/200, it: 351/468, err: 0.0165\n",
      "Ep: 107/200, it: 401/468, err: 0.0272\n",
      "Ep: 107/200, it: 451/468, err: 0.0010\n",
      "Ep: 107/200, it: 468/468, err: 0.0008\n",
      "Test acc: 99.37\n",
      "[[ 977    0    0    0    0    0    0    3    0    0]\n",
      " [   0 1132    0    0    1    0    0    2    0    0]\n",
      " [   1    0 1026    0    0    0    0    4    1    0]\n",
      " [   0    0    1 1007    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    1    0    0    7]\n",
      " [   2    0    0    3    0  885    0    1    0    1]\n",
      " [   1    4    0    0    2    1  949    0    1    0]\n",
      " [   0    2    2    2    1    0    0 1020    0    1]\n",
      " [   0    0    2    1    0    1    0    0  968    2]\n",
      " [   0    0    0    0    7    1    0    2    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2257e-04.\n",
      "Ep: 108/200, it: 1/468, err: 0.0030\n",
      "Ep: 108/200, it: 51/468, err: 0.0060\n",
      "Ep: 108/200, it: 101/468, err: 0.0018\n",
      "Ep: 108/200, it: 151/468, err: 0.0012\n",
      "Ep: 108/200, it: 201/468, err: 0.0340\n",
      "Ep: 108/200, it: 251/468, err: 0.0207\n",
      "Ep: 108/200, it: 301/468, err: 0.0030\n",
      "Ep: 108/200, it: 351/468, err: 0.0027\n",
      "Ep: 108/200, it: 401/468, err: 0.0298\n",
      "Ep: 108/200, it: 451/468, err: 0.0132\n",
      "Ep: 108/200, it: 468/468, err: 0.0022\n",
      "Test acc: 99.31\n",
      "[[ 975    0    1    0    0    0    0    1    3    0]\n",
      " [   0 1126    0    3    1    0    0    5    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    0 1005    0    4    0    0    1    0]\n",
      " [   0    0    0    0  975    0    2    0    0    5]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    5    0    0    4    1  942    0    5    0]\n",
      " [   0    2    3    0    1    0    0 1022    0    0]\n",
      " [   0    0    0    2    0    1    0    0  968    3]\n",
      " [   0    0    0    0    4    1    0    3    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1867e-04.\n",
      "Ep: 109/200, it: 1/468, err: 0.0355\n",
      "Ep: 109/200, it: 51/468, err: 0.0093\n",
      "Ep: 109/200, it: 101/468, err: 0.0012\n",
      "Ep: 109/200, it: 151/468, err: 0.0007\n",
      "Ep: 109/200, it: 201/468, err: 0.0013\n",
      "Ep: 109/200, it: 251/468, err: 0.0010\n",
      "Ep: 109/200, it: 301/468, err: 0.0003\n",
      "Ep: 109/200, it: 351/468, err: 0.0030\n",
      "Ep: 109/200, it: 401/468, err: 0.0222\n",
      "Ep: 109/200, it: 451/468, err: 0.0015\n",
      "Ep: 109/200, it: 468/468, err: 0.0034\n",
      "Test acc: 99.30\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1131    0    1    0    0    0    3    0    0]\n",
      " [   0    0 1026    0    0    0    0    3    3    0]\n",
      " [   0    1    0 1006    0    1    0    1    1    0]\n",
      " [   0    0    0    0  972    0    4    0    0    6]\n",
      " [   0    0    0    5    0  885    0    2    0    0]\n",
      " [   1    3    0    0    1    1  950    0    2    0]\n",
      " [   0    4    3    1    1    0    0 1019    0    0]\n",
      " [   0    0    2    4    0    1    0    1  965    1]\n",
      " [   0    2    0    0    4    1    0    1    1 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1477e-04.\n",
      "Ep: 110/200, it: 1/468, err: 0.0030\n",
      "Ep: 110/200, it: 51/468, err: 0.0013\n",
      "Ep: 110/200, it: 101/468, err: 0.0027\n",
      "Ep: 110/200, it: 151/468, err: 0.0134\n",
      "Ep: 110/200, it: 201/468, err: 0.0069\n",
      "Ep: 110/200, it: 251/468, err: 0.0019\n",
      "Ep: 110/200, it: 301/468, err: 0.0011\n",
      "Ep: 110/200, it: 351/468, err: 0.0067\n",
      "Ep: 110/200, it: 401/468, err: 0.0384\n",
      "Ep: 110/200, it: 451/468, err: 0.0002\n",
      "Ep: 110/200, it: 468/468, err: 0.0085\n",
      "Test acc: 99.36\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1131    1    2    0    0    0    1    0    0]\n",
      " [   1    0 1025    0    0    0    0    3    3    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  973    0    3    0    0    6]\n",
      " [   1    0    0    4    0  884    0    3    0    0]\n",
      " [   2    4    0    0    0    2  947    0    3    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    3    0    0    0    1  966    3]\n",
      " [   0    0    0    0    4    1    0    2    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1089e-04.\n",
      "Ep: 111/200, it: 1/468, err: 0.0007\n",
      "Ep: 111/200, it: 51/468, err: 0.0002\n",
      "Ep: 111/200, it: 101/468, err: 0.0379\n",
      "Ep: 111/200, it: 151/468, err: 0.0116\n",
      "Ep: 111/200, it: 201/468, err: 0.0007\n",
      "Ep: 111/200, it: 251/468, err: 0.0003\n",
      "Ep: 111/200, it: 301/468, err: 0.0074\n",
      "Ep: 111/200, it: 351/468, err: 0.0361\n",
      "Ep: 111/200, it: 401/468, err: 0.0008\n",
      "Ep: 111/200, it: 451/468, err: 0.0002\n",
      "Ep: 111/200, it: 468/468, err: 0.0020\n",
      "Test acc: 99.37\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1130    0    2    0    0    0    3    0    0]\n",
      " [   1    0 1025    0    0    0    0    3    3    0]\n",
      " [   0    0    0 1005    0    3    0    0    1    1]\n",
      " [   0    0    0    0  969    0    4    0    1    8]\n",
      " [   2    0    0    4    0  884    0    1    0    1]\n",
      " [   2    3    0    0    0    1  950    0    2    0]\n",
      " [   0    2    3    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  969    2]\n",
      " [   0    0    0    0    3    1    0    2    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0702e-04.\n",
      "Ep: 112/200, it: 1/468, err: 0.0004\n",
      "Ep: 112/200, it: 51/468, err: 0.0025\n",
      "Ep: 112/200, it: 101/468, err: 0.0003\n",
      "Ep: 112/200, it: 151/468, err: 0.0130\n",
      "Ep: 112/200, it: 201/468, err: 0.0010\n",
      "Ep: 112/200, it: 251/468, err: 0.0189\n",
      "Ep: 112/200, it: 301/468, err: 0.0003\n",
      "Ep: 112/200, it: 351/468, err: 0.0068\n",
      "Ep: 112/200, it: 401/468, err: 0.0318\n",
      "Ep: 112/200, it: 451/468, err: 0.0072\n",
      "Ep: 112/200, it: 468/468, err: 0.0144\n",
      "Test acc: 99.44\n",
      "[[ 976    0    1    0    0    0    1    1    1    0]\n",
      " [   0 1132    0    2    0    0    1    0    0    0]\n",
      " [   0    0 1027    1    0    0    0    2    2    0]\n",
      " [   0    0    0 1005    0    3    0    0    2    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  888    0    0    0    1]\n",
      " [   1    4    0    0    0    2  949    0    2    0]\n",
      " [   0    3    1    1    0    0    0 1022    0    1]\n",
      " [   0    0    1    2    0    1    0    0  969    1]\n",
      " [   0    0    0    2    4    0    0    0    1 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0315e-04.\n",
      "Ep: 113/200, it: 1/468, err: 0.0007\n",
      "Ep: 113/200, it: 51/468, err: 0.0004\n",
      "Ep: 113/200, it: 101/468, err: 0.0008\n",
      "Ep: 113/200, it: 151/468, err: 0.0078\n",
      "Ep: 113/200, it: 201/468, err: 0.0153\n",
      "Ep: 113/200, it: 251/468, err: 0.0015\n",
      "Ep: 113/200, it: 301/468, err: 0.0004\n",
      "Ep: 113/200, it: 351/468, err: 0.0095\n",
      "Ep: 113/200, it: 401/468, err: 0.0016\n",
      "Ep: 113/200, it: 451/468, err: 0.0001\n",
      "Ep: 113/200, it: 468/468, err: 0.0018\n",
      "Test acc: 99.43\n",
      "[[ 976    0    1    0    0    0    1    1    1    0]\n",
      " [   0 1130    3    0    1    0    0    1    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    1 1005    0    3    0    0    1    0]\n",
      " [   0    0    0    0  978    0    2    0    0    2]\n",
      " [   2    0    0    1    0  887    1    0    0    1]\n",
      " [   2    2    0    0    0    1  952    0    1    0]\n",
      " [   0    2    4    0    0    0    0 1022    0    0]\n",
      " [   0    0    4    1    0    0    0    0  968    1]\n",
      " [   0    0    0    2    7    1    0    1    1  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9930e-04.\n",
      "Ep: 114/200, it: 1/468, err: 0.0121\n",
      "Ep: 114/200, it: 51/468, err: 0.0219\n",
      "Ep: 114/200, it: 101/468, err: 0.0010\n",
      "Ep: 114/200, it: 151/468, err: 0.0016\n",
      "Ep: 114/200, it: 201/468, err: 0.0216\n",
      "Ep: 114/200, it: 251/468, err: 0.0014\n",
      "Ep: 114/200, it: 301/468, err: 0.0272\n",
      "Ep: 114/200, it: 351/468, err: 0.0050\n",
      "Ep: 114/200, it: 401/468, err: 0.0017\n",
      "Ep: 114/200, it: 451/468, err: 0.0002\n",
      "Ep: 114/200, it: 468/468, err: 0.0052\n",
      "Test acc: 99.32\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1132    0    1    0    0    2    0    0    0]\n",
      " [   1    1 1027    0    0    0    0    0    3    0]\n",
      " [   0    0    0 1003    0    5    0    0    2    0]\n",
      " [   0    0    0    0  970    0    4    0    1    7]\n",
      " [   1    0    0    1    0  888    1    0    0    1]\n",
      " [   2    3    0    0    0    1  950    0    2    0]\n",
      " [   0    5    5    2    0    0    0 1016    0    0]\n",
      " [   0    0    2    1    0    0    0    0  969    2]\n",
      " [   0    0    0    3    6    1    0    1    0  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9546e-04.\n",
      "Ep: 115/200, it: 1/468, err: 0.0002\n",
      "Ep: 115/200, it: 51/468, err: 0.0021\n",
      "Ep: 115/200, it: 101/468, err: 0.0022\n",
      "Ep: 115/200, it: 151/468, err: 0.0007\n",
      "Ep: 115/200, it: 201/468, err: 0.0024\n",
      "Ep: 115/200, it: 251/468, err: 0.0010\n",
      "Ep: 115/200, it: 301/468, err: 0.0164\n",
      "Ep: 115/200, it: 351/468, err: 0.0001\n",
      "Ep: 115/200, it: 401/468, err: 0.0006\n",
      "Ep: 115/200, it: 451/468, err: 0.0007\n",
      "Ep: 115/200, it: 468/468, err: 0.0011\n",
      "Test acc: 99.45\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1134    0    0    0    0    1    0    0    0]\n",
      " [   1    0 1027    0    0    0    0    2    2    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  972    0    4    0    0    6]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   2    4    0    0    0    1  949    0    2    0]\n",
      " [   0    4    2    1    0    0    0 1020    0    1]\n",
      " [   0    0    2    1    0    0    0    1  969    1]\n",
      " [   0    0    0    1    5    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9164e-04.\n",
      "Ep: 116/200, it: 1/468, err: 0.0012\n",
      "Ep: 116/200, it: 51/468, err: 0.0009\n",
      "Ep: 116/200, it: 101/468, err: 0.0001\n",
      "Ep: 116/200, it: 151/468, err: 0.0004\n",
      "Ep: 116/200, it: 201/468, err: 0.0001\n",
      "Ep: 116/200, it: 251/468, err: 0.0023\n",
      "Ep: 116/200, it: 301/468, err: 0.0007\n",
      "Ep: 116/200, it: 351/468, err: 0.0006\n",
      "Ep: 116/200, it: 401/468, err: 0.0080\n",
      "Ep: 116/200, it: 451/468, err: 0.0003\n",
      "Ep: 116/200, it: 468/468, err: 0.0008\n",
      "Test acc: 99.35\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1129    1    0    0    0    2    3    0    0]\n",
      " [   1    1 1023    1    0    0    0    3    3    0]\n",
      " [   0    0    2 1004    0    4    0    0    0    0]\n",
      " [   0    0    0    0  976    0    4    0    0    2]\n",
      " [   1    0    0    2    0  888    1    0    0    0]\n",
      " [   1    2    0    0    0    1  952    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1022    0    1]\n",
      " [   0    0    2    2    0    1    0    1  966    2]\n",
      " [   0    0    1    1    8    1    0    0    0  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8783e-04.\n",
      "Ep: 117/200, it: 1/468, err: 0.0287\n",
      "Ep: 117/200, it: 51/468, err: 0.0002\n",
      "Ep: 117/200, it: 101/468, err: 0.0004\n",
      "Ep: 117/200, it: 151/468, err: 0.0003\n",
      "Ep: 117/200, it: 201/468, err: 0.0639\n",
      "Ep: 117/200, it: 251/468, err: 0.0010\n",
      "Ep: 117/200, it: 301/468, err: 0.0015\n",
      "Ep: 117/200, it: 351/468, err: 0.0013\n",
      "Ep: 117/200, it: 401/468, err: 0.0062\n",
      "Ep: 117/200, it: 451/468, err: 0.0031\n",
      "Ep: 117/200, it: 468/468, err: 0.0016\n",
      "Test acc: 99.41\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1132    1    0    0    0    1    1    0    0]\n",
      " [   1    1 1027    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    1    0    0  972    0    5    0    0    4]\n",
      " [   1    0    0    5    0  885    0    1    0    0]\n",
      " [   1    3    0    0    0    1  951    0    2    0]\n",
      " [   0    2    2    0    0    0    0 1022    0    2]\n",
      " [   0    1    3    2    0    0    0    1  965    2]\n",
      " [   0    0    1    2    3    1    0    0    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8403e-04.\n",
      "Ep: 118/200, it: 1/468, err: 0.0004\n",
      "Ep: 118/200, it: 51/468, err: 0.0014\n",
      "Ep: 118/200, it: 101/468, err: 0.0003\n",
      "Ep: 118/200, it: 151/468, err: 0.0013\n",
      "Ep: 118/200, it: 201/468, err: 0.0023\n",
      "Ep: 118/200, it: 251/468, err: 0.0010\n",
      "Ep: 118/200, it: 301/468, err: 0.0004\n",
      "Ep: 118/200, it: 351/468, err: 0.0260\n",
      "Ep: 118/200, it: 401/468, err: 0.0002\n",
      "Ep: 118/200, it: 451/468, err: 0.0049\n",
      "Ep: 118/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.34\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1130    1    3    0    0    0    1    0    0]\n",
      " [   1    1 1024    1    0    0    0    1    4    0]\n",
      " [   0    0    0 1005    0    3    0    0    2    0]\n",
      " [   0    0    0    0  972    0    3    0    0    7]\n",
      " [   1    0    0    3    0  887    0    0    0    1]\n",
      " [   2    4    0    0    1    1  949    0    1    0]\n",
      " [   0    1    5    1    0    0    0 1019    0    2]\n",
      " [   0    0    0    3    0    1    0    1  968    1]\n",
      " [   0    1    0    0    3    1    0    0    3 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8025e-04.\n",
      "Ep: 119/200, it: 1/468, err: 0.0021\n",
      "Ep: 119/200, it: 51/468, err: 0.0007\n",
      "Ep: 119/200, it: 101/468, err: 0.0218\n",
      "Ep: 119/200, it: 151/468, err: 0.0007\n",
      "Ep: 119/200, it: 201/468, err: 0.0006\n",
      "Ep: 119/200, it: 251/468, err: 0.0026\n",
      "Ep: 119/200, it: 301/468, err: 0.0009\n",
      "Ep: 119/200, it: 351/468, err: 0.0002\n",
      "Ep: 119/200, it: 401/468, err: 0.0036\n",
      "Ep: 119/200, it: 451/468, err: 0.0026\n",
      "Ep: 119/200, it: 468/468, err: 0.0020\n",
      "Test acc: 99.40\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1133    0    1    0    1    0    0    0    0]\n",
      " [   1    0 1024    0    0    0    0    4    3    0]\n",
      " [   0    0    1 1003    0    4    0    0    2    0]\n",
      " [   0    0    0    0  972    0    4    0    0    6]\n",
      " [   0    0    0    1    0  889    0    2    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    3    2    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    1    1    0  968    1]\n",
      " [   0    1    0    1    3    1    0    1    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7649e-04.\n",
      "Ep: 120/200, it: 1/468, err: 0.0004\n",
      "Ep: 120/200, it: 51/468, err: 0.0008\n",
      "Ep: 120/200, it: 101/468, err: 0.0099\n",
      "Ep: 120/200, it: 151/468, err: 0.0010\n",
      "Ep: 120/200, it: 201/468, err: 0.0040\n",
      "Ep: 120/200, it: 251/468, err: 0.0002\n",
      "Ep: 120/200, it: 301/468, err: 0.0001\n",
      "Ep: 120/200, it: 351/468, err: 0.0003\n",
      "Ep: 120/200, it: 401/468, err: 0.0007\n",
      "Ep: 120/200, it: 451/468, err: 0.0002\n",
      "Ep: 120/200, it: 468/468, err: 0.0635\n",
      "Test acc: 99.49\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1132    1    1    0    1    0    0    0    0]\n",
      " [   0    0 1030    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1004    0    5    0    0    1    0]\n",
      " [   0    0    0    0  974    0    2    0    0    6]\n",
      " [   0    0    0    4    0  887    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    3    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    1    1    0  967    2]\n",
      " [   0    0    0    1    4    1    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7275e-04.\n",
      "Ep: 121/200, it: 1/468, err: 0.0047\n",
      "Ep: 121/200, it: 51/468, err: 0.0009\n",
      "Ep: 121/200, it: 101/468, err: 0.0002\n",
      "Ep: 121/200, it: 151/468, err: 0.0016\n",
      "Ep: 121/200, it: 201/468, err: 0.0022\n",
      "Ep: 121/200, it: 251/468, err: 0.0007\n",
      "Ep: 121/200, it: 301/468, err: 0.0032\n",
      "Ep: 121/200, it: 351/468, err: 0.0002\n",
      "Ep: 121/200, it: 401/468, err: 0.0590\n",
      "Ep: 121/200, it: 451/468, err: 0.0009\n",
      "Ep: 121/200, it: 468/468, err: 0.0015\n",
      "Test acc: 99.36\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1130    0    1    0    1    0    3    0    0]\n",
      " [   0    0 1027    0    0    0    0    4    1    0]\n",
      " [   0    0    0 1005    0    3    0    1    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  886    1    2    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    3    3    0    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    1    1    0  968    1]\n",
      " [   0    0    0    1    8    2    0    2    0  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6902e-04.\n",
      "Ep: 122/200, it: 1/468, err: 0.0001\n",
      "Ep: 122/200, it: 51/468, err: 0.0130\n",
      "Ep: 122/200, it: 101/468, err: 0.0001\n",
      "Ep: 122/200, it: 151/468, err: 0.0007\n",
      "Ep: 122/200, it: 201/468, err: 0.0012\n",
      "Ep: 122/200, it: 251/468, err: 0.0043\n",
      "Ep: 122/200, it: 301/468, err: 0.0010\n",
      "Ep: 122/200, it: 351/468, err: 0.0099\n",
      "Ep: 122/200, it: 401/468, err: 0.0066\n",
      "Ep: 122/200, it: 451/468, err: 0.0027\n",
      "Ep: 122/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.41\n",
      "[[ 975    0    0    0    0    1    2    1    1    0]\n",
      " [   0 1129    0    2    0    0    0    4    0    0]\n",
      " [   1    0 1024    0    0    0    0    4    3    0]\n",
      " [   0    0    0 1005    0    3    0    0    2    0]\n",
      " [   0    0    0    0  978    0    0    0    0    4]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   2    3    0    0    0    2  950    0    1    0]\n",
      " [   0    0    2    0    0    0    0 1025    0    1]\n",
      " [   0    0    0    3    0    0    0    0  970    1]\n",
      " [   0    0    0    2    4    2    0    1    2  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6532e-04.\n",
      "Ep: 123/200, it: 1/468, err: 0.0008\n",
      "Ep: 123/200, it: 51/468, err: 0.0009\n",
      "Ep: 123/200, it: 101/468, err: 0.0003\n",
      "Ep: 123/200, it: 151/468, err: 0.0369\n",
      "Ep: 123/200, it: 201/468, err: 0.0007\n",
      "Ep: 123/200, it: 251/468, err: 0.0003\n",
      "Ep: 123/200, it: 301/468, err: 0.0040\n",
      "Ep: 123/200, it: 351/468, err: 0.0129\n",
      "Ep: 123/200, it: 401/468, err: 0.0003\n",
      "Ep: 123/200, it: 451/468, err: 0.0080\n",
      "Ep: 123/200, it: 468/468, err: 0.0031\n",
      "Test acc: 99.34\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1128    1    2    0    1    1    2    0    0]\n",
      " [   1    0 1026    0    0    0    0    3    2    0]\n",
      " [   0    0    0 1004    0    4    0    0    2    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    3    0  886    1    1    0    0]\n",
      " [   1    2    0    0    0    1  953    0    1    0]\n",
      " [   0    3    3    0    0    0    0 1022    0    0]\n",
      " [   0    1    0    3    0    0    0    0  969    1]\n",
      " [   0    0    0    1   11    1    0    1    0  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6163e-04.\n",
      "Ep: 124/200, it: 1/468, err: 0.0001\n",
      "Ep: 124/200, it: 51/468, err: 0.0012\n",
      "Ep: 124/200, it: 101/468, err: 0.0001\n",
      "Ep: 124/200, it: 151/468, err: 0.0018\n",
      "Ep: 124/200, it: 201/468, err: 0.0060\n",
      "Ep: 124/200, it: 251/468, err: 0.0199\n",
      "Ep: 124/200, it: 301/468, err: 0.0134\n",
      "Ep: 124/200, it: 351/468, err: 0.0001\n",
      "Ep: 124/200, it: 401/468, err: 0.0513\n",
      "Ep: 124/200, it: 451/468, err: 0.0005\n",
      "Ep: 124/200, it: 468/468, err: 0.0030\n",
      "Test acc: 99.39\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1132    1    0    0    1    0    1    0    0]\n",
      " [   1    0 1027    0    0    0    0    3    1    0]\n",
      " [   0    1    0 1004    0    3    0    0    2    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    4    0  885    1    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    2    1    1    0    0    1  967    2]\n",
      " [   0    0    0    1    7    1    0    2    0  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5797e-04.\n",
      "Ep: 125/200, it: 1/468, err: 0.0002\n",
      "Ep: 125/200, it: 51/468, err: 0.0006\n",
      "Ep: 125/200, it: 101/468, err: 0.0118\n",
      "Ep: 125/200, it: 151/468, err: 0.0016\n",
      "Ep: 125/200, it: 201/468, err: 0.0009\n",
      "Ep: 125/200, it: 251/468, err: 0.0049\n",
      "Ep: 125/200, it: 301/468, err: 0.0005\n",
      "Ep: 125/200, it: 351/468, err: 0.0503\n",
      "Ep: 125/200, it: 401/468, err: 0.0002\n",
      "Ep: 125/200, it: 451/468, err: 0.0022\n",
      "Ep: 125/200, it: 468/468, err: 0.0219\n",
      "Test acc: 99.39\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   1    0 1025    0    0    0    0    4    2    0]\n",
      " [   0    0    0 1004    0    4    0    0    2    0]\n",
      " [   0    0    0    0  976    0    3    0    0    3]\n",
      " [   1    0    0    1    0  887    1    2    0    0]\n",
      " [   1    3    0    0    1    1  951    0    1    0]\n",
      " [   0    1    0    0    0    0    0 1027    0    0]\n",
      " [   0    0    2    4    0    1    0    0  965    2]\n",
      " [   0    0    2    0    6    0    0    3    2  996]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5433e-04.\n",
      "Ep: 126/200, it: 1/468, err: 0.0002\n",
      "Ep: 126/200, it: 51/468, err: 0.0002\n",
      "Ep: 126/200, it: 101/468, err: 0.0002\n",
      "Ep: 126/200, it: 151/468, err: 0.0014\n",
      "Ep: 126/200, it: 201/468, err: 0.0015\n",
      "Ep: 126/200, it: 251/468, err: 0.0195\n",
      "Ep: 126/200, it: 301/468, err: 0.0002\n",
      "Ep: 126/200, it: 351/468, err: 0.0042\n",
      "Ep: 126/200, it: 401/468, err: 0.0008\n",
      "Ep: 126/200, it: 451/468, err: 0.0088\n",
      "Ep: 126/200, it: 468/468, err: 0.0011\n",
      "Test acc: 99.38\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   0    0 1028    0    1    0    0    1    2    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  973    0    3    1    0    5]\n",
      " [   1    0    0    2    0  886    1    1    0    1]\n",
      " [   2    4    0    0    0    1  949    0    2    0]\n",
      " [   0    2    4    0    0    0    0 1022    0    0]\n",
      " [   0    0    0    4    0    1    0    1  967    1]\n",
      " [   0    0    0    1    6    0    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5071e-04.\n",
      "Ep: 127/200, it: 1/468, err: 0.0014\n",
      "Ep: 127/200, it: 51/468, err: 0.0016\n",
      "Ep: 127/200, it: 101/468, err: 0.0013\n",
      "Ep: 127/200, it: 151/468, err: 0.0270\n",
      "Ep: 127/200, it: 201/468, err: 0.0019\n",
      "Ep: 127/200, it: 251/468, err: 0.0080\n",
      "Ep: 127/200, it: 301/468, err: 0.0036\n",
      "Ep: 127/200, it: 351/468, err: 0.0005\n",
      "Ep: 127/200, it: 401/468, err: 0.0005\n",
      "Ep: 127/200, it: 451/468, err: 0.0046\n",
      "Ep: 127/200, it: 468/468, err: 0.0005\n",
      "Test acc: 99.43\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1131    0    1    0    0    1    2    0    0]\n",
      " [   0    0 1031    0    0    0    0    1    0    0]\n",
      " [   0    0    0 1005    0    4    0    0    1    0]\n",
      " [   0    0    0    0  969    0    3    0    0   10]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    3    0    0    0    2  951    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1021    0    1]\n",
      " [   0    1    0    5    0    1    0    0  966    1]\n",
      " [   0    0    0    1    4    2    0    0    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4712e-04.\n",
      "Ep: 128/200, it: 1/468, err: 0.0002\n",
      "Ep: 128/200, it: 51/468, err: 0.0002\n",
      "Ep: 128/200, it: 101/468, err: 0.0014\n",
      "Ep: 128/200, it: 151/468, err: 0.0183\n",
      "Ep: 128/200, it: 201/468, err: 0.0003\n",
      "Ep: 128/200, it: 251/468, err: 0.0020\n",
      "Ep: 128/200, it: 301/468, err: 0.0022\n",
      "Ep: 128/200, it: 351/468, err: 0.0160\n",
      "Ep: 128/200, it: 401/468, err: 0.0009\n",
      "Ep: 128/200, it: 451/468, err: 0.0246\n",
      "Ep: 128/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.45\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    0    0    0    0    3    0    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    3    0    0    4]\n",
      " [   1    0    0    3    0  886    1    0    1    0]\n",
      " [   2    4    0    0    0    1  950    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    0    2    0    1    0    1  969    1]\n",
      " [   0    0    0    4    4    1    0    2    1  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4356e-04.\n",
      "Ep: 129/200, it: 1/468, err: 0.0046\n",
      "Ep: 129/200, it: 51/468, err: 0.0018\n",
      "Ep: 129/200, it: 101/468, err: 0.0009\n",
      "Ep: 129/200, it: 151/468, err: 0.0003\n",
      "Ep: 129/200, it: 201/468, err: 0.0002\n",
      "Ep: 129/200, it: 251/468, err: 0.0001\n",
      "Ep: 129/200, it: 301/468, err: 0.0077\n",
      "Ep: 129/200, it: 351/468, err: 0.0009\n",
      "Ep: 129/200, it: 401/468, err: 0.0036\n",
      "Ep: 129/200, it: 451/468, err: 0.0005\n",
      "Ep: 129/200, it: 468/468, err: 0.0010\n",
      "Test acc: 99.48\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1131    1    0    1    0    1    1    0    0]\n",
      " [   0    0 1030    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1001    0    7    0    0    2    0]\n",
      " [   0    1    0    0  976    0    2    0    0    3]\n",
      " [   1    0    0    1    0  888    1    0    1    0]\n",
      " [   1    2    0    0    0    1  951    0    3    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    3    0    0    0    0  969    1]\n",
      " [   0    0    0    0    6    0    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4002e-04.\n",
      "Ep: 130/200, it: 1/468, err: 0.0003\n",
      "Ep: 130/200, it: 51/468, err: 0.0076\n",
      "Ep: 130/200, it: 101/468, err: 0.0061\n",
      "Ep: 130/200, it: 151/468, err: 0.0024\n",
      "Ep: 130/200, it: 201/468, err: 0.0447\n",
      "Ep: 130/200, it: 251/468, err: 0.0001\n",
      "Ep: 130/200, it: 301/468, err: 0.0003\n",
      "Ep: 130/200, it: 351/468, err: 0.0095\n",
      "Ep: 130/200, it: 401/468, err: 0.0001\n",
      "Ep: 130/200, it: 451/468, err: 0.0006\n",
      "Ep: 130/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.49\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1029    0    0    0    0    2    1    0]\n",
      " [   0    0    0 1002    0    6    0    0    2    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    3    0    0    0    1  952    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1022    0    1]\n",
      " [   0    0    0    3    0    0    0    0  970    1]\n",
      " [   0    0    0    1    1    1    0    1    1 1004]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3650e-04.\n",
      "Ep: 131/200, it: 1/468, err: 0.0014\n",
      "Ep: 131/200, it: 51/468, err: 0.0002\n",
      "Ep: 131/200, it: 101/468, err: 0.0001\n",
      "Ep: 131/200, it: 151/468, err: 0.0004\n",
      "Ep: 131/200, it: 201/468, err: 0.0001\n",
      "Ep: 131/200, it: 251/468, err: 0.0004\n",
      "Ep: 131/200, it: 301/468, err: 0.0012\n",
      "Ep: 131/200, it: 351/468, err: 0.0013\n",
      "Ep: 131/200, it: 401/468, err: 0.0001\n",
      "Ep: 131/200, it: 451/468, err: 0.0040\n",
      "Ep: 131/200, it: 468/468, err: 0.0035\n",
      "Test acc: 99.47\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1027    0    0    0    0    2    3    0]\n",
      " [   0    0    0 1006    0    1    0    0    3    0]\n",
      " [   0    0    0    0  976    0    3    0    0    3]\n",
      " [   1    0    0    3    0  887    1    0    0    0]\n",
      " [   1    4    0    0    1    1  949    0    2    0]\n",
      " [   0    2    3    1    2    0    0 1018    0    2]\n",
      " [   0    0    0    2    0    0    0    0  971    1]\n",
      " [   0    0    0    1    5    0    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3302e-04.\n",
      "Ep: 132/200, it: 1/468, err: 0.0006\n",
      "Ep: 132/200, it: 51/468, err: 0.0058\n",
      "Ep: 132/200, it: 101/468, err: 0.0008\n",
      "Ep: 132/200, it: 151/468, err: 0.0013\n",
      "Ep: 132/200, it: 201/468, err: 0.0037\n",
      "Ep: 132/200, it: 251/468, err: 0.0003\n",
      "Ep: 132/200, it: 301/468, err: 0.0002\n",
      "Ep: 132/200, it: 351/468, err: 0.0003\n",
      "Ep: 132/200, it: 401/468, err: 0.0009\n",
      "Ep: 132/200, it: 451/468, err: 0.0447\n",
      "Ep: 132/200, it: 468/468, err: 0.0073\n",
      "Test acc: 99.45\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1029    0    0    0    0    1    2    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  971    0    5    0    0    6]\n",
      " [   1    0    0    4    0  887    0    0    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    3    3    2    0    0    0 1018    0    2]\n",
      " [   0    0    0    3    0    0    0    0  970    1]\n",
      " [   0    0    0    2    3    0    0    0    0 1004]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2956e-04.\n",
      "Ep: 133/200, it: 1/468, err: 0.0073\n",
      "Ep: 133/200, it: 51/468, err: 0.0010\n",
      "Ep: 133/200, it: 101/468, err: 0.0010\n",
      "Ep: 133/200, it: 151/468, err: 0.0004\n",
      "Ep: 133/200, it: 201/468, err: 0.0015\n",
      "Ep: 133/200, it: 251/468, err: 0.0084\n",
      "Ep: 133/200, it: 301/468, err: 0.0035\n",
      "Ep: 133/200, it: 351/468, err: 0.0013\n",
      "Ep: 133/200, it: 401/468, err: 0.0029\n",
      "Ep: 133/200, it: 451/468, err: 0.0007\n",
      "Ep: 133/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.45\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1131    0    0    1    0    1    2    0    0]\n",
      " [   0    1 1029    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  973    0    5    0    0    4]\n",
      " [   1    0    0    6    0  885    0    0    0    0]\n",
      " [   1    3    1    0    0    1  951    0    1    0]\n",
      " [   0    3    3    1    0    0    0 1018    0    3]\n",
      " [   0    0    0    3    0    0    0    0  970    1]\n",
      " [   0    0    0    1    4    0    0    0    1 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2614e-04.\n",
      "Ep: 134/200, it: 1/468, err: 0.0024\n",
      "Ep: 134/200, it: 51/468, err: 0.0011\n",
      "Ep: 134/200, it: 101/468, err: 0.0003\n",
      "Ep: 134/200, it: 151/468, err: 0.0013\n",
      "Ep: 134/200, it: 201/468, err: 0.0018\n",
      "Ep: 134/200, it: 251/468, err: 0.0005\n",
      "Ep: 134/200, it: 301/468, err: 0.0005\n",
      "Ep: 134/200, it: 351/468, err: 0.0096\n",
      "Ep: 134/200, it: 401/468, err: 0.0002\n",
      "Ep: 134/200, it: 451/468, err: 0.0001\n",
      "Ep: 134/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.45\n",
      "[[ 977    0    0    0    0    0    1    2    0    0]\n",
      " [   0 1130    1    0    0    0    0    4    0    0]\n",
      " [   0    0 1026    0    0    0    0    5    1    0]\n",
      " [   0    0    0 1001    0    6    0    0    3    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  952    0    0    0]\n",
      " [   0    1    1    0    0    0    0 1026    0    0]\n",
      " [   0    0    0    3    0    0    0    1  969    1]\n",
      " [   0    0    0    0    3    0    0    3    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2274e-04.\n",
      "Ep: 135/200, it: 1/468, err: 0.0001\n",
      "Ep: 135/200, it: 51/468, err: 0.0022\n",
      "Ep: 135/200, it: 101/468, err: 0.0001\n",
      "Ep: 135/200, it: 151/468, err: 0.0003\n",
      "Ep: 135/200, it: 201/468, err: 0.0004\n",
      "Ep: 135/200, it: 251/468, err: 0.0001\n",
      "Ep: 135/200, it: 301/468, err: 0.0008\n",
      "Ep: 135/200, it: 351/468, err: 0.0269\n",
      "Ep: 135/200, it: 401/468, err: 0.0004\n",
      "Ep: 135/200, it: 451/468, err: 0.0005\n",
      "Ep: 135/200, it: 468/468, err: 0.0125\n",
      "Test acc: 99.48\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    2    1    0    0]\n",
      " [   0    0 1030    0    0    0    0    2    0    0]\n",
      " [   0    0    0 1005    0    4    0    0    1    0]\n",
      " [   0    0    0    0  975    0    5    0    0    2]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    1    0    0    1  950    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    4    0    1    0    0  967    1]\n",
      " [   0    1    0    1    8    1    0    0    1  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1938e-04.\n",
      "Ep: 136/200, it: 1/468, err: 0.0002\n",
      "Ep: 136/200, it: 51/468, err: 0.0001\n",
      "Ep: 136/200, it: 101/468, err: 0.0012\n",
      "Ep: 136/200, it: 151/468, err: 0.0005\n",
      "Ep: 136/200, it: 201/468, err: 0.0015\n",
      "Ep: 136/200, it: 251/468, err: 0.0320\n",
      "Ep: 136/200, it: 301/468, err: 0.0004\n",
      "Ep: 136/200, it: 351/468, err: 0.0004\n",
      "Ep: 136/200, it: 401/468, err: 0.0018\n",
      "Ep: 136/200, it: 451/468, err: 0.0004\n",
      "Ep: 136/200, it: 468/468, err: 0.0057\n",
      "Test acc: 99.47\n",
      "[[ 977    0    1    0    0    0    0    1    0    1]\n",
      " [   0 1130    0    1    0    0    0    4    0    0]\n",
      " [   0    0 1029    0    0    0    0    3    0    0]\n",
      " [   0    0    0 1008    0    2    0    0    0    0]\n",
      " [   0    0    0    0  978    0    2    0    0    2]\n",
      " [   1    0    0    2    0  887    0    2    0    0]\n",
      " [   1    4    1    1    0    1  949    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    3    0    1    0    1  966    2]\n",
      " [   0    0    0    1    6    0    0    3    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1604e-04.\n",
      "Ep: 137/200, it: 1/468, err: 0.0003\n",
      "Ep: 137/200, it: 51/468, err: 0.0090\n",
      "Ep: 137/200, it: 101/468, err: 0.0001\n",
      "Ep: 137/200, it: 151/468, err: 0.0000\n",
      "Ep: 137/200, it: 201/468, err: 0.0001\n",
      "Ep: 137/200, it: 251/468, err: 0.0001\n",
      "Ep: 137/200, it: 301/468, err: 0.0042\n",
      "Ep: 137/200, it: 351/468, err: 0.0001\n",
      "Ep: 137/200, it: 401/468, err: 0.0047\n",
      "Ep: 137/200, it: 451/468, err: 0.0003\n",
      "Ep: 137/200, it: 468/468, err: 0.0047\n",
      "Test acc: 99.41\n",
      "[[ 977    0    1    0    0    0    2    0    0    0]\n",
      " [   0 1128    0    2    0    0    1    4    0    0]\n",
      " [   0    0 1029    0    0    0    0    2    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    5    0  886    0    0    0    0]\n",
      " [   1    2    1    1    1    1  951    0    0    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    1    1    0  967    2]\n",
      " [   0    0    0    3    4    0    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1274e-04.\n",
      "Ep: 138/200, it: 1/468, err: 0.0014\n",
      "Ep: 138/200, it: 51/468, err: 0.0007\n",
      "Ep: 138/200, it: 101/468, err: 0.0003\n",
      "Ep: 138/200, it: 151/468, err: 0.0004\n",
      "Ep: 138/200, it: 201/468, err: 0.0013\n",
      "Ep: 138/200, it: 251/468, err: 0.0017\n",
      "Ep: 138/200, it: 301/468, err: 0.0001\n",
      "Ep: 138/200, it: 351/468, err: 0.0002\n",
      "Ep: 138/200, it: 401/468, err: 0.0004\n",
      "Ep: 138/200, it: 451/468, err: 0.0133\n",
      "Ep: 138/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.45\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1131    0    0    0    0    3    1    0    0]\n",
      " [   0    0 1031    0    0    0    0    1    0    0]\n",
      " [   0    0    0 1003    0    3    0    0    4    0]\n",
      " [   0    0    0    0  973    0    5    0    1    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    1    0    0    0    1  954    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    3    2    0    1    0    0  967    1]\n",
      " [   0    0    0    0    6    3    0    1    2  997]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0948e-04.\n",
      "Ep: 139/200, it: 1/468, err: 0.0038\n",
      "Ep: 139/200, it: 51/468, err: 0.0024\n",
      "Ep: 139/200, it: 101/468, err: 0.0008\n",
      "Ep: 139/200, it: 151/468, err: 0.0001\n",
      "Ep: 139/200, it: 201/468, err: 0.0002\n",
      "Ep: 139/200, it: 251/468, err: 0.0019\n",
      "Ep: 139/200, it: 301/468, err: 0.0001\n",
      "Ep: 139/200, it: 351/468, err: 0.0060\n",
      "Ep: 139/200, it: 401/468, err: 0.0054\n",
      "Ep: 139/200, it: 451/468, err: 0.0002\n",
      "Ep: 139/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.52\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1132    0    2    0    0    1    0    0    0]\n",
      " [   0    0 1030    0    0    0    0    1    1    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  973    0    5    0    1    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    2    0    0    0    1  953    0    1    0]\n",
      " [   0    5    3    1    0    0    0 1019    0    0]\n",
      " [   0    0    0    2    0    0    0    0  970    2]\n",
      " [   0    0    0    0    4    1    0    0    1 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0625e-04.\n",
      "Ep: 140/200, it: 1/468, err: 0.0011\n",
      "Ep: 140/200, it: 51/468, err: 0.0006\n",
      "Ep: 140/200, it: 101/468, err: 0.0005\n",
      "Ep: 140/200, it: 151/468, err: 0.0024\n",
      "Ep: 140/200, it: 201/468, err: 0.0028\n",
      "Ep: 140/200, it: 251/468, err: 0.0002\n",
      "Ep: 140/200, it: 301/468, err: 0.0000\n",
      "Ep: 140/200, it: 351/468, err: 0.0013\n",
      "Ep: 140/200, it: 401/468, err: 0.0002\n",
      "Ep: 140/200, it: 451/468, err: 0.0005\n",
      "Ep: 140/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.45\n",
      "[[ 976    0    1    0    0    0    2    1    0    0]\n",
      " [   0 1130    0    1    1    0    0    3    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    0 1006    0    1    0    0    3    0]\n",
      " [   0    0    1    0  976    0    2    0    0    3]\n",
      " [   1    0    0    4    0  886    0    1    0    0]\n",
      " [   1    4    3    0    0    1  948    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    0    2    0    1    0    1  969    1]\n",
      " [   0    0    0    0    4    2    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0305e-04.\n",
      "Ep: 141/200, it: 1/468, err: 0.0001\n",
      "Ep: 141/200, it: 51/468, err: 0.0001\n",
      "Ep: 141/200, it: 101/468, err: 0.0000\n",
      "Ep: 141/200, it: 151/468, err: 0.0012\n",
      "Ep: 141/200, it: 201/468, err: 0.0008\n",
      "Ep: 141/200, it: 251/468, err: 0.0000\n",
      "Ep: 141/200, it: 301/468, err: 0.0003\n",
      "Ep: 141/200, it: 351/468, err: 0.0006\n",
      "Ep: 141/200, it: 401/468, err: 0.0002\n",
      "Ep: 141/200, it: 451/468, err: 0.0006\n",
      "Ep: 141/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.46\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    1    0    0    0    1    0    0]\n",
      " [   0    0 1030    0    0    0    0    2    0    0]\n",
      " [   0    0    0 1008    0    2    0    0    0    0]\n",
      " [   0    0    0    0  975    0    3    0    0    4]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    3    2    0    1    3  947    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    1    0    1  966    3]\n",
      " [   0    0    0    1    4    2    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9895e-05.\n",
      "Ep: 142/200, it: 1/468, err: 0.0089\n",
      "Ep: 142/200, it: 51/468, err: 0.0007\n",
      "Ep: 142/200, it: 101/468, err: 0.0003\n",
      "Ep: 142/200, it: 151/468, err: 0.0011\n",
      "Ep: 142/200, it: 201/468, err: 0.0004\n",
      "Ep: 142/200, it: 251/468, err: 0.0017\n",
      "Ep: 142/200, it: 301/468, err: 0.0008\n",
      "Ep: 142/200, it: 351/468, err: 0.0002\n",
      "Ep: 142/200, it: 401/468, err: 0.0039\n",
      "Ep: 142/200, it: 451/468, err: 0.0004\n",
      "Ep: 142/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.52\n",
      "[[ 976    0    1    0    0    0    1    1    0    1]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1030    0    0    0    0    2    0    0]\n",
      " [   0    0    0 1006    0    4    0    0    0    0]\n",
      " [   0    0    0    0  974    0    5    0    0    3]\n",
      " [   1    0    0    1    0  888    0    2    0    0]\n",
      " [   1    2    0    0    0    1  953    0    1    0]\n",
      " [   0    2    3    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    3    0    1    0    1  966    2]\n",
      " [   0    1    0    0    5    0    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6773e-05.\n",
      "Ep: 143/200, it: 1/468, err: 0.0000\n",
      "Ep: 143/200, it: 51/468, err: 0.0002\n",
      "Ep: 143/200, it: 101/468, err: 0.0332\n",
      "Ep: 143/200, it: 151/468, err: 0.0001\n",
      "Ep: 143/200, it: 201/468, err: 0.0002\n",
      "Ep: 143/200, it: 251/468, err: 0.0031\n",
      "Ep: 143/200, it: 301/468, err: 0.0059\n",
      "Ep: 143/200, it: 351/468, err: 0.0000\n",
      "Ep: 143/200, it: 401/468, err: 0.0025\n",
      "Ep: 143/200, it: 451/468, err: 0.0004\n",
      "Ep: 143/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.56\n",
      "[[ 978    0    1    0    0    0    0    1    0    0]\n",
      " [   0 1133    0    1    0    0    0    1    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  972    0    3    0    0    7]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    0    0    0    0    1  955    0    1    0]\n",
      " [   0    3    2    1    0    0    0 1022    0    0]\n",
      " [   0    0    0    4    0    2    0    0  966    2]\n",
      " [   0    0    0    0    2    1    0    0    0 1006]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3689e-05.\n",
      "Ep: 144/200, it: 1/468, err: 0.0011\n",
      "Ep: 144/200, it: 51/468, err: 0.0012\n",
      "Ep: 144/200, it: 101/468, err: 0.0003\n",
      "Ep: 144/200, it: 151/468, err: 0.0002\n",
      "Ep: 144/200, it: 201/468, err: 0.0002\n",
      "Ep: 144/200, it: 251/468, err: 0.0054\n",
      "Ep: 144/200, it: 301/468, err: 0.0001\n",
      "Ep: 144/200, it: 351/468, err: 0.0005\n",
      "Ep: 144/200, it: 401/468, err: 0.0003\n",
      "Ep: 144/200, it: 451/468, err: 0.0003\n",
      "Ep: 144/200, it: 468/468, err: 0.0005\n",
      "Test acc: 99.57\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1134    0    0    0    0    1    0    0    0]\n",
      " [   0    0 1032    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   0    0    0    4    0  888    0    0    0    0]\n",
      " [   1    1    0    0    0    2  953    0    1    0]\n",
      " [   0    3    3    1    0    0    0 1021    0    0]\n",
      " [   0    0    0    4    0    1    0    0  968    1]\n",
      " [   0    0    0    1    4    1    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0644e-05.\n",
      "Ep: 145/200, it: 1/468, err: 0.0001\n",
      "Ep: 145/200, it: 51/468, err: 0.0001\n",
      "Ep: 145/200, it: 101/468, err: 0.0001\n",
      "Ep: 145/200, it: 151/468, err: 0.0007\n",
      "Ep: 145/200, it: 201/468, err: 0.0000\n",
      "Ep: 145/200, it: 251/468, err: 0.0002\n",
      "Ep: 145/200, it: 301/468, err: 0.0009\n",
      "Ep: 145/200, it: 351/468, err: 0.0001\n",
      "Ep: 145/200, it: 401/468, err: 0.0019\n",
      "Ep: 145/200, it: 451/468, err: 0.0001\n",
      "Ep: 145/200, it: 468/468, err: 0.0013\n",
      "Test acc: 99.50\n",
      "[[ 978    0    0    0    0    0    2    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    3    3    1    0    0    0 1021    0    0]\n",
      " [   0    0    0    3    0    0    0    0  969    2]\n",
      " [   0    0    0    1    4    1    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7638e-05.\n",
      "Ep: 146/200, it: 1/468, err: 0.0001\n",
      "Ep: 146/200, it: 51/468, err: 0.0006\n",
      "Ep: 146/200, it: 101/468, err: 0.0125\n",
      "Ep: 146/200, it: 151/468, err: 0.0050\n",
      "Ep: 146/200, it: 201/468, err: 0.0001\n",
      "Ep: 146/200, it: 251/468, err: 0.0023\n",
      "Ep: 146/200, it: 301/468, err: 0.0005\n",
      "Ep: 146/200, it: 351/468, err: 0.0035\n",
      "Ep: 146/200, it: 401/468, err: 0.0002\n",
      "Ep: 146/200, it: 451/468, err: 0.0011\n",
      "Ep: 146/200, it: 468/468, err: 0.0027\n",
      "Test acc: 99.46\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1133    0    0    1    0    0    1    0    0]\n",
      " [   0    0 1028    0    0    0    0    3    1    0]\n",
      " [   0    0    0 1006    0    2    0    1    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   0    0    0    4    0  886    1    1    0    0]\n",
      " [   1    4    1    0    0    1  948    0    3    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    0    2    0    0    0    0  970    2]\n",
      " [   0    0    0    1    4    1    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4672e-05.\n",
      "Ep: 147/200, it: 1/468, err: 0.0002\n",
      "Ep: 147/200, it: 51/468, err: 0.0042\n",
      "Ep: 147/200, it: 101/468, err: 0.0004\n",
      "Ep: 147/200, it: 151/468, err: 0.0115\n",
      "Ep: 147/200, it: 201/468, err: 0.0023\n",
      "Ep: 147/200, it: 251/468, err: 0.0000\n",
      "Ep: 147/200, it: 301/468, err: 0.0001\n",
      "Ep: 147/200, it: 351/468, err: 0.0002\n",
      "Ep: 147/200, it: 401/468, err: 0.0084\n",
      "Ep: 147/200, it: 451/468, err: 0.0234\n",
      "Ep: 147/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.40\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1028    0    0    0    0    2    2    0]\n",
      " [   0    0    0 1005    0    3    0    1    1    0]\n",
      " [   0    0    0    0  974    0    5    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    2    2    0    0    2  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    1    8    1    0    2    2  995]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1747e-05.\n",
      "Ep: 148/200, it: 1/468, err: 0.0022\n",
      "Ep: 148/200, it: 51/468, err: 0.0044\n",
      "Ep: 148/200, it: 101/468, err: 0.0001\n",
      "Ep: 148/200, it: 151/468, err: 0.0007\n",
      "Ep: 148/200, it: 201/468, err: 0.0002\n",
      "Ep: 148/200, it: 251/468, err: 0.0002\n",
      "Ep: 148/200, it: 301/468, err: 0.0035\n",
      "Ep: 148/200, it: 351/468, err: 0.0002\n",
      "Ep: 148/200, it: 401/468, err: 0.0273\n",
      "Ep: 148/200, it: 451/468, err: 0.0004\n",
      "Ep: 148/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.47\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1027    0    0    0    0    3    2    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    3    0    0    0    1  951    0    2    0]\n",
      " [   0    2    5    0    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    1    0    0  967    3]\n",
      " [   0    0    0    1    3    2    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8863e-05.\n",
      "Ep: 149/200, it: 1/468, err: 0.0143\n",
      "Ep: 149/200, it: 51/468, err: 0.0001\n",
      "Ep: 149/200, it: 101/468, err: 0.0000\n",
      "Ep: 149/200, it: 151/468, err: 0.0001\n",
      "Ep: 149/200, it: 201/468, err: 0.0002\n",
      "Ep: 149/200, it: 251/468, err: 0.0000\n",
      "Ep: 149/200, it: 301/468, err: 0.0006\n",
      "Ep: 149/200, it: 351/468, err: 0.0005\n",
      "Ep: 149/200, it: 401/468, err: 0.0003\n",
      "Ep: 149/200, it: 451/468, err: 0.0002\n",
      "Ep: 149/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.44\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1028    0    0    0    0    1    3    0]\n",
      " [   0    0    0 1007    0    1    0    0    2    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    3    0  886    1    1    0    0]\n",
      " [   1    3    1    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  969    2]\n",
      " [   0    0    0    1    5    2    0    1    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6022e-05.\n",
      "Ep: 150/200, it: 1/468, err: 0.0007\n",
      "Ep: 150/200, it: 51/468, err: 0.0002\n",
      "Ep: 150/200, it: 101/468, err: 0.0016\n",
      "Ep: 150/200, it: 151/468, err: 0.0000\n",
      "Ep: 150/200, it: 201/468, err: 0.0004\n",
      "Ep: 150/200, it: 251/468, err: 0.0018\n",
      "Ep: 150/200, it: 301/468, err: 0.0062\n",
      "Ep: 150/200, it: 351/468, err: 0.0000\n",
      "Ep: 150/200, it: 401/468, err: 0.0003\n",
      "Ep: 150/200, it: 451/468, err: 0.0002\n",
      "Ep: 150/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.48\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1028    0    0    0    0    1    3    0]\n",
      " [   0    0    0 1007    0    1    0    0    2    0]\n",
      " [   0    0    0    0  975    0    3    0    0    4]\n",
      " [   1    0    0    3    0  885    0    1    1    1]\n",
      " [   1    3    0    0    1    2  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    0    2    0    0    0    1  970    1]\n",
      " [   0    0    0    1    6    1    0    1    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3223e-05.\n",
      "Ep: 151/200, it: 1/468, err: 0.0000\n",
      "Ep: 151/200, it: 51/468, err: 0.0000\n",
      "Ep: 151/200, it: 101/468, err: 0.0000\n",
      "Ep: 151/200, it: 151/468, err: 0.0001\n",
      "Ep: 151/200, it: 201/468, err: 0.0002\n",
      "Ep: 151/200, it: 251/468, err: 0.0001\n",
      "Ep: 151/200, it: 301/468, err: 0.0001\n",
      "Ep: 151/200, it: 351/468, err: 0.0002\n",
      "Ep: 151/200, it: 401/468, err: 0.0055\n",
      "Ep: 151/200, it: 451/468, err: 0.0001\n",
      "Ep: 151/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.43\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1131    0    1    1    0    1    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  971    0    5    0    0    6]\n",
      " [   1    0    0    4    0  885    1    1    0    0]\n",
      " [   1    4    0    0    0    2  950    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    1  969    1]\n",
      " [   0    0    0    1    6    0    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0468e-05.\n",
      "Ep: 152/200, it: 1/468, err: 0.0003\n",
      "Ep: 152/200, it: 51/468, err: 0.0002\n",
      "Ep: 152/200, it: 101/468, err: 0.0003\n",
      "Ep: 152/200, it: 151/468, err: 0.0000\n",
      "Ep: 152/200, it: 201/468, err: 0.0006\n",
      "Ep: 152/200, it: 251/468, err: 0.0001\n",
      "Ep: 152/200, it: 301/468, err: 0.0000\n",
      "Ep: 152/200, it: 351/468, err: 0.0000\n",
      "Ep: 152/200, it: 401/468, err: 0.0004\n",
      "Ep: 152/200, it: 451/468, err: 0.0002\n",
      "Ep: 152/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.47\n",
      "[[ 977    0    0    0    0    0    1    2    0    0]\n",
      " [   0 1133    0    0    1    0    0    1    0    0]\n",
      " [   0    0 1028    1    0    0    0    0    3    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  973    0    5    0    0    4]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    7    1    0    2    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7758e-05.\n",
      "Ep: 153/200, it: 1/468, err: 0.0008\n",
      "Ep: 153/200, it: 51/468, err: 0.0000\n",
      "Ep: 153/200, it: 101/468, err: 0.0002\n",
      "Ep: 153/200, it: 151/468, err: 0.0001\n",
      "Ep: 153/200, it: 201/468, err: 0.0000\n",
      "Ep: 153/200, it: 251/468, err: 0.0023\n",
      "Ep: 153/200, it: 301/468, err: 0.0006\n",
      "Ep: 153/200, it: 351/468, err: 0.0002\n",
      "Ep: 153/200, it: 401/468, err: 0.0000\n",
      "Ep: 153/200, it: 451/468, err: 0.0005\n",
      "Ep: 153/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.47\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    1    0    0    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    3    0  886    1    1    0    0]\n",
      " [   1    4    0    0    2    2  948    0    1    0]\n",
      " [   0    2    3    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  969    2]\n",
      " [   0    0    0    0    5    1    0    0    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5092e-05.\n",
      "Ep: 154/200, it: 1/468, err: 0.0002\n",
      "Ep: 154/200, it: 51/468, err: 0.0014\n",
      "Ep: 154/200, it: 101/468, err: 0.0002\n",
      "Ep: 154/200, it: 151/468, err: 0.0001\n",
      "Ep: 154/200, it: 201/468, err: 0.0000\n",
      "Ep: 154/200, it: 251/468, err: 0.0006\n",
      "Ep: 154/200, it: 301/468, err: 0.0003\n",
      "Ep: 154/200, it: 351/468, err: 0.0001\n",
      "Ep: 154/200, it: 401/468, err: 0.0024\n",
      "Ep: 154/200, it: 451/468, err: 0.0002\n",
      "Ep: 154/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.53\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1134    0    0    1    0    0    0    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1006    0    3    0    0    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    1    2  949    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  969    2]\n",
      " [   0    0    0    0    3    0    0    0    0 1006]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2472e-05.\n",
      "Ep: 155/200, it: 1/468, err: 0.0001\n",
      "Ep: 155/200, it: 51/468, err: 0.0004\n",
      "Ep: 155/200, it: 101/468, err: 0.0004\n",
      "Ep: 155/200, it: 151/468, err: 0.0000\n",
      "Ep: 155/200, it: 201/468, err: 0.0000\n",
      "Ep: 155/200, it: 251/468, err: 0.0001\n",
      "Ep: 155/200, it: 301/468, err: 0.0366\n",
      "Ep: 155/200, it: 351/468, err: 0.0007\n",
      "Ep: 155/200, it: 401/468, err: 0.0000\n",
      "Ep: 155/200, it: 451/468, err: 0.0001\n",
      "Ep: 155/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.46\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1027    1    0    0    0    1    3    0]\n",
      " [   0    0    0 1004    0    5    0    0    1    0]\n",
      " [   0    0    0    0  971    0    5    0    0    6]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    0    2    0    0    0    1  969    2]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9899e-05.\n",
      "Ep: 156/200, it: 1/468, err: 0.0003\n",
      "Ep: 156/200, it: 51/468, err: 0.0035\n",
      "Ep: 156/200, it: 101/468, err: 0.0102\n",
      "Ep: 156/200, it: 151/468, err: 0.0001\n",
      "Ep: 156/200, it: 201/468, err: 0.0005\n",
      "Ep: 156/200, it: 251/468, err: 0.0019\n",
      "Ep: 156/200, it: 301/468, err: 0.0034\n",
      "Ep: 156/200, it: 351/468, err: 0.0001\n",
      "Ep: 156/200, it: 401/468, err: 0.0000\n",
      "Ep: 156/200, it: 451/468, err: 0.0268\n",
      "Ep: 156/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.45\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  972    0    5    0    0    5]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    6    1    0    0    0 1019    0    0]\n",
      " [   0    0    1    3    0    0    0    0  968    2]\n",
      " [   0    0    0    1    4    2    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7372e-05.\n",
      "Ep: 157/200, it: 1/468, err: 0.0003\n",
      "Ep: 157/200, it: 51/468, err: 0.0000\n",
      "Ep: 157/200, it: 101/468, err: 0.0005\n",
      "Ep: 157/200, it: 151/468, err: 0.0008\n",
      "Ep: 157/200, it: 201/468, err: 0.0002\n",
      "Ep: 157/200, it: 251/468, err: 0.0001\n",
      "Ep: 157/200, it: 301/468, err: 0.0001\n",
      "Ep: 157/200, it: 351/468, err: 0.0016\n",
      "Ep: 157/200, it: 401/468, err: 0.0001\n",
      "Ep: 157/200, it: 451/468, err: 0.0001\n",
      "Ep: 157/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.52\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1028    1    0    0    0    1    2    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    5    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    2  950    0    1    0]\n",
      " [   0    2    2    2    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    1  969    1]\n",
      " [   0    0    0    0    5    2    0    0    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4892e-05.\n",
      "Ep: 158/200, it: 1/468, err: 0.0002\n",
      "Ep: 158/200, it: 51/468, err: 0.0000\n",
      "Ep: 158/200, it: 101/468, err: 0.0002\n",
      "Ep: 158/200, it: 151/468, err: 0.0032\n",
      "Ep: 158/200, it: 201/468, err: 0.0014\n",
      "Ep: 158/200, it: 251/468, err: 0.0009\n",
      "Ep: 158/200, it: 301/468, err: 0.0001\n",
      "Ep: 158/200, it: 351/468, err: 0.0007\n",
      "Ep: 158/200, it: 401/468, err: 0.0012\n",
      "Ep: 158/200, it: 451/468, err: 0.0000\n",
      "Ep: 158/200, it: 468/468, err: 0.0036\n",
      "Test acc: 99.51\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  971    0    5    0    0    6]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    1    2    1    0    0    0 1024    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    3    2    0    2    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2461e-05.\n",
      "Ep: 159/200, it: 1/468, err: 0.0010\n",
      "Ep: 159/200, it: 51/468, err: 0.0001\n",
      "Ep: 159/200, it: 101/468, err: 0.0001\n",
      "Ep: 159/200, it: 151/468, err: 0.0018\n",
      "Ep: 159/200, it: 201/468, err: 0.0086\n",
      "Ep: 159/200, it: 251/468, err: 0.0000\n",
      "Ep: 159/200, it: 301/468, err: 0.0026\n",
      "Ep: 159/200, it: 351/468, err: 0.0002\n",
      "Ep: 159/200, it: 401/468, err: 0.0000\n",
      "Ep: 159/200, it: 451/468, err: 0.0005\n",
      "Ep: 159/200, it: 468/468, err: 0.0041\n",
      "Test acc: 99.47\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    0    2    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1006    0    2    0    0    2    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   2    3    0    0    1    2  947    0    3    0]\n",
      " [   0    2    3    0    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    4    1    0    2    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0079e-05.\n",
      "Ep: 160/200, it: 1/468, err: 0.0001\n",
      "Ep: 160/200, it: 51/468, err: 0.0001\n",
      "Ep: 160/200, it: 101/468, err: 0.0007\n",
      "Ep: 160/200, it: 151/468, err: 0.0021\n",
      "Ep: 160/200, it: 201/468, err: 0.0002\n",
      "Ep: 160/200, it: 251/468, err: 0.0000\n",
      "Ep: 160/200, it: 301/468, err: 0.0007\n",
      "Ep: 160/200, it: 351/468, err: 0.0000\n",
      "Ep: 160/200, it: 401/468, err: 0.0001\n",
      "Ep: 160/200, it: 451/468, err: 0.0038\n",
      "Ep: 160/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.48\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    1    0    0    2    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    3    0    0    0    1  950    0    3    0]\n",
      " [   0    1    3    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    4    2    0    4    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7746e-05.\n",
      "Ep: 161/200, it: 1/468, err: 0.0000\n",
      "Ep: 161/200, it: 51/468, err: 0.0000\n",
      "Ep: 161/200, it: 101/468, err: 0.0006\n",
      "Ep: 161/200, it: 151/468, err: 0.0001\n",
      "Ep: 161/200, it: 201/468, err: 0.0009\n",
      "Ep: 161/200, it: 251/468, err: 0.0068\n",
      "Ep: 161/200, it: 301/468, err: 0.0001\n",
      "Ep: 161/200, it: 351/468, err: 0.0003\n",
      "Ep: 161/200, it: 401/468, err: 0.0005\n",
      "Ep: 161/200, it: 451/468, err: 0.0001\n",
      "Ep: 161/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.49\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    2    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    3    0    0    0    1  951    0    2    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    3    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5463e-05.\n",
      "Ep: 162/200, it: 1/468, err: 0.0011\n",
      "Ep: 162/200, it: 51/468, err: 0.0008\n",
      "Ep: 162/200, it: 101/468, err: 0.0002\n",
      "Ep: 162/200, it: 151/468, err: 0.0025\n",
      "Ep: 162/200, it: 201/468, err: 0.0006\n",
      "Ep: 162/200, it: 251/468, err: 0.0000\n",
      "Ep: 162/200, it: 301/468, err: 0.0002\n",
      "Ep: 162/200, it: 351/468, err: 0.0000\n",
      "Ep: 162/200, it: 401/468, err: 0.0286\n",
      "Ep: 162/200, it: 451/468, err: 0.0008\n",
      "Ep: 162/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1027    1    0    0    0    2    2    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  949    0    3    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   1    0    1    2    0    0    0    0  969    1]\n",
      " [   0    0    0    0    5    0    0    1    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3230e-05.\n",
      "Ep: 163/200, it: 1/468, err: 0.0001\n",
      "Ep: 163/200, it: 51/468, err: 0.0000\n",
      "Ep: 163/200, it: 101/468, err: 0.0001\n",
      "Ep: 163/200, it: 151/468, err: 0.0001\n",
      "Ep: 163/200, it: 201/468, err: 0.0004\n",
      "Ep: 163/200, it: 251/468, err: 0.0023\n",
      "Ep: 163/200, it: 301/468, err: 0.0002\n",
      "Ep: 163/200, it: 351/468, err: 0.0000\n",
      "Ep: 163/200, it: 401/468, err: 0.0001\n",
      "Ep: 163/200, it: 451/468, err: 0.0013\n",
      "Ep: 163/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.50\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    0    0    3    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    2  949    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    0    2    0    0    0    0  970    2]\n",
      " [   0    0    0    0    5    0    0    1    0 1003]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1048e-05.\n",
      "Ep: 164/200, it: 1/468, err: 0.0001\n",
      "Ep: 164/200, it: 51/468, err: 0.0000\n",
      "Ep: 164/200, it: 101/468, err: 0.0001\n",
      "Ep: 164/200, it: 151/468, err: 0.0020\n",
      "Ep: 164/200, it: 201/468, err: 0.0003\n",
      "Ep: 164/200, it: 251/468, err: 0.0005\n",
      "Ep: 164/200, it: 301/468, err: 0.0001\n",
      "Ep: 164/200, it: 351/468, err: 0.0000\n",
      "Ep: 164/200, it: 401/468, err: 0.0000\n",
      "Ep: 164/200, it: 451/468, err: 0.0006\n",
      "Ep: 164/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.52\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  973    0    5    0    0    4]\n",
      " [   1    0    0    3    0  887    0    1    0    0]\n",
      " [   1    3    0    0    0    1  952    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    0    0    1    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8918e-05.\n",
      "Ep: 165/200, it: 1/468, err: 0.0005\n",
      "Ep: 165/200, it: 51/468, err: 0.0007\n",
      "Ep: 165/200, it: 101/468, err: 0.0002\n",
      "Ep: 165/200, it: 151/468, err: 0.0010\n",
      "Ep: 165/200, it: 201/468, err: 0.0009\n",
      "Ep: 165/200, it: 251/468, err: 0.0001\n",
      "Ep: 165/200, it: 301/468, err: 0.0005\n",
      "Ep: 165/200, it: 351/468, err: 0.0001\n",
      "Ep: 165/200, it: 401/468, err: 0.0001\n",
      "Ep: 165/200, it: 451/468, err: 0.0001\n",
      "Ep: 165/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.50\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1131    0    0    0    0    0    4    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    1    1  949    0    2    0]\n",
      " [   0    1    3    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    5    0    0    3    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6840e-05.\n",
      "Ep: 166/200, it: 1/468, err: 0.0071\n",
      "Ep: 166/200, it: 51/468, err: 0.0002\n",
      "Ep: 166/200, it: 101/468, err: 0.0241\n",
      "Ep: 166/200, it: 151/468, err: 0.0004\n",
      "Ep: 166/200, it: 201/468, err: 0.0030\n",
      "Ep: 166/200, it: 251/468, err: 0.0001\n",
      "Ep: 166/200, it: 301/468, err: 0.0006\n",
      "Ep: 166/200, it: 351/468, err: 0.0001\n",
      "Ep: 166/200, it: 401/468, err: 0.0001\n",
      "Ep: 166/200, it: 451/468, err: 0.0000\n",
      "Ep: 166/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.52\n",
      "[[ 977    0    1    0    0    0    1    1    0    0]\n",
      " [   0 1134    0    0    0    0    1    0    0    0]\n",
      " [   0    0 1028    1    0    0    0    2    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    2    0    0    0    0 1024    0    0]\n",
      " [   0    0    1    2    0    0    0    1  969    1]\n",
      " [   0    1    0    0    6    1    0    2    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4814e-05.\n",
      "Ep: 167/200, it: 1/468, err: 0.0001\n",
      "Ep: 167/200, it: 51/468, err: 0.0007\n",
      "Ep: 167/200, it: 101/468, err: 0.0000\n",
      "Ep: 167/200, it: 151/468, err: 0.0010\n",
      "Ep: 167/200, it: 201/468, err: 0.0003\n",
      "Ep: 167/200, it: 251/468, err: 0.0000\n",
      "Ep: 167/200, it: 301/468, err: 0.0003\n",
      "Ep: 167/200, it: 351/468, err: 0.0001\n",
      "Ep: 167/200, it: 401/468, err: 0.0237\n",
      "Ep: 167/200, it: 451/468, err: 0.0001\n",
      "Ep: 167/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.47\n",
      "[[ 977    0    0    0    0    0    2    1    0    0]\n",
      " [   0 1131    0    0    0    0    2    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    1    0    0    1  949    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    1    0    0    4    2    0    2    2  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2842e-05.\n",
      "Ep: 168/200, it: 1/468, err: 0.0001\n",
      "Ep: 168/200, it: 51/468, err: 0.0000\n",
      "Ep: 168/200, it: 101/468, err: 0.0001\n",
      "Ep: 168/200, it: 151/468, err: 0.0000\n",
      "Ep: 168/200, it: 201/468, err: 0.0001\n",
      "Ep: 168/200, it: 251/468, err: 0.0036\n",
      "Ep: 168/200, it: 301/468, err: 0.0068\n",
      "Ep: 168/200, it: 351/468, err: 0.0001\n",
      "Ep: 168/200, it: 401/468, err: 0.0000\n",
      "Ep: 168/200, it: 451/468, err: 0.0004\n",
      "Ep: 168/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.54\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    3    1    0    0    1  950    0    2    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    1    0    0    3    1    0    2    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0923e-05.\n",
      "Ep: 169/200, it: 1/468, err: 0.0002\n",
      "Ep: 169/200, it: 51/468, err: 0.0001\n",
      "Ep: 169/200, it: 101/468, err: 0.0001\n",
      "Ep: 169/200, it: 151/468, err: 0.0001\n",
      "Ep: 169/200, it: 201/468, err: 0.0002\n",
      "Ep: 169/200, it: 251/468, err: 0.0000\n",
      "Ep: 169/200, it: 301/468, err: 0.0002\n",
      "Ep: 169/200, it: 351/468, err: 0.0033\n",
      "Ep: 169/200, it: 401/468, err: 0.0001\n",
      "Ep: 169/200, it: 451/468, err: 0.0001\n",
      "Ep: 169/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.52\n",
      "[[ 977    0    1    0    0    0    2    0    0    0]\n",
      " [   0 1132    0    0    0    0    0    3    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    1    0    0    2  948    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    3    2    0    2    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9059e-05.\n",
      "Ep: 170/200, it: 1/468, err: 0.0011\n",
      "Ep: 170/200, it: 51/468, err: 0.0000\n",
      "Ep: 170/200, it: 101/468, err: 0.0000\n",
      "Ep: 170/200, it: 151/468, err: 0.0008\n",
      "Ep: 170/200, it: 201/468, err: 0.0001\n",
      "Ep: 170/200, it: 251/468, err: 0.0001\n",
      "Ep: 170/200, it: 301/468, err: 0.0005\n",
      "Ep: 170/200, it: 351/468, err: 0.0002\n",
      "Ep: 170/200, it: 401/468, err: 0.0002\n",
      "Ep: 170/200, it: 451/468, err: 0.0001\n",
      "Ep: 170/200, it: 468/468, err: 0.0021\n",
      "Test acc: 99.49\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    4    0  887    0    0    0    0]\n",
      " [   1    4    0    0    0    1  950    0    2    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    3    1  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7248e-05.\n",
      "Ep: 171/200, it: 1/468, err: 0.0002\n",
      "Ep: 171/200, it: 51/468, err: 0.0004\n",
      "Ep: 171/200, it: 101/468, err: 0.0266\n",
      "Ep: 171/200, it: 151/468, err: 0.0022\n",
      "Ep: 171/200, it: 201/468, err: 0.0000\n",
      "Ep: 171/200, it: 251/468, err: 0.0000\n",
      "Ep: 171/200, it: 301/468, err: 0.0010\n",
      "Ep: 171/200, it: 351/468, err: 0.0000\n",
      "Ep: 171/200, it: 401/468, err: 0.0000\n",
      "Ep: 171/200, it: 451/468, err: 0.0001\n",
      "Ep: 171/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.54\n",
      "[[ 977    0    1    0    0    0    2    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  973    0    4    0    0    5]\n",
      " [   1    0    0    3    0  888    0    0    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  969    2]\n",
      " [   0    0    0    0    4    0    0    1    0 1004]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5493e-05.\n",
      "Ep: 172/200, it: 1/468, err: 0.0002\n",
      "Ep: 172/200, it: 51/468, err: 0.0002\n",
      "Ep: 172/200, it: 101/468, err: 0.0010\n",
      "Ep: 172/200, it: 151/468, err: 0.0000\n",
      "Ep: 172/200, it: 201/468, err: 0.0007\n",
      "Ep: 172/200, it: 251/468, err: 0.0005\n",
      "Ep: 172/200, it: 301/468, err: 0.0000\n",
      "Ep: 172/200, it: 351/468, err: 0.0000\n",
      "Ep: 172/200, it: 401/468, err: 0.0001\n",
      "Ep: 172/200, it: 451/468, err: 0.0001\n",
      "Ep: 172/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.56\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1027    1    0    0    0    2    2    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    0    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3793e-05.\n",
      "Ep: 173/200, it: 1/468, err: 0.0001\n",
      "Ep: 173/200, it: 51/468, err: 0.0006\n",
      "Ep: 173/200, it: 101/468, err: 0.0000\n",
      "Ep: 173/200, it: 151/468, err: 0.0001\n",
      "Ep: 173/200, it: 201/468, err: 0.0001\n",
      "Ep: 173/200, it: 251/468, err: 0.0001\n",
      "Ep: 173/200, it: 301/468, err: 0.0007\n",
      "Ep: 173/200, it: 351/468, err: 0.0002\n",
      "Ep: 173/200, it: 401/468, err: 0.0001\n",
      "Ep: 173/200, it: 451/468, err: 0.0002\n",
      "Ep: 173/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.55\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    4    1    0    1    1  949    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    0    0    1    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2149e-05.\n",
      "Ep: 174/200, it: 1/468, err: 0.0000\n",
      "Ep: 174/200, it: 51/468, err: 0.0000\n",
      "Ep: 174/200, it: 101/468, err: 0.0005\n",
      "Ep: 174/200, it: 151/468, err: 0.0018\n",
      "Ep: 174/200, it: 201/468, err: 0.0000\n",
      "Ep: 174/200, it: 251/468, err: 0.0000\n",
      "Ep: 174/200, it: 301/468, err: 0.0001\n",
      "Ep: 174/200, it: 351/468, err: 0.0001\n",
      "Ep: 174/200, it: 401/468, err: 0.0003\n",
      "Ep: 174/200, it: 451/468, err: 0.0000\n",
      "Ep: 174/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.55\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    0    3    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    1    0    0    1  949    0    2    0]\n",
      " [   0    2    2    1    0    0    0 1023    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    0    0    1    0 1002]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0561e-05.\n",
      "Ep: 175/200, it: 1/468, err: 0.0000\n",
      "Ep: 175/200, it: 51/468, err: 0.0000\n",
      "Ep: 175/200, it: 101/468, err: 0.0001\n",
      "Ep: 175/200, it: 151/468, err: 0.0002\n",
      "Ep: 175/200, it: 201/468, err: 0.0007\n",
      "Ep: 175/200, it: 251/468, err: 0.0003\n",
      "Ep: 175/200, it: 301/468, err: 0.0006\n",
      "Ep: 175/200, it: 351/468, err: 0.0009\n",
      "Ep: 175/200, it: 401/468, err: 0.0000\n",
      "Ep: 175/200, it: 451/468, err: 0.0001\n",
      "Ep: 175/200, it: 468/468, err: 0.0005\n",
      "Test acc: 99.57\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    3    1    0    0    0 1022    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    0    0    1    1 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9030e-05.\n",
      "Ep: 176/200, it: 1/468, err: 0.0000\n",
      "Ep: 176/200, it: 51/468, err: 0.0006\n",
      "Ep: 176/200, it: 101/468, err: 0.0003\n",
      "Ep: 176/200, it: 151/468, err: 0.0061\n",
      "Ep: 176/200, it: 201/468, err: 0.0001\n",
      "Ep: 176/200, it: 251/468, err: 0.0001\n",
      "Ep: 176/200, it: 301/468, err: 0.0004\n",
      "Ep: 176/200, it: 351/468, err: 0.0001\n",
      "Ep: 176/200, it: 401/468, err: 0.0000\n",
      "Ep: 176/200, it: 451/468, err: 0.0000\n",
      "Ep: 176/200, it: 468/468, err: 0.0006\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    2    0    2    1  998]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7556e-05.\n",
      "Ep: 177/200, it: 1/468, err: 0.0001\n",
      "Ep: 177/200, it: 51/468, err: 0.0000\n",
      "Ep: 177/200, it: 101/468, err: 0.0000\n",
      "Ep: 177/200, it: 151/468, err: 0.0001\n",
      "Ep: 177/200, it: 201/468, err: 0.0002\n",
      "Ep: 177/200, it: 251/468, err: 0.0144\n",
      "Ep: 177/200, it: 301/468, err: 0.0004\n",
      "Ep: 177/200, it: 351/468, err: 0.0000\n",
      "Ep: 177/200, it: 401/468, err: 0.0000\n",
      "Ep: 177/200, it: 451/468, err: 0.0001\n",
      "Ep: 177/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    2    0    2    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6139e-05.\n",
      "Ep: 178/200, it: 1/468, err: 0.0000\n",
      "Ep: 178/200, it: 51/468, err: 0.0001\n",
      "Ep: 178/200, it: 101/468, err: 0.0003\n",
      "Ep: 178/200, it: 151/468, err: 0.0000\n",
      "Ep: 178/200, it: 201/468, err: 0.0001\n",
      "Ep: 178/200, it: 251/468, err: 0.0001\n",
      "Ep: 178/200, it: 301/468, err: 0.0128\n",
      "Ep: 178/200, it: 351/468, err: 0.0001\n",
      "Ep: 178/200, it: 401/468, err: 0.0007\n",
      "Ep: 178/200, it: 451/468, err: 0.0005\n",
      "Ep: 178/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.55\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4780e-05.\n",
      "Ep: 179/200, it: 1/468, err: 0.0000\n",
      "Ep: 179/200, it: 51/468, err: 0.0001\n",
      "Ep: 179/200, it: 101/468, err: 0.0007\n",
      "Ep: 179/200, it: 151/468, err: 0.0000\n",
      "Ep: 179/200, it: 201/468, err: 0.0003\n",
      "Ep: 179/200, it: 251/468, err: 0.0003\n",
      "Ep: 179/200, it: 301/468, err: 0.0002\n",
      "Ep: 179/200, it: 351/468, err: 0.0002\n",
      "Ep: 179/200, it: 401/468, err: 0.0000\n",
      "Ep: 179/200, it: 451/468, err: 0.0001\n",
      "Ep: 179/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3479e-05.\n",
      "Ep: 180/200, it: 1/468, err: 0.0000\n",
      "Ep: 180/200, it: 51/468, err: 0.0004\n",
      "Ep: 180/200, it: 101/468, err: 0.0000\n",
      "Ep: 180/200, it: 151/468, err: 0.0079\n",
      "Ep: 180/200, it: 201/468, err: 0.0001\n",
      "Ep: 180/200, it: 251/468, err: 0.0000\n",
      "Ep: 180/200, it: 301/468, err: 0.0000\n",
      "Ep: 180/200, it: 351/468, err: 0.0000\n",
      "Ep: 180/200, it: 401/468, err: 0.0004\n",
      "Ep: 180/200, it: 451/468, err: 0.0000\n",
      "Ep: 180/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.54\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    3    0  999]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2236e-05.\n",
      "Ep: 181/200, it: 1/468, err: 0.0001\n",
      "Ep: 181/200, it: 51/468, err: 0.0006\n",
      "Ep: 181/200, it: 101/468, err: 0.0000\n",
      "Ep: 181/200, it: 151/468, err: 0.0001\n",
      "Ep: 181/200, it: 201/468, err: 0.0000\n",
      "Ep: 181/200, it: 251/468, err: 0.0000\n",
      "Ep: 181/200, it: 301/468, err: 0.0000\n",
      "Ep: 181/200, it: 351/468, err: 0.0002\n",
      "Ep: 181/200, it: 401/468, err: 0.0001\n",
      "Ep: 181/200, it: 451/468, err: 0.0000\n",
      "Ep: 181/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.54\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1052e-05.\n",
      "Ep: 182/200, it: 1/468, err: 0.0002\n",
      "Ep: 182/200, it: 51/468, err: 0.0003\n",
      "Ep: 182/200, it: 101/468, err: 0.0000\n",
      "Ep: 182/200, it: 151/468, err: 0.0001\n",
      "Ep: 182/200, it: 201/468, err: 0.0003\n",
      "Ep: 182/200, it: 251/468, err: 0.0001\n",
      "Ep: 182/200, it: 301/468, err: 0.0002\n",
      "Ep: 182/200, it: 351/468, err: 0.0000\n",
      "Ep: 182/200, it: 401/468, err: 0.0008\n",
      "Ep: 182/200, it: 451/468, err: 0.0010\n",
      "Ep: 182/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9266e-06.\n",
      "Ep: 183/200, it: 1/468, err: 0.0002\n",
      "Ep: 183/200, it: 51/468, err: 0.0000\n",
      "Ep: 183/200, it: 101/468, err: 0.0002\n",
      "Ep: 183/200, it: 151/468, err: 0.0004\n",
      "Ep: 183/200, it: 201/468, err: 0.0009\n",
      "Ep: 183/200, it: 251/468, err: 0.0000\n",
      "Ep: 183/200, it: 301/468, err: 0.0002\n",
      "Ep: 183/200, it: 351/468, err: 0.0000\n",
      "Ep: 183/200, it: 401/468, err: 0.0001\n",
      "Ep: 183/200, it: 451/468, err: 0.0001\n",
      "Ep: 183/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.54\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8606e-06.\n",
      "Ep: 184/200, it: 1/468, err: 0.0001\n",
      "Ep: 184/200, it: 51/468, err: 0.0001\n",
      "Ep: 184/200, it: 101/468, err: 0.0000\n",
      "Ep: 184/200, it: 151/468, err: 0.0001\n",
      "Ep: 184/200, it: 201/468, err: 0.0000\n",
      "Ep: 184/200, it: 251/468, err: 0.0015\n",
      "Ep: 184/200, it: 301/468, err: 0.0000\n",
      "Ep: 184/200, it: 351/468, err: 0.0000\n",
      "Ep: 184/200, it: 401/468, err: 0.0001\n",
      "Ep: 184/200, it: 451/468, err: 0.0000\n",
      "Ep: 184/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.55\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8542e-06.\n",
      "Ep: 185/200, it: 1/468, err: 0.0001\n",
      "Ep: 185/200, it: 51/468, err: 0.0004\n",
      "Ep: 185/200, it: 101/468, err: 0.0003\n",
      "Ep: 185/200, it: 151/468, err: 0.0001\n",
      "Ep: 185/200, it: 201/468, err: 0.0002\n",
      "Ep: 185/200, it: 251/468, err: 0.0003\n",
      "Ep: 185/200, it: 301/468, err: 0.0000\n",
      "Ep: 185/200, it: 351/468, err: 0.0001\n",
      "Ep: 185/200, it: 401/468, err: 0.0002\n",
      "Ep: 185/200, it: 451/468, err: 0.0000\n",
      "Ep: 185/200, it: 468/468, err: 0.0013\n",
      "Test acc: 99.56\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9075e-06.\n",
      "Ep: 186/200, it: 1/468, err: 0.0013\n",
      "Ep: 186/200, it: 51/468, err: 0.0000\n",
      "Ep: 186/200, it: 101/468, err: 0.0006\n",
      "Ep: 186/200, it: 151/468, err: 0.0001\n",
      "Ep: 186/200, it: 201/468, err: 0.0002\n",
      "Ep: 186/200, it: 251/468, err: 0.0000\n",
      "Ep: 186/200, it: 301/468, err: 0.0000\n",
      "Ep: 186/200, it: 351/468, err: 0.0000\n",
      "Ep: 186/200, it: 401/468, err: 0.0000\n",
      "Ep: 186/200, it: 451/468, err: 0.0001\n",
      "Ep: 186/200, it: 468/468, err: 0.0008\n",
      "Test acc: 99.55\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1008    0    1    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0208e-06.\n",
      "Ep: 187/200, it: 1/468, err: 0.0001\n",
      "Ep: 187/200, it: 51/468, err: 0.0005\n",
      "Ep: 187/200, it: 101/468, err: 0.0005\n",
      "Ep: 187/200, it: 151/468, err: 0.0003\n",
      "Ep: 187/200, it: 201/468, err: 0.0000\n",
      "Ep: 187/200, it: 251/468, err: 0.0001\n",
      "Ep: 187/200, it: 301/468, err: 0.0000\n",
      "Ep: 187/200, it: 351/468, err: 0.0001\n",
      "Ep: 187/200, it: 401/468, err: 0.0007\n",
      "Ep: 187/200, it: 451/468, err: 0.0002\n",
      "Ep: 187/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.54\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    1    1  950    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1943e-06.\n",
      "Ep: 188/200, it: 1/468, err: 0.0000\n",
      "Ep: 188/200, it: 51/468, err: 0.0001\n",
      "Ep: 188/200, it: 101/468, err: 0.0001\n",
      "Ep: 188/200, it: 151/468, err: 0.0001\n",
      "Ep: 188/200, it: 201/468, err: 0.0000\n",
      "Ep: 188/200, it: 251/468, err: 0.0001\n",
      "Ep: 188/200, it: 301/468, err: 0.0003\n",
      "Ep: 188/200, it: 351/468, err: 0.0000\n",
      "Ep: 188/200, it: 401/468, err: 0.0016\n",
      "Ep: 188/200, it: 451/468, err: 0.0000\n",
      "Ep: 188/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.55\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  974    0    4    0    0    4]\n",
      " [   1    0    0    1    0  890    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4282e-06.\n",
      "Ep: 189/200, it: 1/468, err: 0.0000\n",
      "Ep: 189/200, it: 51/468, err: 0.0005\n",
      "Ep: 189/200, it: 101/468, err: 0.0000\n",
      "Ep: 189/200, it: 151/468, err: 0.0001\n",
      "Ep: 189/200, it: 201/468, err: 0.0000\n",
      "Ep: 189/200, it: 251/468, err: 0.0000\n",
      "Ep: 189/200, it: 301/468, err: 0.0001\n",
      "Ep: 189/200, it: 351/468, err: 0.0000\n",
      "Ep: 189/200, it: 401/468, err: 0.0001\n",
      "Ep: 189/200, it: 451/468, err: 0.0027\n",
      "Ep: 189/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.55\n",
      "[[ 979    0    0    0    0    0    1    0    0    0]\n",
      " [   0 1134    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7227e-06.\n",
      "Ep: 190/200, it: 1/468, err: 0.0000\n",
      "Ep: 190/200, it: 51/468, err: 0.0002\n",
      "Ep: 190/200, it: 101/468, err: 0.0003\n",
      "Ep: 190/200, it: 151/468, err: 0.0000\n",
      "Ep: 190/200, it: 201/468, err: 0.0000\n",
      "Ep: 190/200, it: 251/468, err: 0.0000\n",
      "Ep: 190/200, it: 301/468, err: 0.0001\n",
      "Ep: 190/200, it: 351/468, err: 0.0001\n",
      "Ep: 190/200, it: 401/468, err: 0.0002\n",
      "Ep: 190/200, it: 451/468, err: 0.0002\n",
      "Ep: 190/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1028    1    0    0    0    1    2    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  889    0    0    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0779e-06.\n",
      "Ep: 191/200, it: 1/468, err: 0.0000\n",
      "Ep: 191/200, it: 51/468, err: 0.0000\n",
      "Ep: 191/200, it: 101/468, err: 0.0001\n",
      "Ep: 191/200, it: 151/468, err: 0.0000\n",
      "Ep: 191/200, it: 201/468, err: 0.0002\n",
      "Ep: 191/200, it: 251/468, err: 0.0002\n",
      "Ep: 191/200, it: 301/468, err: 0.0001\n",
      "Ep: 191/200, it: 351/468, err: 0.0008\n",
      "Ep: 191/200, it: 401/468, err: 0.0001\n",
      "Ep: 191/200, it: 451/468, err: 0.0001\n",
      "Ep: 191/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4941e-06.\n",
      "Ep: 192/200, it: 1/468, err: 0.0080\n",
      "Ep: 192/200, it: 51/468, err: 0.0011\n",
      "Ep: 192/200, it: 101/468, err: 0.0017\n",
      "Ep: 192/200, it: 151/468, err: 0.0000\n",
      "Ep: 192/200, it: 201/468, err: 0.0011\n",
      "Ep: 192/200, it: 251/468, err: 0.0000\n",
      "Ep: 192/200, it: 301/468, err: 0.0006\n",
      "Ep: 192/200, it: 351/468, err: 0.0000\n",
      "Ep: 192/200, it: 401/468, err: 0.0011\n",
      "Ep: 192/200, it: 451/468, err: 0.0001\n",
      "Ep: 192/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.51\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9713e-06.\n",
      "Ep: 193/200, it: 1/468, err: 0.0002\n",
      "Ep: 193/200, it: 51/468, err: 0.0000\n",
      "Ep: 193/200, it: 101/468, err: 0.0000\n",
      "Ep: 193/200, it: 151/468, err: 0.0001\n",
      "Ep: 193/200, it: 201/468, err: 0.0001\n",
      "Ep: 193/200, it: 251/468, err: 0.0003\n",
      "Ep: 193/200, it: 301/468, err: 0.0003\n",
      "Ep: 193/200, it: 351/468, err: 0.0011\n",
      "Ep: 193/200, it: 401/468, err: 0.0000\n",
      "Ep: 193/200, it: 451/468, err: 0.0000\n",
      "Ep: 193/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.51\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5098e-06.\n",
      "Ep: 194/200, it: 1/468, err: 0.0001\n",
      "Ep: 194/200, it: 51/468, err: 0.0000\n",
      "Ep: 194/200, it: 101/468, err: 0.0001\n",
      "Ep: 194/200, it: 151/468, err: 0.0000\n",
      "Ep: 194/200, it: 201/468, err: 0.0001\n",
      "Ep: 194/200, it: 251/468, err: 0.0000\n",
      "Ep: 194/200, it: 301/468, err: 0.0001\n",
      "Ep: 194/200, it: 351/468, err: 0.0001\n",
      "Ep: 194/200, it: 401/468, err: 0.0001\n",
      "Ep: 194/200, it: 451/468, err: 0.0018\n",
      "Ep: 194/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1030    1    0    0    0    1    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    2    0 1000]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1095e-06.\n",
      "Ep: 195/200, it: 1/468, err: 0.0001\n",
      "Ep: 195/200, it: 51/468, err: 0.0009\n",
      "Ep: 195/200, it: 101/468, err: 0.0001\n",
      "Ep: 195/200, it: 151/468, err: 0.0000\n",
      "Ep: 195/200, it: 201/468, err: 0.0000\n",
      "Ep: 195/200, it: 251/468, err: 0.0001\n",
      "Ep: 195/200, it: 301/468, err: 0.0001\n",
      "Ep: 195/200, it: 351/468, err: 0.0006\n",
      "Ep: 195/200, it: 401/468, err: 0.0000\n",
      "Ep: 195/200, it: 451/468, err: 0.0001\n",
      "Ep: 195/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7067e-07.\n",
      "Ep: 196/200, it: 1/468, err: 0.0002\n",
      "Ep: 196/200, it: 51/468, err: 0.0006\n",
      "Ep: 196/200, it: 101/468, err: 0.0000\n",
      "Ep: 196/200, it: 151/468, err: 0.0011\n",
      "Ep: 196/200, it: 201/468, err: 0.0000\n",
      "Ep: 196/200, it: 251/468, err: 0.0001\n",
      "Ep: 196/200, it: 301/468, err: 0.0001\n",
      "Ep: 196/200, it: 351/468, err: 0.0006\n",
      "Ep: 196/200, it: 401/468, err: 0.0000\n",
      "Ep: 196/200, it: 451/468, err: 0.0002\n",
      "Ep: 196/200, it: 468/468, err: 0.0001\n",
      "Test acc: 99.52\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    2    0  888    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9332e-07.\n",
      "Ep: 197/200, it: 1/468, err: 0.0000\n",
      "Ep: 197/200, it: 51/468, err: 0.0001\n",
      "Ep: 197/200, it: 101/468, err: 0.0001\n",
      "Ep: 197/200, it: 151/468, err: 0.0000\n",
      "Ep: 197/200, it: 201/468, err: 0.0007\n",
      "Ep: 197/200, it: 251/468, err: 0.0001\n",
      "Ep: 197/200, it: 301/468, err: 0.0001\n",
      "Ep: 197/200, it: 351/468, err: 0.0003\n",
      "Ep: 197/200, it: 401/468, err: 0.0001\n",
      "Ep: 197/200, it: 451/468, err: 0.0005\n",
      "Ep: 197/200, it: 468/468, err: 0.0002\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7753e-07.\n",
      "Ep: 198/200, it: 1/468, err: 0.0010\n",
      "Ep: 198/200, it: 51/468, err: 0.0000\n",
      "Ep: 198/200, it: 101/468, err: 0.0001\n",
      "Ep: 198/200, it: 151/468, err: 0.0000\n",
      "Ep: 198/200, it: 201/468, err: 0.0091\n",
      "Ep: 198/200, it: 251/468, err: 0.0001\n",
      "Ep: 198/200, it: 301/468, err: 0.0000\n",
      "Ep: 198/200, it: 351/468, err: 0.0000\n",
      "Ep: 198/200, it: 401/468, err: 0.0003\n",
      "Ep: 198/200, it: 451/468, err: 0.0001\n",
      "Ep: 198/200, it: 468/468, err: 0.0000\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2336e-07.\n",
      "Ep: 199/200, it: 1/468, err: 0.0004\n",
      "Ep: 199/200, it: 51/468, err: 0.0001\n",
      "Ep: 199/200, it: 101/468, err: 0.0005\n",
      "Ep: 199/200, it: 151/468, err: 0.0001\n",
      "Ep: 199/200, it: 201/468, err: 0.0001\n",
      "Ep: 199/200, it: 251/468, err: 0.0001\n",
      "Ep: 199/200, it: 301/468, err: 0.0004\n",
      "Ep: 199/200, it: 351/468, err: 0.0003\n",
      "Ep: 199/200, it: 401/468, err: 0.0000\n",
      "Ep: 199/200, it: 451/468, err: 0.0002\n",
      "Ep: 199/200, it: 468/468, err: 0.0004\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0842e-08.\n",
      "Ep: 200/200, it: 1/468, err: 0.0003\n",
      "Ep: 200/200, it: 51/468, err: 0.0001\n",
      "Ep: 200/200, it: 101/468, err: 0.0015\n",
      "Ep: 200/200, it: 151/468, err: 0.0003\n",
      "Ep: 200/200, it: 201/468, err: 0.0000\n",
      "Ep: 200/200, it: 251/468, err: 0.0001\n",
      "Ep: 200/200, it: 301/468, err: 0.0000\n",
      "Ep: 200/200, it: 351/468, err: 0.0001\n",
      "Ep: 200/200, it: 401/468, err: 0.0000\n",
      "Ep: 200/200, it: 451/468, err: 0.0009\n",
      "Ep: 200/200, it: 468/468, err: 0.0003\n",
      "Test acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]] \n",
      "\n",
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "Tr Acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]]\n",
      "Te Acc: 99.53\n",
      "[[ 978    0    1    0    0    0    1    0    0    0]\n",
      " [   0 1132    0    0    0    0    1    2    0    0]\n",
      " [   0    0 1029    1    0    0    0    1    1    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  975    0    4    0    0    3]\n",
      " [   1    0    0    1    0  889    0    1    0    0]\n",
      " [   1    4    0    0    0    1  951    0    1    0]\n",
      " [   0    2    4    1    0    0    0 1021    0    0]\n",
      " [   0    0    1    2    0    0    0    0  970    1]\n",
      " [   0    0    0    0    6    1    0    1    0 1001]]\n",
      "Ended at 2023-06-20 12:37:29\n",
      "Duration: 0:50:40.013933\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(args.model_path,exist_ok=True)\n",
    "solver = Solver(args)\n",
    "solver.train()\n",
    "solver.test()\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(\"Ended at \" + str(end_time.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "print(\"Duration: \" + str(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(solver.model.state_dict(),\"./data/model/mnist/Transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.train_loader.dataset.data.shape\n",
    "solver.test_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img,ax = plt.subplots(4,4,figsize=(9,9))\n",
    "plt.subplots_adjust(hspace=0.25,wspace=0.2)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        num = np.random.randint(0,solver.train_loader.dataset.data.shape[0])\n",
    "        ax[i][j].imshow(solver.train_loader.dataset.data[num],cmap=\"gray\")\n",
    "        ax[i][j].set_title(solver.train_loader.dataset.targets[num].item(),fontdict={\"fontsize\":20})\n",
    "        ax[i][j].set_xticks([])\n",
    "        ax[i][j].set_yticks([])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (imgs,labels) in solver.test_loader:\n",
    "    imgs = imgs.cuda()\n",
    "    with torch.no_grad():\n",
    "        class_out = solver.model(imgs)\n",
    "    \n",
    "    _,predicted = torch.max(class_out.data,1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img,ax = plt.subplots(4,4,figsize=(9,9))\n",
    "plt.subplots_adjust(hspace=0.25,wspace=0.2)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        num = np.random.randint(0,imgs.shape[0])\n",
    "        ax[i][j].imshow(imgs[num][0].cpu(),cmap=\"gray\")\n",
    "        ax[i][j].set_title(\"P:\"+str(predicted[num].cpu().item())+\",T:\"+str(labels[num].item()),fontdict={\"fontsize\":20})\n",
    "        ax[i][j].set_xticks([])\n",
    "        ax[i][j].set_yticks([])\n",
    "        \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "971ee1da7255ecde3216791eeee73f2ee8d2956ba6b6da13cdfb2a534ec0c35f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
